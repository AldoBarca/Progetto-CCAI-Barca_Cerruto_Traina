{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c5dcf1-fd7f-498b-a627-f95b3d1f7a28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Inizializzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40eceac-2dd3-4eba-bfbc-8b2a2cfb7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "063fd768-2fe9-4315-b472-23d52a5c921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.23.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fce462e-0156-4751-aeba-df63a6cf37c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3fff90d-213e-48ab-9eb4-34bb2f5bf9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e449586-6df0-4775-8c09-de9aa1c99c0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import AST Pretrained and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf758e99-f37f-4e8c-9f30-6a0ae431333f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import dataset huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab574a30-36f7-46f2-8b5c-df8de3bc784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, ASTForAudioClassification\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\", trust_remote_code=True)\n",
    "dataset = dataset.sort(\"id\")\n",
    "sampling_rate = dataset.features[\"audio\"].sampling_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a91f313-1b2c-4fdb-beb4-e3d1436c2286",
   "metadata": {},
   "source": [
    "## Import AST huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "91dfc551-2442-4274-a0a4-ed1281707bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ast feature extractor\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "743c5bc6-a339-4c1f-ae24-9ec4641ca4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASTForAudioClassification(\n",
       "  (audio_spectrogram_transformer): ASTModel(\n",
       "    (embeddings): ASTEmbeddings(\n",
       "      (patch_embeddings): ASTPatchEmbeddings(\n",
       "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ASTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ASTLayer(\n",
       "          (attention): ASTSdpaAttention(\n",
       "            (attention): ASTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ASTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ASTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ASTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): ASTMLPHead(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=768, out_features=527, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ast pretrained\n",
    "ast_huggingface = ASTForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "ast_huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574de9e3-7f7f-40b2-911c-92d3d4013896",
   "metadata": {},
   "source": [
    "## Test pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a4185ed5-b0e3-4b3c-82f1-4bc82a1c423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio file is decoded on the fly\n",
    "inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = ast_huggingface(**inputs).logits\n",
    "\n",
    "predicted_class_ids = torch.argmax(logits, dim=-1).item()\n",
    "predicted_label = ast_huggingface.config.id2label[predicted_class_ids]\n",
    "print(predicted_label)\n",
    "\n",
    "# compute loss - target_label is e.g. \"down\"\n",
    "target_label = ast_huggingface.config.id2label[0]\n",
    "inputs[\"labels\"] = torch.tensor([ast_huggingface.config.label2id[target_label]])\n",
    "loss = ast_huggingface(**inputs).loss\n",
    "round(loss.item(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c578e51-5352-4509-90ad-a8ee869c69c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prompt Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dcd6f0-f65a-44b9-b327-3096e50b4a89",
   "metadata": {},
   "source": [
    "## Retrieve Output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "187b8b8f-f1f4-4ffd-8ce1-e7c11fdd2eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASTModel(\n",
       "  (embeddings): ASTEmbeddings(\n",
       "    (patch_embeddings): ASTPatchEmbeddings(\n",
       "      (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): ASTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ASTLayer(\n",
       "        (attention): ASTSdpaAttention(\n",
       "          (attention): ASTSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ASTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ASTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ASTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ASTModel\n",
    "import torch\n",
    "\n",
    "ast_model = ASTModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "ast_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c0265fcd-366f-4fa5-9cd1-8204a8ffe4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1214, 768]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio file is decoded on the fly\n",
    "inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = ast_model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9207ad-fdde-42f1-b9b8-263d20db75e5",
   "metadata": {},
   "source": [
    "## Model and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7892cd7b-906c-4c63-baaa-452420a9edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import mul\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AST_PromptTuning(nn.Module):\n",
    "\n",
    "    # dropout apply dropout after each prompt\n",
    "    # str = \"none\" --> only head tuning\n",
    "    def __init__(self, prompt_tokens: int = 5, prompt_dropout: float = 0.0, prompt_type: str = 'deep'):\n",
    "        super().__init__()\n",
    "\n",
    "        # load vit model\n",
    "        self.encoder = ASTModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "\n",
    "        # hidden_size = depth of the model\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.config.hidden_size, 384),\n",
    "            # nn.Linear(self.encoder.config.hidden_size, 192),\n",
    "            # nn.Linear(self.encoder.config.hidden_size, 96),\n",
    "            nn.Linear(384, 15)\n",
    "        )\n",
    "\n",
    "        # freeze\n",
    "        for n, p in self.encoder.named_parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.prompt_type = prompt_type # \"shallow\" \"deep\" or None\n",
    "\n",
    "        if prompt_type is not None:\n",
    "\n",
    "            # prompt\n",
    "            self.prompt_tokens = prompt_tokens  # number of prompted tokens\n",
    "            self.prompt_dropout = nn.Dropout(prompt_dropout)\n",
    "            self.prompt_dim = self.encoder.config.hidden_size\n",
    "\n",
    "            # initiate prompt (random)\n",
    "            val = math.sqrt(6. / float(3 * reduce(mul, (self.encoder.config.patch_size, self.encoder.config.patch_size), 1) + self.prompt_dim))\n",
    "\n",
    "            # my vector of learnable parameters (how many (prompt_tokens) and dimension (prompt_dim))\n",
    "            self.prompt_embeddings = nn.Parameter(torch.zeros(1, self.prompt_tokens, self.prompt_dim))\n",
    "\n",
    "            # xavier_uniform initialization\n",
    "            nn.init.uniform_(self.prompt_embeddings.data, -val, val)\n",
    "\n",
    "            if self.prompt_type == 'deep':\n",
    "                self.total_d_layer = self.encoder.config.num_hidden_layers\n",
    "                self.deep_prompt_embeddings = nn.Parameter(\n",
    "                    # - 1 cause shallow already inserted\n",
    "                    torch.zeros(self.total_d_layer-1, self.prompt_tokens, self.prompt_dim)\n",
    "                )\n",
    "                # xavier_uniform initialization\n",
    "                nn.init.uniform_(self.deep_prompt_embeddings.data, -val, val)\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        # set train status for this class: disable all but the prompt-related modules\n",
    "        if mode:\n",
    "            # training:\n",
    "            self.encoder.eval()\n",
    "            if self.prompt_type is not None:\n",
    "              # enable dropout and batch normalization\n",
    "                self.prompt_dropout.train()\n",
    "        else:\n",
    "            # eval:\n",
    "            for module in self.children():\n",
    "                module.train(mode)\n",
    "\n",
    "    def incorporate_prompt(self, x, prompt_embeddings, n_prompt: int = 0):\n",
    "        # x shape: (batch size, n_tokens, hidden_dim)\n",
    "        # pompt_embeddings shape: (1, n_prompt, hidden_dim)\n",
    "        B = x.shape[0]\n",
    "\n",
    "        # peek the class token, add prompts, add sequence\n",
    "\n",
    "        # concat prompts: (batch size, cls_token + n_prompt + n_patches, hidden_dim)\n",
    "        x = torch.cat((\n",
    "            x[:, :1, :],\n",
    "            self.prompt_dropout(prompt_embeddings.expand(B, -1, -1)),\n",
    "            x[:, (1+n_prompt):, :]\n",
    "        ), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_features(self, x):\n",
    "\n",
    "        # go through the encoder embeddings\n",
    "        x = self.encoder.embeddings(x)\n",
    "\n",
    "        # add prompts\n",
    "        x = self.incorporate_prompt(x, self.prompt_embeddings)\n",
    "\n",
    "        if self.prompt_type == 'deep':\n",
    "            # deep mode\n",
    "            x = model.encoder.encoder.layer[0](x)[0]\n",
    "            for i in range(1, self.total_d_layer):\n",
    "                x = self.incorporate_prompt(x, self.deep_prompt_embeddings[i-1], self.prompt_tokens)\n",
    "                x = model.encoder.encoder.layer[i](x)[0]\n",
    "        else:\n",
    "            # shallow mode\n",
    "            x = self.encoder.encoder(x)[\"last_hidden_state\"]\n",
    "\n",
    "        x = self.encoder.layernorm(x)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.prompt_type is not None:\n",
    "            x = self.forward_features(x)[:, 0, :]\n",
    "        else:\n",
    "          # pass x, take the classification token\n",
    "            x = self.encoder(x)[\"last_hidden_state\"][:, 0, :]\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f5f66293-d648-4fb4-808d-1ef178a2e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AST params: 86488335\n",
      "Head fine-tuning: 301071\n",
      "Shallow prompt-tuning: 304911\n",
      "Deep prompt-tuning: 347151\n"
     ]
    }
   ],
   "source": [
    "ast_prompt = AST_PromptTuning(prompt_type=None)\n",
    "# count number of parameters\n",
    "print(\"AST params:\", sum(p.numel() for p in ast_prompt.parameters()))\n",
    "# count number of trainable parameters\n",
    "print(\"Head fine-tuning:\", sum(p.numel() for p in ast_prompt.parameters() if p.requires_grad))\n",
    "ast_prompt_shallow = AST_PromptTuning(prompt_type='shallow')\n",
    "# count number of trainable parameters\n",
    "print(\"Shallow prompt-tuning:\", sum(p.numel() for p in ast_prompt_shallow.parameters() if p.requires_grad))\n",
    "ast_prompt_deep = AST_PromptTuning(prompt_type='deep')\n",
    "# count number of trainable parameters\n",
    "print(\"Deep prompt-tuning:\", sum(p.numel() for p in ast_prompt_deep.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a071ebf6-97fa-4c54-9831-12b5dbdd824e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio file is decoded on the fly\n",
    "inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = ast_prompt(inputs['input_values'])\n",
    "\n",
    "predicted_class_ids = torch.argmax(outputs, dim=-1).item()\n",
    "predicted_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f0ca634f-8544-499d-b268-8383356231ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0868, 0.0701, 0.0472, 0.0732, 0.0544, 0.0472, 0.0497, 0.0480, 0.0695,\n",
       "         0.0493, 0.0593, 0.0988, 0.1038, 0.0229, 0.1197]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "softmax = F.softmax(outputs, dim=1)\n",
    "softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7bebb3-793a-4215-b567-97907f86307a",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a87894-a860-4c30-a814-9119f3cedb47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "370425c2-b8aa-44bb-bf95-07aa08e059df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "def load_audio(audio_path):\n",
    "    audio, sample_rate = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "    return audio, sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a968417d-4032-4d6f-8d10-60063e4ff6db",
   "metadata": {},
   "source": [
    "## TUT17 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "7b89526e-dc00-4ffc-a07f-566c0d1f9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "# from folder to PyTorch Dataset\n",
    "class TUT17(Dataset):\n",
    "    def __init__(self, root_dir, split = 'train', seed = 42, val_frac= 0.1, test_frac= 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # we use seed because every time we instantiate the dataset we shuffle all the data\n",
    "        # we call at least 3 times (train, validation, test) --> overlapping area\n",
    "        # with seed we are sure that the dataset is shuffled always in the same way\n",
    "        random.seed(seed)\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        audio_names = os.listdir(os.path.join(root_dir, 'Audio'))\n",
    "        \n",
    "        num_val = int(len(audio_names)*val_frac)\n",
    "        num_test = int(len(audio_names)*test_frac)\n",
    "        num_train = len(audio_names) - num_val - num_test\n",
    "\n",
    "        random.shuffle(audio_names)\n",
    "    \n",
    "        # at this step we are only using images names - we are not using images\n",
    "        if split == 'train':\n",
    "            self.data = audio_names[:num_train]\n",
    "        elif split == 'val':\n",
    "            self.data = audio_names[num_train:num_train+num_val]\n",
    "        elif split == 'test':\n",
    "            self.data = audio_names[-num_test:]\n",
    "        else:\n",
    "          raise ValueError('Invalid split value.')\n",
    "    \n",
    "    # optional\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = os.path.join(self.root_dir, 'audio', self.data[idx])\n",
    "\n",
    "        audio_name = audio_path.split('/')[-1][6:].replace('\\\\', '/')\n",
    "\n",
    "        label_path = os.path.join(self.root_dir, 'labels\\evaluate.txt')\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            while line := f.readline():\n",
    "                if line.split('\\t')[0] == audio_name:\n",
    "                    f.close()\n",
    "                    audio, sample_rate = load_audio(audio_path)\n",
    "                    return {'audio': audio, 'sample_rate': sample_rate, 'label': line.split('\\t')[1][:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d37473dd-0577-4cdc-97f6-de8d4662d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TUT17(root_dir = \"c:/Users/cerru/Desktop/TUT17\", split='train')\n",
    "val_dataset = TUT17(root_dir = 'c:/Users/cerru/Desktop/TUT17', split='val')\n",
    "test_dataset = TUT17(root_dir = 'c:/Users/cerru/Desktop/TUT17', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "ee2c9675-88c7-4189-a173-da28bf87fb89",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[344], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m test_loader  \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset,  batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[1;32m---> 10\u001b[0m \u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\audio_spectrogram_transformer\\feature_extraction_audio_spectrogram_transformer.py:188\u001b[0m, in \u001b[0;36mASTFeatureExtractor.__call__\u001b[1;34m(self, raw_speech, sampling_rate, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mMain method to featurize and prepare for the model one or several sequence(s).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m        - `'np'`: Return Numpy `np.ndarray` objects.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampling_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sampling_rate \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate:\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    190\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model corresponding to this feature extractor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was trained using a sampling rate of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please make sure that the provided `raw_speech` input was sampled with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m         )\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, num_workers=0, shuffle=True, drop_last=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=4, num_workers=0, shuffle=False, drop_last=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=4, num_workers=0, shuffle=False, drop_last=True)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "feature_extractor(batch[\"audio\"], sampling_rate=batch[\"sample_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f191b1-4f7e-46e9-a07c-955634e586e8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "313650d0-9f4b-48aa-9119-c1becea13199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, feature_extractor, criterion, epochs, dev, lr=0.001, load_checkpoint = False, save_every = 10, save_path = 'weights'):\n",
    "    try:\n",
    "        if not os.path.isdir(save_path):\n",
    "            os.mkdir(save_path)\n",
    "            \n",
    "        # Move model to CUDA\n",
    "        model = model.to(dev)\n",
    "        # MOVE criterior to CUDA\n",
    "        criterion = criterion.to(dev)\n",
    "\n",
    "        # create optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "        \n",
    "        labels_l = []\n",
    "        predictions_l = []\n",
    "        \n",
    "        # load checkpoints\n",
    "        if load_checkpoint:\n",
    "            if os.path.isfile(os.path.join(save_path,'weights.pt')):\n",
    "                print('Loading weights...')\n",
    "                # it is possible to load a state dict that doesn't match the networck architecture by passing asserting the strict mode\n",
    "                model.load_state_dict(torch.load(os.path.join(save_path,'weights.pt')))\n",
    "            if os.path.isfile(os.path.join(save_path,'optim.pt')):\n",
    "                print('Loading optimizer...')\n",
    "                optimizer.load_state_dict(torch.load(os.path.join(save_path,'optim.pt')))\n",
    "            print('Loading completed!')\n",
    "\n",
    "        # Initialize history\n",
    "        history_loss = {\"train\": [], \"val\": [], \"test\": []}\n",
    "        history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "        # Process each epoch\n",
    "        for epoch in range(epochs):\n",
    "            # Initialize epoch variables\n",
    "            sum_loss = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "            sum_accuracy = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "            \n",
    "            # Process each split\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                #Select train() or eval() mode\n",
    "                if split == 'train':\n",
    "                  model.train()\n",
    "                else:\n",
    "                  model.eval()\n",
    "                    \n",
    "                # Process each batch\n",
    "                for batch in loaders[split]:\n",
    "                    # Move to CUDA\n",
    "                    input_audio = batch['audio'].to(dev)\n",
    "                    sample_rate = batch['sample_rate'].to(dev)\n",
    "                    target = batch['label'].squeeze(1).to(dev)\n",
    "\n",
    "                    # Reset gradients\n",
    "                    if split == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                    \n",
    "                    # Compute output\n",
    "                    ast_imput = feature_extractor(input_audio, sampling_rate=sample_rate, return_tensors=\"pt\")\n",
    "                    output = model(ast_input)\n",
    "\n",
    "                    # Compute loss \n",
    "                    loss = criterion(output, target.long())\n",
    "                    \n",
    "                    # Update loss\n",
    "                    sum_loss[split] += loss.item()\n",
    "                    \n",
    "                    # Check parameter update\n",
    "                    if split == \"train\":\n",
    "                        # Compute gradients\n",
    "                        loss.backward()\n",
    "                        # Optimize\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    # Compute accuracy\n",
    "                    pred = torch.argmax(output,1)\n",
    "                    batch_accuracy = (pred == target).sum().item()/target.numel()\n",
    "                    \n",
    "                    # Update accuracy\n",
    "                    sum_accuracy[split] += batch_accuracy\n",
    "\n",
    "                # checkpoint\n",
    "                if epoch%save_every == 0 and split == 'train':\n",
    "                    torch.save(model.state_dict(), os.path.join(save_path, 'weights.pt'))\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(save_path, 'optim.pt'))\n",
    "                \n",
    "                \n",
    "            # Compute epoch loss/accuracy\n",
    "            epoch_loss = {split: sum_loss[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
    "            epoch_accuracy = {split: sum_accuracy[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
    "            # Update history\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                history_loss[split].append(epoch_loss[split])\n",
    "                history_accuracy[split].append(epoch_accuracy[split])\n",
    "            # Print info\n",
    "            print(f\"Epoch {epoch+1}:\",\n",
    "                  f\"TrL={epoch_loss['train']:.4f},\",\n",
    "                  f\"TrA={epoch_accuracy['train']:.4f},\",\n",
    "                  f\"VL={epoch_loss['val']:.4f},\",\n",
    "                  f\"VA={epoch_accuracy['val']:.4f},\",\n",
    "                  f\"TeL={epoch_loss['test']:.4f},\",\n",
    "                  f\"TeA={epoch_accuracy['test']:.4f},\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    finally:\n",
    "        # Plot loss\n",
    "        plt.title(\"Loss\")\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            plt.plot(history_loss[split], label=split)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # Plot accuracy\n",
    "        plt.title(\"Accuracy\")\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            plt.plot(history_accuracy[split], label=split)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    running_loss = 0.0\n",
    "    for batch in tqdm(train_loader):\n",
    "        audio = batch[\"audio\"]\n",
    "        sample_rate = batch[\"sample_rate\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        audio, sample_rate = audio.to(device), labels.to(device)\n",
    "        #optimizer.zero_grad()\n",
    "        #outputs = model(inputs)\n",
    "        #loss = criterion(outputs, labels)\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        #running_loss += loss.item()\n",
    "    #return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "041bfcca-8a9a-410d-80e0-a2e2998a51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    running_loss = 0.0\n",
    "    for (inputs, labels) in tqdm(val_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "95832ebb-acda-4849-87e0-9c144c0157f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, device, n_epochs: int = 10):\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        #train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        #val_loss = validate(model, val_loader, criterion, device)\n",
    "        #print(f'Epoch {epoch+1}/{n_epochs} : Train Loss {train_loss:.4f} : Val Loss {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "6cd60963-7457-492a-9392-4b5f1b7dba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    running_loss = 0.0\n",
    "    labels_l = []\n",
    "    predictions_l = []\n",
    "    for (inputs, labels) in tqdm(test_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        # compute accuracy\n",
    "        labels_l.append(labels)\n",
    "        predictions_l.append(predictions)\n",
    "\n",
    "    labels = torch.cat(labels_l, dim=0)\n",
    "    predictions = torch.cat(predictions_l, dim=0)\n",
    "\n",
    "    accuracy = (predictions == labels).sum().item() / len(labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "03c893d9-5497-4b25-9a82-589420bdddcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–Œ                                                                                 | 2/324 [00:00<00:24, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-1.8764e-04, -2.4411e-04, -1.8040e-04,  ...,  2.6641e-03,\n",
      "          3.0369e-03,  0.0000e+00],\n",
      "        [ 6.9736e-04,  1.5239e-03,  1.7926e-03,  ..., -3.9335e-03,\n",
      "         -1.0351e-02,  0.0000e+00],\n",
      "        [-8.8113e-05, -1.1776e-04, -8.4949e-05,  ..., -1.3294e-04,\n",
      "         -1.4187e-04,  0.0000e+00],\n",
      "        [ 4.3056e-03,  6.6272e-03,  5.0238e-03,  ..., -8.2879e-03,\n",
      "         -1.1731e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'city_center', 'office', 'cafe/restaurant']}\n",
      "tensor([[-1.8764e-04, -2.4411e-04, -1.8040e-04,  ...,  2.6641e-03,\n",
      "          3.0369e-03,  0.0000e+00],\n",
      "        [ 6.9736e-04,  1.5239e-03,  1.7926e-03,  ..., -3.9335e-03,\n",
      "         -1.0351e-02,  0.0000e+00],\n",
      "        [-8.8113e-05, -1.1776e-04, -8.4949e-05,  ..., -1.3294e-04,\n",
      "         -1.4187e-04,  0.0000e+00],\n",
      "        [ 4.3056e-03,  6.6272e-03,  5.0238e-03,  ..., -8.2879e-03,\n",
      "         -1.1731e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'city_center', 'office', 'cafe/restaurant']\n",
      "{'audio': tensor([[ 3.1229e-04,  4.6596e-04,  7.7522e-04,  ...,  1.6630e-04,\n",
      "          1.1017e-03,  0.0000e+00],\n",
      "        [-2.6343e-03, -4.6063e-03, -3.4863e-03,  ..., -9.7539e-03,\n",
      "         -1.1159e-02,  0.0000e+00],\n",
      "        [ 2.6595e-03,  4.4404e-03,  3.9372e-03,  ...,  1.1404e-03,\n",
      "          2.7413e-03,  0.0000e+00],\n",
      "        [ 4.8246e-05,  6.2797e-05, -2.2807e-06,  ..., -6.5853e-04,\n",
      "         -8.3269e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'cafe/restaurant', 'car', 'residential_area']}\n",
      "tensor([[ 3.1229e-04,  4.6596e-04,  7.7522e-04,  ...,  1.6630e-04,\n",
      "          1.1017e-03,  0.0000e+00],\n",
      "        [-2.6343e-03, -4.6063e-03, -3.4863e-03,  ..., -9.7539e-03,\n",
      "         -1.1159e-02,  0.0000e+00],\n",
      "        [ 2.6595e-03,  4.4404e-03,  3.9372e-03,  ...,  1.1404e-03,\n",
      "          2.7413e-03,  0.0000e+00],\n",
      "        [ 4.8246e-05,  6.2797e-05, -2.2807e-06,  ..., -6.5853e-04,\n",
      "         -8.3269e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'cafe/restaurant', 'car', 'residential_area']\n",
      "{'audio': tensor([[-0.0003, -0.0005, -0.0004,  ...,  0.0004,  0.0004,  0.0000],\n",
      "        [-0.0172, -0.0299, -0.0272,  ..., -0.0113, -0.0134,  0.0000],\n",
      "        [ 0.0103,  0.0172,  0.0149,  ..., -0.0041, -0.0054,  0.0000],\n",
      "        [ 0.0034,  0.0061,  0.0033,  ...,  0.0012, -0.0016,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'car', 'train', 'metro_station']}\n",
      "tensor([[-0.0003, -0.0005, -0.0004,  ...,  0.0004,  0.0004,  0.0000],\n",
      "        [-0.0172, -0.0299, -0.0272,  ..., -0.0113, -0.0134,  0.0000],\n",
      "        [ 0.0103,  0.0172,  0.0149,  ..., -0.0041, -0.0054,  0.0000],\n",
      "        [ 0.0034,  0.0061,  0.0033,  ...,  0.0012, -0.0016,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'car', 'train', 'metro_station']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–ˆâ–Œ                                                                                | 6/324 [00:00<00:26, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0042, -0.0069, -0.0059,  ...,  0.0093,  0.0119,  0.0000],\n",
      "        [-0.0019, -0.0041, -0.0045,  ..., -0.0045, -0.0055,  0.0000],\n",
      "        [-0.0052, -0.0086, -0.0074,  ...,  0.0037,  0.0040,  0.0000],\n",
      "        [-0.0005, -0.0008, -0.0006,  ..., -0.0010, -0.0013,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['grocery_store', 'park', 'car', 'forest_path']}\n",
      "tensor([[-0.0042, -0.0069, -0.0059,  ...,  0.0093,  0.0119,  0.0000],\n",
      "        [-0.0019, -0.0041, -0.0045,  ..., -0.0045, -0.0055,  0.0000],\n",
      "        [-0.0052, -0.0086, -0.0074,  ...,  0.0037,  0.0040,  0.0000],\n",
      "        [-0.0005, -0.0008, -0.0006,  ..., -0.0010, -0.0013,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['grocery_store', 'park', 'car', 'forest_path']\n",
      "{'audio': tensor([[-0.0063, -0.0105, -0.0087,  ...,  0.0158,  0.0210,  0.0000],\n",
      "        [ 0.0009,  0.0019,  0.0020,  ..., -0.0010, -0.0015,  0.0000],\n",
      "        [-0.0020, -0.0037, -0.0038,  ...,  0.0060,  0.0054,  0.0000],\n",
      "        [ 0.0001,  0.0002,  0.0001,  ...,  0.0009,  0.0011,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['grocery_store', 'forest_path', 'car', 'library']}\n",
      "tensor([[-0.0063, -0.0105, -0.0087,  ...,  0.0158,  0.0210,  0.0000],\n",
      "        [ 0.0009,  0.0019,  0.0020,  ..., -0.0010, -0.0015,  0.0000],\n",
      "        [-0.0020, -0.0037, -0.0038,  ...,  0.0060,  0.0054,  0.0000],\n",
      "        [ 0.0001,  0.0002,  0.0001,  ...,  0.0009,  0.0011,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['grocery_store', 'forest_path', 'car', 'library']\n",
      "{'audio': tensor([[ 0.0227,  0.0374,  0.0319,  ...,  0.0048,  0.0063,  0.0000],\n",
      "        [ 0.0105,  0.0164,  0.0163,  ...,  0.0082,  0.0098,  0.0000],\n",
      "        [ 0.0109,  0.0183,  0.0158,  ...,  0.0826,  0.0891,  0.0000],\n",
      "        [-0.0308, -0.0524, -0.0469,  ...,  0.0816,  0.0922,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['train', 'cafe/restaurant', 'car', 'car']}\n",
      "tensor([[ 0.0227,  0.0374,  0.0319,  ...,  0.0048,  0.0063,  0.0000],\n",
      "        [ 0.0105,  0.0164,  0.0163,  ...,  0.0082,  0.0098,  0.0000],\n",
      "        [ 0.0109,  0.0183,  0.0158,  ...,  0.0826,  0.0891,  0.0000],\n",
      "        [-0.0308, -0.0524, -0.0469,  ...,  0.0816,  0.0922,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['train', 'cafe/restaurant', 'car', 'car']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–ˆâ–ˆ                                                                                | 8/324 [00:00<00:26, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-1.3624e-04,  1.1135e-03,  3.9968e-03,  ..., -1.5293e-02,\n",
      "         -1.7948e-02,  0.0000e+00],\n",
      "        [-1.9540e-02, -3.2813e-02, -2.8338e-02,  ..., -2.8979e-02,\n",
      "         -3.3219e-02,  0.0000e+00],\n",
      "        [-9.0841e-05, -3.1393e-04, -5.0443e-04,  ..., -4.9155e-04,\n",
      "          2.3185e-04,  0.0000e+00],\n",
      "        [ 8.5528e-05,  1.0414e-04, -4.4602e-05,  ..., -2.6228e-04,\n",
      "         -2.7247e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['train', 'bus', 'residential_area', 'office']}\n",
      "tensor([[-1.3624e-04,  1.1135e-03,  3.9968e-03,  ..., -1.5293e-02,\n",
      "         -1.7948e-02,  0.0000e+00],\n",
      "        [-1.9540e-02, -3.2813e-02, -2.8338e-02,  ..., -2.8979e-02,\n",
      "         -3.3219e-02,  0.0000e+00],\n",
      "        [-9.0841e-05, -3.1393e-04, -5.0443e-04,  ..., -4.9155e-04,\n",
      "          2.3185e-04,  0.0000e+00],\n",
      "        [ 8.5528e-05,  1.0414e-04, -4.4602e-05,  ..., -2.6228e-04,\n",
      "         -2.7247e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['train', 'bus', 'residential_area', 'office']\n",
      "{'audio': tensor([[-0.0043, -0.0071, -0.0065,  ...,  0.0033,  0.0038,  0.0000],\n",
      "        [ 0.0045,  0.0087,  0.0052,  ...,  0.0026,  0.0035,  0.0000],\n",
      "        [ 0.0003,  0.0009,  0.0013,  ..., -0.0016, -0.0020,  0.0000],\n",
      "        [ 0.0018,  0.0025,  0.0018,  ..., -0.0021, -0.0026,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'park', 'beach', 'tram']}\n",
      "tensor([[-0.0043, -0.0071, -0.0065,  ...,  0.0033,  0.0038,  0.0000],\n",
      "        [ 0.0045,  0.0087,  0.0052,  ...,  0.0026,  0.0035,  0.0000],\n",
      "        [ 0.0003,  0.0009,  0.0013,  ..., -0.0016, -0.0020,  0.0000],\n",
      "        [ 0.0018,  0.0025,  0.0018,  ..., -0.0021, -0.0026,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'park', 'beach', 'tram']\n",
      "{'audio': tensor([[-7.8577e-05, -4.8162e-05,  4.3935e-05,  ...,  5.3827e-04,\n",
      "          5.9416e-04,  0.0000e+00],\n",
      "        [ 3.1323e-05,  5.6124e-04,  8.4939e-04,  ..., -4.8392e-04,\n",
      "         -3.2296e-04,  0.0000e+00],\n",
      "        [ 7.4447e-04, -1.2852e-03, -3.1504e-03,  ..., -4.2467e-03,\n",
      "         -6.2888e-03,  0.0000e+00],\n",
      "        [-1.0679e-03, -9.2495e-04,  8.5078e-04,  ...,  2.5084e-02,\n",
      "          2.1206e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'grocery_store', 'metro_station', 'residential_area']}\n",
      "tensor([[-7.8577e-05, -4.8162e-05,  4.3935e-05,  ...,  5.3827e-04,\n",
      "          5.9416e-04,  0.0000e+00],\n",
      "        [ 3.1323e-05,  5.6124e-04,  8.4939e-04,  ..., -4.8392e-04,\n",
      "         -3.2296e-04,  0.0000e+00],\n",
      "        [ 7.4447e-04, -1.2852e-03, -3.1504e-03,  ..., -4.2467e-03,\n",
      "         -6.2888e-03,  0.0000e+00],\n",
      "        [-1.0679e-03, -9.2495e-04,  8.5078e-04,  ...,  2.5084e-02,\n",
      "          2.1206e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'grocery_store', 'metro_station', 'residential_area']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–ˆâ–ˆâ–ˆ                                                                              | 12/324 [00:00<00:26, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-1.3511e-02, -2.1407e-02, -2.1955e-02,  ..., -2.2219e-02,\n",
      "         -2.1327e-02,  0.0000e+00],\n",
      "        [-3.4188e-05,  2.1089e-04,  1.5366e-04,  ..., -1.8785e-03,\n",
      "         -1.7878e-03,  0.0000e+00],\n",
      "        [ 2.7353e-04,  1.0721e-03, -7.0572e-05,  ..., -1.6345e-03,\n",
      "         -1.8741e-03,  0.0000e+00],\n",
      "        [-1.4287e-02, -2.1274e-02, -1.1655e-02,  ...,  3.1093e-02,\n",
      "          3.2549e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['city_center', 'metro_station', 'library', 'city_center']}\n",
      "tensor([[-1.3511e-02, -2.1407e-02, -2.1955e-02,  ..., -2.2219e-02,\n",
      "         -2.1327e-02,  0.0000e+00],\n",
      "        [-3.4188e-05,  2.1089e-04,  1.5366e-04,  ..., -1.8785e-03,\n",
      "         -1.7878e-03,  0.0000e+00],\n",
      "        [ 2.7353e-04,  1.0721e-03, -7.0572e-05,  ..., -1.6345e-03,\n",
      "         -1.8741e-03,  0.0000e+00],\n",
      "        [-1.4287e-02, -2.1274e-02, -1.1655e-02,  ...,  3.1093e-02,\n",
      "          3.2549e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['city_center', 'metro_station', 'library', 'city_center']\n",
      "{'audio': tensor([[-1.1496e-04, -7.4821e-05,  3.2311e-05,  ..., -3.9653e-04,\n",
      "         -2.9703e-05,  0.0000e+00],\n",
      "        [-1.6517e-03, -2.7423e-03, -2.2741e-03,  ..., -1.0291e-04,\n",
      "         -1.9043e-04,  0.0000e+00],\n",
      "        [-4.1872e-03, -6.1047e-03, -7.7395e-03,  ..., -2.4814e-02,\n",
      "         -2.7130e-02,  0.0000e+00],\n",
      "        [-2.6343e-03, -4.0401e-03, -7.8867e-04,  ..., -7.7246e-03,\n",
      "         -1.0137e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['metro_station', 'metro_station', 'train', 'cafe/restaurant']}\n",
      "tensor([[-1.1496e-04, -7.4821e-05,  3.2311e-05,  ..., -3.9653e-04,\n",
      "         -2.9703e-05,  0.0000e+00],\n",
      "        [-1.6517e-03, -2.7423e-03, -2.2741e-03,  ..., -1.0291e-04,\n",
      "         -1.9043e-04,  0.0000e+00],\n",
      "        [-4.1872e-03, -6.1047e-03, -7.7395e-03,  ..., -2.4814e-02,\n",
      "         -2.7130e-02,  0.0000e+00],\n",
      "        [-2.6343e-03, -4.0401e-03, -7.8867e-04,  ..., -7.7246e-03,\n",
      "         -1.0137e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['metro_station', 'metro_station', 'train', 'cafe/restaurant']\n",
      "{'audio': tensor([[-1.2818e-04, -2.8855e-04, -1.5757e-04,  ..., -2.0508e-04,\n",
      "         -2.1982e-04,  0.0000e+00],\n",
      "        [ 2.7419e-05,  8.4337e-05,  1.0376e-04,  ..., -3.7970e-04,\n",
      "         -4.2986e-04,  0.0000e+00],\n",
      "        [ 1.3769e-03,  2.9394e-03,  3.2272e-03,  ..., -3.7700e-03,\n",
      "         -3.6744e-03,  0.0000e+00],\n",
      "        [ 1.4318e-03,  2.2626e-03,  1.2195e-03,  ..., -5.3438e-03,\n",
      "         -4.6674e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'forest_path', 'train', 'beach']}\n",
      "tensor([[-1.2818e-04, -2.8855e-04, -1.5757e-04,  ..., -2.0508e-04,\n",
      "         -2.1982e-04,  0.0000e+00],\n",
      "        [ 2.7419e-05,  8.4337e-05,  1.0376e-04,  ..., -3.7970e-04,\n",
      "         -4.2986e-04,  0.0000e+00],\n",
      "        [ 1.3769e-03,  2.9394e-03,  3.2272e-03,  ..., -3.7700e-03,\n",
      "         -3.6744e-03,  0.0000e+00],\n",
      "        [ 1.4318e-03,  2.2626e-03,  1.2195e-03,  ..., -5.3438e-03,\n",
      "         -4.6674e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'forest_path', 'train', 'beach']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–ˆâ–ˆâ–ˆâ–Œ                                                                             | 14/324 [00:01<00:26, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-5.5635e-03, -9.1519e-03, -7.5676e-03,  ..., -4.7393e-02,\n",
      "         -5.5831e-02,  0.0000e+00],\n",
      "        [ 4.2677e-03,  7.1920e-03,  6.4576e-03,  ..., -3.1504e-02,\n",
      "         -3.6569e-02,  0.0000e+00],\n",
      "        [ 2.5836e-05, -3.1287e-05, -1.1036e-04,  ..., -6.6740e-05,\n",
      "          1.4680e-06,  0.0000e+00],\n",
      "        [-2.1464e-03, -7.2466e-03, -8.9443e-03,  ..., -2.1542e-02,\n",
      "         -2.8332e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['tram', 'car', 'library', 'city_center']}\n",
      "tensor([[-5.5635e-03, -9.1519e-03, -7.5676e-03,  ..., -4.7393e-02,\n",
      "         -5.5831e-02,  0.0000e+00],\n",
      "        [ 4.2677e-03,  7.1920e-03,  6.4576e-03,  ..., -3.1504e-02,\n",
      "         -3.6569e-02,  0.0000e+00],\n",
      "        [ 2.5836e-05, -3.1287e-05, -1.1036e-04,  ..., -6.6740e-05,\n",
      "          1.4680e-06,  0.0000e+00],\n",
      "        [-2.1464e-03, -7.2466e-03, -8.9443e-03,  ..., -2.1542e-02,\n",
      "         -2.8332e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['tram', 'car', 'library', 'city_center']\n",
      "{'audio': tensor([[ 0.0007,  0.0010,  0.0006,  ..., -0.0003, -0.0005,  0.0000],\n",
      "        [ 0.0025,  0.0038,  0.0022,  ...,  0.0085,  0.0094,  0.0000],\n",
      "        [-0.0054, -0.0081, -0.0046,  ...,  0.0130,  0.0140,  0.0000],\n",
      "        [ 0.0148,  0.0272,  0.0252,  ..., -0.0288, -0.0343,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'residential_area', 'tram', 'city_center']}\n",
      "tensor([[ 0.0007,  0.0010,  0.0006,  ..., -0.0003, -0.0005,  0.0000],\n",
      "        [ 0.0025,  0.0038,  0.0022,  ...,  0.0085,  0.0094,  0.0000],\n",
      "        [-0.0054, -0.0081, -0.0046,  ...,  0.0130,  0.0140,  0.0000],\n",
      "        [ 0.0148,  0.0272,  0.0252,  ..., -0.0288, -0.0343,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'residential_area', 'tram', 'city_center']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–ˆâ–ˆâ–ˆâ–ˆ                                                                             | 16/324 [00:01<00:26, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-1.9793e-04, -3.2484e-04, -2.1027e-04,  ..., -3.1048e-05,\n",
      "         -1.3128e-04,  0.0000e+00],\n",
      "        [ 8.0956e-03,  1.3977e-02,  1.2827e-02,  ...,  3.5226e-03,\n",
      "          2.4298e-03,  0.0000e+00],\n",
      "        [ 4.4128e-03,  7.7163e-03,  7.1604e-03,  ..., -3.4944e-02,\n",
      "         -4.0328e-02,  0.0000e+00],\n",
      "        [ 7.5541e-03,  1.2844e-02,  1.1502e-02,  ...,  3.4933e-04,\n",
      "          2.8949e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'bus', 'tram', 'residential_area']}\n",
      "tensor([[-1.9793e-04, -3.2484e-04, -2.1027e-04,  ..., -3.1048e-05,\n",
      "         -1.3128e-04,  0.0000e+00],\n",
      "        [ 8.0956e-03,  1.3977e-02,  1.2827e-02,  ...,  3.5226e-03,\n",
      "          2.4298e-03,  0.0000e+00],\n",
      "        [ 4.4128e-03,  7.7163e-03,  7.1604e-03,  ..., -3.4944e-02,\n",
      "         -4.0328e-02,  0.0000e+00],\n",
      "        [ 7.5541e-03,  1.2844e-02,  1.1502e-02,  ...,  3.4933e-04,\n",
      "          2.8949e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'bus', 'tram', 'residential_area']\n",
      "{'audio': tensor([[ 3.6852e-03,  3.8576e-03,  2.3022e-03,  ...,  4.5283e-03,\n",
      "          4.8865e-03,  0.0000e+00],\n",
      "        [-9.7458e-03, -1.6124e-02, -1.3941e-02,  ..., -1.4101e-03,\n",
      "         -5.9592e-04,  0.0000e+00],\n",
      "        [ 1.2128e-04,  1.6129e-04,  1.4092e-04,  ...,  7.7985e-05,\n",
      "         -5.6945e-07,  0.0000e+00],\n",
      "        [ 8.3636e-03,  1.3662e-02,  1.0128e-02,  ..., -1.6850e-03,\n",
      "         -1.3925e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['grocery_store', 'bus', 'home', 'cafe/restaurant']}\n",
      "tensor([[ 3.6852e-03,  3.8576e-03,  2.3022e-03,  ...,  4.5283e-03,\n",
      "          4.8865e-03,  0.0000e+00],\n",
      "        [-9.7458e-03, -1.6124e-02, -1.3941e-02,  ..., -1.4101e-03,\n",
      "         -5.9592e-04,  0.0000e+00],\n",
      "        [ 1.2128e-04,  1.6129e-04,  1.4092e-04,  ...,  7.7985e-05,\n",
      "         -5.6945e-07,  0.0000e+00],\n",
      "        [ 8.3636e-03,  1.3662e-02,  1.0128e-02,  ..., -1.6850e-03,\n",
      "         -1.3925e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['grocery_store', 'bus', 'home', 'cafe/restaurant']\n",
      "{'audio': tensor([[-0.0032, -0.0075, -0.0095,  ...,  0.0151,  0.0161,  0.0000],\n",
      "        [ 0.0129,  0.0224,  0.0198,  ...,  0.0028,  0.0025,  0.0000],\n",
      "        [-0.0007, -0.0011, -0.0008,  ..., -0.0005, -0.0004,  0.0000],\n",
      "        [-0.0021, -0.0038, -0.0037,  ..., -0.0041, -0.0046,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['train', 'train', 'forest_path', 'car']}\n",
      "tensor([[-0.0032, -0.0075, -0.0095,  ...,  0.0151,  0.0161,  0.0000],\n",
      "        [ 0.0129,  0.0224,  0.0198,  ...,  0.0028,  0.0025,  0.0000],\n",
      "        [-0.0007, -0.0011, -0.0008,  ..., -0.0005, -0.0004,  0.0000],\n",
      "        [-0.0021, -0.0038, -0.0037,  ..., -0.0041, -0.0046,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['train', 'train', 'forest_path', 'car']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                            | 20/324 [00:01<00:24, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 0.0018,  0.0032,  0.0029,  ..., -0.0019, -0.0021,  0.0000],\n",
      "        [-0.0002, -0.0003, -0.0001,  ..., -0.0001, -0.0002,  0.0000],\n",
      "        [ 0.0229,  0.0383,  0.0332,  ..., -0.0084, -0.0099,  0.0000],\n",
      "        [ 0.0007,  0.0024,  0.0015,  ...,  0.0029,  0.0003,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['cafe/restaurant', 'office', 'bus', 'home']}\n",
      "tensor([[ 0.0018,  0.0032,  0.0029,  ..., -0.0019, -0.0021,  0.0000],\n",
      "        [-0.0002, -0.0003, -0.0001,  ..., -0.0001, -0.0002,  0.0000],\n",
      "        [ 0.0229,  0.0383,  0.0332,  ..., -0.0084, -0.0099,  0.0000],\n",
      "        [ 0.0007,  0.0024,  0.0015,  ...,  0.0029,  0.0003,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['cafe/restaurant', 'office', 'bus', 'home']\n",
      "{'audio': tensor([[ 7.1387e-04,  1.2182e-03,  1.0898e-03,  ...,  3.8495e-03,\n",
      "          5.1014e-03,  0.0000e+00],\n",
      "        [-4.0032e-05,  8.6922e-05,  2.3711e-04,  ...,  1.9334e-04,\n",
      "          4.1771e-04,  0.0000e+00],\n",
      "        [ 1.9622e-04,  3.0882e-04, -3.6107e-04,  ..., -5.6995e-04,\n",
      "         -4.3459e-04,  0.0000e+00],\n",
      "        [ 1.9640e-03,  2.2094e-03, -1.4673e-03,  ..., -8.5398e-04,\n",
      "          2.7113e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'home', 'library', 'home']}\n",
      "tensor([[ 7.1387e-04,  1.2182e-03,  1.0898e-03,  ...,  3.8495e-03,\n",
      "          5.1014e-03,  0.0000e+00],\n",
      "        [-4.0032e-05,  8.6922e-05,  2.3711e-04,  ...,  1.9334e-04,\n",
      "          4.1771e-04,  0.0000e+00],\n",
      "        [ 1.9622e-04,  3.0882e-04, -3.6107e-04,  ..., -5.6995e-04,\n",
      "         -4.3459e-04,  0.0000e+00],\n",
      "        [ 1.9640e-03,  2.2094e-03, -1.4673e-03,  ..., -8.5398e-04,\n",
      "          2.7113e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'home', 'library', 'home']\n",
      "{'audio': tensor([[ 4.1571e-05,  1.3997e-04,  2.4575e-04,  ..., -5.7483e-05,\n",
      "          4.6161e-06,  0.0000e+00],\n",
      "        [-4.8306e-02, -8.1443e-02, -7.1950e-02,  ...,  7.8592e-03,\n",
      "          9.2762e-03,  0.0000e+00],\n",
      "        [-4.6809e-03, -4.9667e-03, -1.1551e-03,  ...,  8.0736e-03,\n",
      "          1.0106e-02,  0.0000e+00],\n",
      "        [-9.7928e-03, -1.6246e-02, -1.2732e-02,  ...,  4.2329e-02,\n",
      "          4.8618e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'car', 'metro_station', 'train']}\n",
      "tensor([[ 4.1571e-05,  1.3997e-04,  2.4575e-04,  ..., -5.7483e-05,\n",
      "          4.6161e-06,  0.0000e+00],\n",
      "        [-4.8306e-02, -8.1443e-02, -7.1950e-02,  ...,  7.8592e-03,\n",
      "          9.2762e-03,  0.0000e+00],\n",
      "        [-4.6809e-03, -4.9667e-03, -1.1551e-03,  ...,  8.0736e-03,\n",
      "          1.0106e-02,  0.0000e+00],\n",
      "        [-9.7928e-03, -1.6246e-02, -1.2732e-02,  ...,  4.2329e-02,\n",
      "          4.8618e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'car', 'metro_station', 'train']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                           | 22/324 [00:01<00:23, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 1.0456e-04,  5.6972e-04,  7.4362e-04,  ..., -1.9797e-05,\n",
      "         -3.4515e-05,  0.0000e+00],\n",
      "        [-6.3523e-04, -9.9755e-04, -7.4254e-04,  ...,  1.0414e-03,\n",
      "          8.5526e-04,  0.0000e+00],\n",
      "        [-4.5543e-03, -8.4557e-03, -8.4365e-03,  ..., -2.7297e-03,\n",
      "         -2.6237e-03,  0.0000e+00],\n",
      "        [-2.0339e-04, -3.3966e-04, -3.6760e-04,  ..., -3.3573e-05,\n",
      "         -2.3736e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['cafe/restaurant', 'car', 'train', 'office']}\n",
      "tensor([[ 1.0456e-04,  5.6972e-04,  7.4362e-04,  ..., -1.9797e-05,\n",
      "         -3.4515e-05,  0.0000e+00],\n",
      "        [-6.3523e-04, -9.9755e-04, -7.4254e-04,  ...,  1.0414e-03,\n",
      "          8.5526e-04,  0.0000e+00],\n",
      "        [-4.5543e-03, -8.4557e-03, -8.4365e-03,  ..., -2.7297e-03,\n",
      "         -2.6237e-03,  0.0000e+00],\n",
      "        [-2.0339e-04, -3.3966e-04, -3.6760e-04,  ..., -3.3573e-05,\n",
      "         -2.3736e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['cafe/restaurant', 'car', 'train', 'office']\n",
      "{'audio': tensor([[ 0.0001,  0.0001,  0.0001,  ..., -0.0032, -0.0041,  0.0000],\n",
      "        [ 0.0010,  0.0015,  0.0009,  ...,  0.0030,  0.0035,  0.0000],\n",
      "        [ 0.0044,  0.0074,  0.0060,  ..., -0.0015, -0.0003,  0.0000],\n",
      "        [-0.0057, -0.0081, -0.0056,  ...,  0.0110,  0.0124,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'bus', 'beach', 'tram']}\n",
      "tensor([[ 0.0001,  0.0001,  0.0001,  ..., -0.0032, -0.0041,  0.0000],\n",
      "        [ 0.0010,  0.0015,  0.0009,  ...,  0.0030,  0.0035,  0.0000],\n",
      "        [ 0.0044,  0.0074,  0.0060,  ..., -0.0015, -0.0003,  0.0000],\n",
      "        [-0.0057, -0.0081, -0.0056,  ...,  0.0110,  0.0124,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'bus', 'beach', 'tram']\n",
      "{'audio': tensor([[ 3.1100e-04,  5.1977e-04,  4.5436e-04,  ..., -5.1315e-05,\n",
      "         -3.9081e-05,  0.0000e+00],\n",
      "        [ 1.4375e-03,  2.2979e-03,  1.8807e-03,  ..., -1.4208e-03,\n",
      "         -2.2469e-03,  0.0000e+00],\n",
      "        [ 1.5379e-03,  3.1932e-03,  3.4012e-03,  ..., -5.2731e-02,\n",
      "         -5.9683e-02,  0.0000e+00],\n",
      "        [-7.7424e-04, -1.3165e-03, -1.0976e-03,  ..., -1.0216e-04,\n",
      "         -2.9361e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'metro_station', 'train', 'office']}\n",
      "tensor([[ 3.1100e-04,  5.1977e-04,  4.5436e-04,  ..., -5.1315e-05,\n",
      "         -3.9081e-05,  0.0000e+00],\n",
      "        [ 1.4375e-03,  2.2979e-03,  1.8807e-03,  ..., -1.4208e-03,\n",
      "         -2.2469e-03,  0.0000e+00],\n",
      "        [ 1.5379e-03,  3.1932e-03,  3.4012e-03,  ..., -5.2731e-02,\n",
      "         -5.9683e-02,  0.0000e+00],\n",
      "        [-7.7424e-04, -1.3165e-03, -1.0976e-03,  ..., -1.0216e-04,\n",
      "         -2.9361e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'metro_station', 'train', 'office']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                          | 26/324 [00:02<00:23, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-6.7202e-04, -1.7282e-03, -1.1863e-03,  ..., -6.9840e-04,\n",
      "         -9.3095e-04,  0.0000e+00],\n",
      "        [ 3.0755e-03,  6.1614e-03,  2.9063e-03,  ..., -9.3027e-04,\n",
      "         -1.0930e-03,  0.0000e+00],\n",
      "        [ 1.2248e-05, -2.8301e-05,  7.8967e-05,  ...,  4.5245e-04,\n",
      "          5.4226e-04,  0.0000e+00],\n",
      "        [ 4.6979e-05,  8.7899e-05,  3.1958e-05,  ..., -1.3103e-04,\n",
      "         -2.1819e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'beach', 'library', 'office']}\n",
      "tensor([[-6.7202e-04, -1.7282e-03, -1.1863e-03,  ..., -6.9840e-04,\n",
      "         -9.3095e-04,  0.0000e+00],\n",
      "        [ 3.0755e-03,  6.1614e-03,  2.9063e-03,  ..., -9.3027e-04,\n",
      "         -1.0930e-03,  0.0000e+00],\n",
      "        [ 1.2248e-05, -2.8301e-05,  7.8967e-05,  ...,  4.5245e-04,\n",
      "          5.4226e-04,  0.0000e+00],\n",
      "        [ 4.6979e-05,  8.7899e-05,  3.1958e-05,  ..., -1.3103e-04,\n",
      "         -2.1819e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'beach', 'library', 'office']\n",
      "{'audio': tensor([[-7.9898e-04, -2.9688e-03, -2.7259e-03,  ..., -2.7091e-05,\n",
      "          5.8760e-05,  0.0000e+00],\n",
      "        [-7.9687e-06,  9.4209e-05,  1.4820e-04,  ...,  3.2301e-05,\n",
      "          4.5219e-05,  0.0000e+00],\n",
      "        [-1.5526e-02, -2.9984e-02, -2.4153e-02,  ..., -1.9220e-02,\n",
      "         -3.2045e-02,  0.0000e+00],\n",
      "        [ 4.3490e-03,  7.5051e-03,  6.9500e-03,  ...,  1.6017e-03,\n",
      "          1.6617e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['cafe/restaurant', 'office', 'city_center', 'bus']}\n",
      "tensor([[-7.9898e-04, -2.9688e-03, -2.7259e-03,  ..., -2.7091e-05,\n",
      "          5.8760e-05,  0.0000e+00],\n",
      "        [-7.9687e-06,  9.4209e-05,  1.4820e-04,  ...,  3.2301e-05,\n",
      "          4.5219e-05,  0.0000e+00],\n",
      "        [-1.5526e-02, -2.9984e-02, -2.4153e-02,  ..., -1.9220e-02,\n",
      "         -3.2045e-02,  0.0000e+00],\n",
      "        [ 4.3490e-03,  7.5051e-03,  6.9500e-03,  ...,  1.6017e-03,\n",
      "          1.6617e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['cafe/restaurant', 'office', 'city_center', 'bus']\n",
      "{'audio': tensor([[-8.9533e-04, -1.8997e-03, -2.2582e-03,  ..., -4.6459e-03,\n",
      "         -4.9179e-03,  0.0000e+00],\n",
      "        [ 2.7763e-03,  4.5193e-03,  3.7490e-03,  ...,  4.3464e-03,\n",
      "          4.4730e-03,  0.0000e+00],\n",
      "        [-2.2399e-04, -1.4800e-03, -1.4290e-03,  ...,  1.1232e-02,\n",
      "          5.3317e-03,  0.0000e+00],\n",
      "        [ 1.7886e-04,  3.5758e-04,  1.0909e-04,  ..., -3.1542e-04,\n",
      "          2.0432e-05,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['grocery_store', 'park', 'metro_station', 'library']}\n",
      "tensor([[-8.9533e-04, -1.8997e-03, -2.2582e-03,  ..., -4.6459e-03,\n",
      "         -4.9179e-03,  0.0000e+00],\n",
      "        [ 2.7763e-03,  4.5193e-03,  3.7490e-03,  ...,  4.3464e-03,\n",
      "          4.4730e-03,  0.0000e+00],\n",
      "        [-2.2399e-04, -1.4800e-03, -1.4290e-03,  ...,  1.1232e-02,\n",
      "          5.3317e-03,  0.0000e+00],\n",
      "        [ 1.7886e-04,  3.5758e-04,  1.0909e-04,  ..., -3.1542e-04,\n",
      "          2.0432e-05,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['grocery_store', 'park', 'metro_station', 'library']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                          | 28/324 [00:02<00:23, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 0.0118,  0.0113, -0.0035,  ...,  0.0194,  0.0388,  0.0000],\n",
      "        [-0.0006, -0.0004, -0.0002,  ..., -0.0008, -0.0004,  0.0000],\n",
      "        [ 0.0001,  0.0002,  0.0002,  ...,  0.0001,  0.0001,  0.0000],\n",
      "        [-0.0007, -0.0011, -0.0007,  ..., -0.0004, -0.0004,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['city_center', 'residential_area', 'office', 'forest_path']}\n",
      "tensor([[ 0.0118,  0.0113, -0.0035,  ...,  0.0194,  0.0388,  0.0000],\n",
      "        [-0.0006, -0.0004, -0.0002,  ..., -0.0008, -0.0004,  0.0000],\n",
      "        [ 0.0001,  0.0002,  0.0002,  ...,  0.0001,  0.0001,  0.0000],\n",
      "        [-0.0007, -0.0011, -0.0007,  ..., -0.0004, -0.0004,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['city_center', 'residential_area', 'office', 'forest_path']\n",
      "{'audio': tensor([[-0.0162, -0.0260, -0.0251,  ..., -0.0015, -0.0023,  0.0000],\n",
      "        [ 0.0091,  0.0144,  0.0134,  ..., -0.0063, -0.0073,  0.0000],\n",
      "        [ 0.0003,  0.0004,  0.0003,  ...,  0.0010,  0.0011,  0.0000],\n",
      "        [ 0.0003,  0.0006,  0.0002,  ...,  0.0005,  0.0005,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'tram', 'forest_path', 'library']}\n",
      "tensor([[-0.0162, -0.0260, -0.0251,  ..., -0.0015, -0.0023,  0.0000],\n",
      "        [ 0.0091,  0.0144,  0.0134,  ..., -0.0063, -0.0073,  0.0000],\n",
      "        [ 0.0003,  0.0004,  0.0003,  ...,  0.0010,  0.0011,  0.0000],\n",
      "        [ 0.0003,  0.0006,  0.0002,  ...,  0.0005,  0.0005,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'tram', 'forest_path', 'library']\n",
      "{'audio': tensor([[-1.8347e-03, -2.5425e-03, -1.1660e-03,  ..., -2.5059e-02,\n",
      "         -2.8763e-02,  0.0000e+00],\n",
      "        [ 1.3081e-03,  2.7419e-03,  1.9721e-03,  ..., -7.7298e-03,\n",
      "         -8.7986e-03,  0.0000e+00],\n",
      "        [-1.1902e-03, -2.4771e-03, -2.1570e-03,  ..., -4.7536e-05,\n",
      "         -1.5116e-04,  0.0000e+00],\n",
      "        [ 1.5883e-03, -3.3854e-05, -3.3509e-03,  ...,  7.5480e-04,\n",
      "          1.6818e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'park', 'metro_station', 'home']}\n",
      "tensor([[-1.8347e-03, -2.5425e-03, -1.1660e-03,  ..., -2.5059e-02,\n",
      "         -2.8763e-02,  0.0000e+00],\n",
      "        [ 1.3081e-03,  2.7419e-03,  1.9721e-03,  ..., -7.7298e-03,\n",
      "         -8.7986e-03,  0.0000e+00],\n",
      "        [-1.1902e-03, -2.4771e-03, -2.1570e-03,  ..., -4.7536e-05,\n",
      "         -1.5116e-04,  0.0000e+00],\n",
      "        [ 1.5883e-03, -3.3854e-05, -3.3509e-03,  ...,  7.5480e-04,\n",
      "          1.6818e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'park', 'metro_station', 'home']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                         | 32/324 [00:02<00:22, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 0.0013,  0.0016, -0.0008,  ...,  0.0348,  0.0402,  0.0000],\n",
      "        [ 0.0062,  0.0107,  0.0091,  ..., -0.0186, -0.0192,  0.0000],\n",
      "        [ 0.0262,  0.0442,  0.0321,  ..., -0.0281, -0.0348,  0.0000],\n",
      "        [ 0.0018,  0.0032,  0.0030,  ...,  0.0008,  0.0012,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'residential_area', 'city_center', 'home']}\n",
      "tensor([[ 0.0013,  0.0016, -0.0008,  ...,  0.0348,  0.0402,  0.0000],\n",
      "        [ 0.0062,  0.0107,  0.0091,  ..., -0.0186, -0.0192,  0.0000],\n",
      "        [ 0.0262,  0.0442,  0.0321,  ..., -0.0281, -0.0348,  0.0000],\n",
      "        [ 0.0018,  0.0032,  0.0030,  ...,  0.0008,  0.0012,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'residential_area', 'city_center', 'home']\n",
      "{'audio': tensor([[-2.1605e-05,  4.0666e-05,  1.4191e-04,  ...,  4.4170e-04,\n",
      "          5.8762e-04,  0.0000e+00],\n",
      "        [ 1.6701e-03,  5.3799e-03,  7.4097e-03,  ...,  8.2139e-03,\n",
      "          8.0700e-03,  0.0000e+00],\n",
      "        [-5.0114e-04, -4.6444e-04, -4.4948e-05,  ..., -2.1592e-03,\n",
      "         -2.3499e-03,  0.0000e+00],\n",
      "        [ 6.5120e-04,  6.0889e-04, -1.7147e-04,  ..., -1.3660e-03,\n",
      "          2.4590e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'city_center', 'metro_station', 'residential_area']}\n",
      "tensor([[-2.1605e-05,  4.0666e-05,  1.4191e-04,  ...,  4.4170e-04,\n",
      "          5.8762e-04,  0.0000e+00],\n",
      "        [ 1.6701e-03,  5.3799e-03,  7.4097e-03,  ...,  8.2139e-03,\n",
      "          8.0700e-03,  0.0000e+00],\n",
      "        [-5.0114e-04, -4.6444e-04, -4.4948e-05,  ..., -2.1592e-03,\n",
      "         -2.3499e-03,  0.0000e+00],\n",
      "        [ 6.5120e-04,  6.0889e-04, -1.7147e-04,  ..., -1.3660e-03,\n",
      "          2.4590e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'city_center', 'metro_station', 'residential_area']\n",
      "{'audio': tensor([[ 0.0368,  0.0559,  0.0355,  ..., -0.0254, -0.0363,  0.0000],\n",
      "        [ 0.0005,  0.0008,  0.0019,  ...,  0.0009, -0.0012,  0.0000],\n",
      "        [ 0.0004,  0.0007,  0.0006,  ...,  0.0008,  0.0010,  0.0000],\n",
      "        [-0.0004, -0.0009,  0.0001,  ...,  0.0003,  0.0004,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['city_center', 'city_center', 'forest_path', 'office']}\n",
      "tensor([[ 0.0368,  0.0559,  0.0355,  ..., -0.0254, -0.0363,  0.0000],\n",
      "        [ 0.0005,  0.0008,  0.0019,  ...,  0.0009, -0.0012,  0.0000],\n",
      "        [ 0.0004,  0.0007,  0.0006,  ...,  0.0008,  0.0010,  0.0000],\n",
      "        [-0.0004, -0.0009,  0.0001,  ...,  0.0003,  0.0004,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['city_center', 'city_center', 'forest_path', 'office']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                        | 34/324 [00:02<00:22, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 3.0008e-05,  8.3516e-05,  1.3430e-04,  ...,  3.7243e-04,\n",
      "          7.8138e-05,  0.0000e+00],\n",
      "        [ 1.0882e-06,  6.6537e-05,  3.7023e-05,  ..., -1.4316e-04,\n",
      "         -1.6072e-04,  0.0000e+00],\n",
      "        [-7.2679e-04, -3.1629e-03, -3.5755e-03,  ...,  1.7255e-03,\n",
      "          2.3706e-03,  0.0000e+00],\n",
      "        [ 1.1911e-04, -1.1953e-03,  8.9990e-04,  ...,  9.1994e-04,\n",
      "         -3.7350e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'office', 'grocery_store', 'home']}\n",
      "tensor([[ 3.0008e-05,  8.3516e-05,  1.3430e-04,  ...,  3.7243e-04,\n",
      "          7.8138e-05,  0.0000e+00],\n",
      "        [ 1.0882e-06,  6.6537e-05,  3.7023e-05,  ..., -1.4316e-04,\n",
      "         -1.6072e-04,  0.0000e+00],\n",
      "        [-7.2679e-04, -3.1629e-03, -3.5755e-03,  ...,  1.7255e-03,\n",
      "          2.3706e-03,  0.0000e+00],\n",
      "        [ 1.1911e-04, -1.1953e-03,  8.9990e-04,  ...,  9.1994e-04,\n",
      "         -3.7350e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'office', 'grocery_store', 'home']\n",
      "{'audio': tensor([[ 1.4151e-03,  2.2026e-03,  2.3538e-03,  ...,  3.2992e-04,\n",
      "          7.2009e-04,  0.0000e+00],\n",
      "        [ 1.5193e-04,  3.1024e-04,  3.2665e-04,  ..., -2.3143e-04,\n",
      "         -2.0979e-04,  0.0000e+00],\n",
      "        [-1.5619e-04, -2.8818e-04, -2.2205e-04,  ...,  4.2289e-04,\n",
      "          5.9197e-04,  0.0000e+00],\n",
      "        [ 3.0359e-04,  4.8256e-04,  4.4703e-04,  ...,  1.0732e-04,\n",
      "          6.9648e-05,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['residential_area', 'home', 'metro_station', 'home']}\n",
      "tensor([[ 1.4151e-03,  2.2026e-03,  2.3538e-03,  ...,  3.2992e-04,\n",
      "          7.2009e-04,  0.0000e+00],\n",
      "        [ 1.5193e-04,  3.1024e-04,  3.2665e-04,  ..., -2.3143e-04,\n",
      "         -2.0979e-04,  0.0000e+00],\n",
      "        [-1.5619e-04, -2.8818e-04, -2.2205e-04,  ...,  4.2289e-04,\n",
      "          5.9197e-04,  0.0000e+00],\n",
      "        [ 3.0359e-04,  4.8256e-04,  4.4703e-04,  ...,  1.0732e-04,\n",
      "          6.9648e-05,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['residential_area', 'home', 'metro_station', 'home']\n",
      "{'audio': tensor([[ 1.4730e-03,  2.3514e-03,  2.8325e-03,  ..., -1.8805e-03,\n",
      "         -1.3751e-03,  0.0000e+00],\n",
      "        [-6.5747e-04, -1.0605e-03, -1.2407e-03,  ..., -8.1548e-04,\n",
      "         -9.6046e-04,  0.0000e+00],\n",
      "        [-4.3329e-03, -1.1180e-02, -1.1549e-02,  ...,  1.9223e-02,\n",
      "          2.3661e-02,  0.0000e+00],\n",
      "        [ 3.6767e-05, -8.6717e-07, -2.8831e-04,  ..., -6.6828e-04,\n",
      "         -2.9991e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['metro_station', 'library', 'city_center', 'cafe/restaurant']}\n",
      "tensor([[ 1.4730e-03,  2.3514e-03,  2.8325e-03,  ..., -1.8805e-03,\n",
      "         -1.3751e-03,  0.0000e+00],\n",
      "        [-6.5747e-04, -1.0605e-03, -1.2407e-03,  ..., -8.1548e-04,\n",
      "         -9.6046e-04,  0.0000e+00],\n",
      "        [-4.3329e-03, -1.1180e-02, -1.1549e-02,  ...,  1.9223e-02,\n",
      "          2.3661e-02,  0.0000e+00],\n",
      "        [ 3.6767e-05, -8.6717e-07, -2.8831e-04,  ..., -6.6828e-04,\n",
      "         -2.9991e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['metro_station', 'library', 'city_center', 'cafe/restaurant']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                        | 36/324 [00:02<00:22, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0001, -0.0002, -0.0002,  ...,  0.0004,  0.0006,  0.0000],\n",
      "        [-0.0004, -0.0008, -0.0006,  ..., -0.0100, -0.0086,  0.0000],\n",
      "        [ 0.0018,  0.0019,  0.0011,  ...,  0.0186,  0.0205,  0.0000],\n",
      "        [-0.0005, -0.0008, -0.0006,  ...,  0.0013,  0.0005,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'office', 'tram', 'forest_path']}\n",
      "tensor([[-0.0001, -0.0002, -0.0002,  ...,  0.0004,  0.0006,  0.0000],\n",
      "        [-0.0004, -0.0008, -0.0006,  ..., -0.0100, -0.0086,  0.0000],\n",
      "        [ 0.0018,  0.0019,  0.0011,  ...,  0.0186,  0.0205,  0.0000],\n",
      "        [-0.0005, -0.0008, -0.0006,  ...,  0.0013,  0.0005,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'office', 'tram', 'forest_path']\n",
      "{'audio': tensor([[-1.0588e-03,  3.6582e-04,  2.4836e-03,  ..., -1.2177e-03,\n",
      "         -1.6354e-03,  0.0000e+00],\n",
      "        [-9.4595e-04, -1.6663e-03, -2.9765e-04,  ..., -1.2849e-02,\n",
      "         -1.8617e-02,  0.0000e+00],\n",
      "        [-6.3233e-04, -1.0808e-03, -8.0247e-04,  ...,  2.0473e-04,\n",
      "          5.6351e-05,  0.0000e+00],\n",
      "        [ 7.5451e-04,  1.0320e-03,  4.4970e-04,  ..., -8.0267e-04,\n",
      "         -1.1688e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['grocery_store', 'tram', 'office', 'cafe/restaurant']}\n",
      "tensor([[-1.0588e-03,  3.6582e-04,  2.4836e-03,  ..., -1.2177e-03,\n",
      "         -1.6354e-03,  0.0000e+00],\n",
      "        [-9.4595e-04, -1.6663e-03, -2.9765e-04,  ..., -1.2849e-02,\n",
      "         -1.8617e-02,  0.0000e+00],\n",
      "        [-6.3233e-04, -1.0808e-03, -8.0247e-04,  ...,  2.0473e-04,\n",
      "          5.6351e-05,  0.0000e+00],\n",
      "        [ 7.5451e-04,  1.0320e-03,  4.4970e-04,  ..., -8.0267e-04,\n",
      "         -1.1688e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['grocery_store', 'tram', 'office', 'cafe/restaurant']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                       | 40/324 [00:03<00:23, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-8.4171e-03, -5.9735e-04,  1.7398e-02,  ..., -1.0187e-02,\n",
      "         -1.1438e-02,  0.0000e+00],\n",
      "        [-1.5755e-02, -2.5616e-02, -2.0963e-02,  ..., -3.9192e-02,\n",
      "         -4.5500e-02,  0.0000e+00],\n",
      "        [-6.3642e-05, -5.0940e-05, -6.2148e-03,  ..., -2.7739e-03,\n",
      "         -5.8336e-03,  0.0000e+00],\n",
      "        [-7.2909e-03, -1.4166e-02, -1.5539e-02,  ...,  1.3057e-02,\n",
      "          1.3359e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['city_center', 'train', 'home', 'tram']}\n",
      "tensor([[-8.4171e-03, -5.9735e-04,  1.7398e-02,  ..., -1.0187e-02,\n",
      "         -1.1438e-02,  0.0000e+00],\n",
      "        [-1.5755e-02, -2.5616e-02, -2.0963e-02,  ..., -3.9192e-02,\n",
      "         -4.5500e-02,  0.0000e+00],\n",
      "        [-6.3642e-05, -5.0940e-05, -6.2148e-03,  ..., -2.7739e-03,\n",
      "         -5.8336e-03,  0.0000e+00],\n",
      "        [-7.2909e-03, -1.4166e-02, -1.5539e-02,  ...,  1.3057e-02,\n",
      "          1.3359e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['city_center', 'train', 'home', 'tram']\n",
      "{'audio': tensor([[ 4.9895e-02,  8.0770e-02,  7.1738e-02,  ...,  1.8070e-02,\n",
      "          2.0450e-02,  0.0000e+00],\n",
      "        [ 9.1060e-05, -6.6649e-04,  1.2806e-04,  ..., -1.1001e-03,\n",
      "         -8.1925e-04,  0.0000e+00],\n",
      "        [ 2.8603e-03,  6.2397e-03,  6.7694e-03,  ..., -1.9488e-03,\n",
      "         -1.0806e-03,  0.0000e+00],\n",
      "        [ 3.7450e-03,  7.2646e-03,  6.6125e-03,  ..., -1.4123e-02,\n",
      "         -1.6671e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['train', 'residential_area', 'car', 'bus']}\n",
      "tensor([[ 4.9895e-02,  8.0770e-02,  7.1738e-02,  ...,  1.8070e-02,\n",
      "          2.0450e-02,  0.0000e+00],\n",
      "        [ 9.1060e-05, -6.6649e-04,  1.2806e-04,  ..., -1.1001e-03,\n",
      "         -8.1925e-04,  0.0000e+00],\n",
      "        [ 2.8603e-03,  6.2397e-03,  6.7694e-03,  ..., -1.9488e-03,\n",
      "         -1.0806e-03,  0.0000e+00],\n",
      "        [ 3.7450e-03,  7.2646e-03,  6.6125e-03,  ..., -1.4123e-02,\n",
      "         -1.6671e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['train', 'residential_area', 'car', 'bus']\n",
      "{'audio': tensor([[ 1.0725e-03,  1.2530e-03,  8.7703e-04,  ...,  5.1454e-03,\n",
      "          6.1728e-03,  0.0000e+00],\n",
      "        [-3.7776e-04, -6.0994e-04, -3.0574e-04,  ...,  1.6839e-03,\n",
      "          2.1668e-03,  0.0000e+00],\n",
      "        [ 2.8975e-03,  5.5824e-03,  5.4879e-03,  ..., -2.5722e-03,\n",
      "         -3.9122e-03,  0.0000e+00],\n",
      "        [ 3.5780e-05, -6.8100e-04, -1.3946e-03,  ...,  4.9234e-03,\n",
      "          4.3804e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['beach', 'forest_path', 'park', 'cafe/restaurant']}\n",
      "tensor([[ 1.0725e-03,  1.2530e-03,  8.7703e-04,  ...,  5.1454e-03,\n",
      "          6.1728e-03,  0.0000e+00],\n",
      "        [-3.7776e-04, -6.0994e-04, -3.0574e-04,  ...,  1.6839e-03,\n",
      "          2.1668e-03,  0.0000e+00],\n",
      "        [ 2.8975e-03,  5.5824e-03,  5.4879e-03,  ..., -2.5722e-03,\n",
      "         -3.9122e-03,  0.0000e+00],\n",
      "        [ 3.5780e-05, -6.8100e-04, -1.3946e-03,  ...,  4.9234e-03,\n",
      "          4.3804e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['beach', 'forest_path', 'park', 'cafe/restaurant']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                      | 42/324 [00:03<00:22, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0002, -0.0001,  0.0003,  ..., -0.0001, -0.0006,  0.0000],\n",
      "        [-0.0010, -0.0016, -0.0011,  ..., -0.0008, -0.0009,  0.0000],\n",
      "        [ 0.0538,  0.0843,  0.0653,  ...,  0.0496,  0.0524,  0.0000],\n",
      "        [-0.0004, -0.0006, -0.0007,  ...,  0.0007,  0.0018,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['residential_area', 'forest_path', 'tram', 'park']}\n",
      "tensor([[-0.0002, -0.0001,  0.0003,  ..., -0.0001, -0.0006,  0.0000],\n",
      "        [-0.0010, -0.0016, -0.0011,  ..., -0.0008, -0.0009,  0.0000],\n",
      "        [ 0.0538,  0.0843,  0.0653,  ...,  0.0496,  0.0524,  0.0000],\n",
      "        [-0.0004, -0.0006, -0.0007,  ...,  0.0007,  0.0018,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['residential_area', 'forest_path', 'tram', 'park']\n",
      "{'audio': tensor([[ 3.0741e-04,  6.5529e-04,  6.9601e-04,  ..., -1.4189e-03,\n",
      "         -1.5949e-03,  0.0000e+00],\n",
      "        [ 2.9158e-03,  5.0830e-03,  3.4957e-03,  ..., -4.2555e-04,\n",
      "          9.2919e-04,  0.0000e+00],\n",
      "        [-1.2573e-05,  1.1557e-04,  3.2965e-04,  ..., -7.1654e-04,\n",
      "         -4.1027e-04,  0.0000e+00],\n",
      "        [-6.1633e-02, -1.0208e-01, -8.6840e-02,  ...,  2.2586e-02,\n",
      "          2.3102e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'cafe/restaurant', 'forest_path', 'train']}\n",
      "tensor([[ 3.0741e-04,  6.5529e-04,  6.9601e-04,  ..., -1.4189e-03,\n",
      "         -1.5949e-03,  0.0000e+00],\n",
      "        [ 2.9158e-03,  5.0830e-03,  3.4957e-03,  ..., -4.2555e-04,\n",
      "          9.2919e-04,  0.0000e+00],\n",
      "        [-1.2573e-05,  1.1557e-04,  3.2965e-04,  ..., -7.1654e-04,\n",
      "         -4.1027e-04,  0.0000e+00],\n",
      "        [-6.1633e-02, -1.0208e-01, -8.6840e-02,  ...,  2.2586e-02,\n",
      "          2.3102e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'cafe/restaurant', 'forest_path', 'train']\n",
      "{'audio': tensor([[-4.6851e-03, -8.3659e-03, -7.3663e-03,  ...,  1.5926e-03,\n",
      "          1.2079e-03,  0.0000e+00],\n",
      "        [ 6.0779e-05,  9.1117e-05,  6.0322e-05,  ..., -2.3569e-05,\n",
      "         -2.0629e-05,  0.0000e+00],\n",
      "        [ 3.1765e-03,  9.3555e-04, -1.9857e-03,  ..., -3.0859e-03,\n",
      "         -2.8658e-04,  0.0000e+00],\n",
      "        [ 2.0414e-03,  3.4412e-03,  3.1185e-03,  ..., -1.5494e-03,\n",
      "         -2.1929e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'home', 'home', 'park']}\n",
      "tensor([[-4.6851e-03, -8.3659e-03, -7.3663e-03,  ...,  1.5926e-03,\n",
      "          1.2079e-03,  0.0000e+00],\n",
      "        [ 6.0779e-05,  9.1117e-05,  6.0322e-05,  ..., -2.3569e-05,\n",
      "         -2.0629e-05,  0.0000e+00],\n",
      "        [ 3.1765e-03,  9.3555e-04, -1.9857e-03,  ..., -3.0859e-03,\n",
      "         -2.8658e-04,  0.0000e+00],\n",
      "        [ 2.0414e-03,  3.4412e-03,  3.1185e-03,  ..., -1.5494e-03,\n",
      "         -2.1929e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'home', 'home', 'park']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                     | 46/324 [00:03<00:21, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0016, -0.0026, -0.0014,  ..., -0.0015, -0.0041,  0.0000],\n",
      "        [-0.0270, -0.0441, -0.0373,  ...,  0.0088,  0.0110,  0.0000],\n",
      "        [-0.0045, -0.0072, -0.0040,  ..., -0.0078, -0.0111,  0.0000],\n",
      "        [-0.0010, -0.0016, -0.0011,  ...,  0.0022,  0.0025,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'train', 'cafe/restaurant', 'grocery_store']}\n",
      "tensor([[-0.0016, -0.0026, -0.0014,  ..., -0.0015, -0.0041,  0.0000],\n",
      "        [-0.0270, -0.0441, -0.0373,  ...,  0.0088,  0.0110,  0.0000],\n",
      "        [-0.0045, -0.0072, -0.0040,  ..., -0.0078, -0.0111,  0.0000],\n",
      "        [-0.0010, -0.0016, -0.0011,  ...,  0.0022,  0.0025,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'train', 'cafe/restaurant', 'grocery_store']\n",
      "{'audio': tensor([[-0.0030, -0.0051, -0.0046,  ..., -0.0003, -0.0018,  0.0000],\n",
      "        [ 0.0001,  0.0003, -0.0005,  ..., -0.0012,  0.0008,  0.0000],\n",
      "        [ 0.0015,  0.0015,  0.0013,  ...,  0.0065,  0.0067,  0.0000],\n",
      "        [-0.0004, -0.0009, -0.0009,  ..., -0.0007, -0.0007,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'home', 'cafe/restaurant', 'library']}\n",
      "tensor([[-0.0030, -0.0051, -0.0046,  ..., -0.0003, -0.0018,  0.0000],\n",
      "        [ 0.0001,  0.0003, -0.0005,  ..., -0.0012,  0.0008,  0.0000],\n",
      "        [ 0.0015,  0.0015,  0.0013,  ...,  0.0065,  0.0067,  0.0000],\n",
      "        [-0.0004, -0.0009, -0.0009,  ..., -0.0007, -0.0007,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'home', 'cafe/restaurant', 'library']\n",
      "{'audio': tensor([[-0.0009, -0.0027, -0.0033,  ...,  0.0024,  0.0023,  0.0000],\n",
      "        [ 0.0003,  0.0005,  0.0005,  ...,  0.0013,  0.0013,  0.0000],\n",
      "        [ 0.0054,  0.0072,  0.0027,  ...,  0.0062,  0.0069,  0.0000],\n",
      "        [ 0.0051,  0.0085,  0.0081,  ..., -0.0581, -0.0674,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['city_center', 'forest_path', 'residential_area', 'bus']}\n",
      "tensor([[-0.0009, -0.0027, -0.0033,  ...,  0.0024,  0.0023,  0.0000],\n",
      "        [ 0.0003,  0.0005,  0.0005,  ...,  0.0013,  0.0013,  0.0000],\n",
      "        [ 0.0054,  0.0072,  0.0027,  ...,  0.0062,  0.0069,  0.0000],\n",
      "        [ 0.0051,  0.0085,  0.0081,  ..., -0.0581, -0.0674,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['city_center', 'forest_path', 'residential_area', 'bus']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                     | 48/324 [00:03<00:20, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 0.0077,  0.0113,  0.0084,  ...,  0.0029,  0.0023,  0.0000],\n",
      "        [-0.0024, -0.0028, -0.0027,  ..., -0.0011, -0.0004,  0.0000],\n",
      "        [-0.0037, -0.0071, -0.0082,  ...,  0.0035,  0.0038,  0.0000],\n",
      "        [-0.0007, -0.0021, -0.0008,  ..., -0.0019, -0.0018,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['tram', 'car', 'metro_station', 'residential_area']}\n",
      "tensor([[ 0.0077,  0.0113,  0.0084,  ...,  0.0029,  0.0023,  0.0000],\n",
      "        [-0.0024, -0.0028, -0.0027,  ..., -0.0011, -0.0004,  0.0000],\n",
      "        [-0.0037, -0.0071, -0.0082,  ...,  0.0035,  0.0038,  0.0000],\n",
      "        [-0.0007, -0.0021, -0.0008,  ..., -0.0019, -0.0018,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['tram', 'car', 'metro_station', 'residential_area']\n",
      "{'audio': tensor([[ 6.1457e-03,  1.0320e-02,  9.1478e-03,  ...,  1.8629e-02,\n",
      "          2.1425e-02,  0.0000e+00],\n",
      "        [-5.5775e-03, -9.2519e-03, -8.8833e-03,  ...,  3.5871e-03,\n",
      "          1.2101e-03,  0.0000e+00],\n",
      "        [-7.8598e-05, -1.3657e-04, -1.1806e-04,  ...,  8.3226e-05,\n",
      "          1.0837e-04,  0.0000e+00],\n",
      "        [ 8.9910e-05,  8.1268e-05,  2.9321e-05,  ..., -4.3438e-06,\n",
      "         -3.3531e-05,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'grocery_store', 'home', 'office']}\n",
      "tensor([[ 6.1457e-03,  1.0320e-02,  9.1478e-03,  ...,  1.8629e-02,\n",
      "          2.1425e-02,  0.0000e+00],\n",
      "        [-5.5775e-03, -9.2519e-03, -8.8833e-03,  ...,  3.5871e-03,\n",
      "          1.2101e-03,  0.0000e+00],\n",
      "        [-7.8598e-05, -1.3657e-04, -1.1806e-04,  ...,  8.3226e-05,\n",
      "          1.0837e-04,  0.0000e+00],\n",
      "        [ 8.9910e-05,  8.1268e-05,  2.9321e-05,  ..., -4.3438e-06,\n",
      "         -3.3531e-05,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'grocery_store', 'home', 'office']\n",
      "{'audio': tensor([[ 0.0002, -0.0008, -0.0011,  ..., -0.0042, -0.0034,  0.0000],\n",
      "        [-0.0002, -0.0004, -0.0004,  ...,  0.0004,  0.0005,  0.0000],\n",
      "        [-0.0015, -0.0023, -0.0019,  ...,  0.0007,  0.0021,  0.0000],\n",
      "        [-0.0004, -0.0005,  0.0001,  ..., -0.0018, -0.0019,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'forest_path', 'park', 'residential_area']}\n",
      "tensor([[ 0.0002, -0.0008, -0.0011,  ..., -0.0042, -0.0034,  0.0000],\n",
      "        [-0.0002, -0.0004, -0.0004,  ...,  0.0004,  0.0005,  0.0000],\n",
      "        [-0.0015, -0.0023, -0.0019,  ...,  0.0007,  0.0021,  0.0000],\n",
      "        [-0.0004, -0.0005,  0.0001,  ..., -0.0018, -0.0019,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'forest_path', 'park', 'residential_area']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                    | 52/324 [00:04<00:20, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0430, -0.0712, -0.0617,  ..., -0.0182, -0.0152,  0.0000],\n",
      "        [-0.0059, -0.0097, -0.0085,  ..., -0.0010, -0.0008,  0.0000],\n",
      "        [-0.0001,  0.0012,  0.0010,  ...,  0.0005, -0.0122,  0.0000],\n",
      "        [-0.0198, -0.0322, -0.0280,  ...,  0.0259,  0.0303,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'train', 'cafe/restaurant', 'tram']}\n",
      "tensor([[-0.0430, -0.0712, -0.0617,  ..., -0.0182, -0.0152,  0.0000],\n",
      "        [-0.0059, -0.0097, -0.0085,  ..., -0.0010, -0.0008,  0.0000],\n",
      "        [-0.0001,  0.0012,  0.0010,  ...,  0.0005, -0.0122,  0.0000],\n",
      "        [-0.0198, -0.0322, -0.0280,  ...,  0.0259,  0.0303,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'train', 'cafe/restaurant', 'tram']\n",
      "{'audio': tensor([[-6.5961e-05,  8.7274e-05,  3.6109e-04,  ...,  4.0368e-04,\n",
      "          4.3289e-04,  0.0000e+00],\n",
      "        [ 6.5132e-04,  8.8496e-04,  4.4306e-04,  ...,  3.3260e-03,\n",
      "          3.9672e-03,  0.0000e+00],\n",
      "        [-1.2042e-04, -4.3792e-04, -4.9851e-04,  ...,  8.2170e-04,\n",
      "          8.2889e-04,  0.0000e+00],\n",
      "        [ 4.7334e-03,  8.1121e-03,  7.8489e-03,  ..., -1.6068e-03,\n",
      "         -7.7888e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'forest_path', 'cafe/restaurant', 'city_center']}\n",
      "tensor([[-6.5961e-05,  8.7274e-05,  3.6109e-04,  ...,  4.0368e-04,\n",
      "          4.3289e-04,  0.0000e+00],\n",
      "        [ 6.5132e-04,  8.8496e-04,  4.4306e-04,  ...,  3.3260e-03,\n",
      "          3.9672e-03,  0.0000e+00],\n",
      "        [-1.2042e-04, -4.3792e-04, -4.9851e-04,  ...,  8.2170e-04,\n",
      "          8.2889e-04,  0.0000e+00],\n",
      "        [ 4.7334e-03,  8.1121e-03,  7.8489e-03,  ..., -1.6068e-03,\n",
      "         -7.7888e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'forest_path', 'cafe/restaurant', 'city_center']\n",
      "{'audio': tensor([[-3.1752e-05, -5.8268e-05,  1.3557e-05,  ...,  1.1772e-04,\n",
      "          1.5547e-04,  0.0000e+00],\n",
      "        [ 3.6731e-03,  5.3148e-03,  4.3093e-03,  ...,  5.3611e-05,\n",
      "          1.1082e-03,  0.0000e+00],\n",
      "        [-1.2985e-02, -2.2290e-02, -1.7223e-02,  ..., -3.2240e-03,\n",
      "         -3.7057e-03,  0.0000e+00],\n",
      "        [ 3.0316e-04,  5.5434e-04,  3.5697e-04,  ..., -5.2110e-04,\n",
      "         -4.3704e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'grocery_store', 'metro_station', 'office']}\n",
      "tensor([[-3.1752e-05, -5.8268e-05,  1.3557e-05,  ...,  1.1772e-04,\n",
      "          1.5547e-04,  0.0000e+00],\n",
      "        [ 3.6731e-03,  5.3148e-03,  4.3093e-03,  ...,  5.3611e-05,\n",
      "          1.1082e-03,  0.0000e+00],\n",
      "        [-1.2985e-02, -2.2290e-02, -1.7223e-02,  ..., -3.2240e-03,\n",
      "         -3.7057e-03,  0.0000e+00],\n",
      "        [ 3.0316e-04,  5.5434e-04,  3.5697e-04,  ..., -5.2110e-04,\n",
      "         -4.3704e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'grocery_store', 'metro_station', 'office']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                   | 54/324 [00:04<00:20, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0016, -0.0037, -0.0038,  ..., -0.0037, -0.0032,  0.0000],\n",
      "        [-0.0014, -0.0022, -0.0018,  ...,  0.0028,  0.0045,  0.0000],\n",
      "        [ 0.0029,  0.0040,  0.0016,  ..., -0.0018, -0.0028,  0.0000],\n",
      "        [ 0.0013,  0.0018,  0.0010,  ..., -0.0004,  0.0005,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['beach', 'park', 'grocery_store', 'cafe/restaurant']}\n",
      "tensor([[-0.0016, -0.0037, -0.0038,  ..., -0.0037, -0.0032,  0.0000],\n",
      "        [-0.0014, -0.0022, -0.0018,  ...,  0.0028,  0.0045,  0.0000],\n",
      "        [ 0.0029,  0.0040,  0.0016,  ..., -0.0018, -0.0028,  0.0000],\n",
      "        [ 0.0013,  0.0018,  0.0010,  ..., -0.0004,  0.0005,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['beach', 'park', 'grocery_store', 'cafe/restaurant']\n",
      "{'audio': tensor([[ 3.4004e-04,  8.5960e-05, -2.7312e-04,  ..., -5.0116e-04,\n",
      "         -3.6932e-04,  0.0000e+00],\n",
      "        [ 1.2410e-03,  1.2137e-03,  2.0229e-03,  ..., -6.0329e-03,\n",
      "         -6.1455e-03,  0.0000e+00],\n",
      "        [ 3.9622e-03,  6.9426e-03,  6.4455e-03,  ..., -4.4612e-04,\n",
      "         -1.2940e-03,  0.0000e+00],\n",
      "        [ 1.0263e-05,  4.9919e-07,  3.0416e-05,  ...,  1.8481e-04,\n",
      "          2.8934e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['grocery_store', 'city_center', 'grocery_store', 'office']}\n",
      "tensor([[ 3.4004e-04,  8.5960e-05, -2.7312e-04,  ..., -5.0116e-04,\n",
      "         -3.6932e-04,  0.0000e+00],\n",
      "        [ 1.2410e-03,  1.2137e-03,  2.0229e-03,  ..., -6.0329e-03,\n",
      "         -6.1455e-03,  0.0000e+00],\n",
      "        [ 3.9622e-03,  6.9426e-03,  6.4455e-03,  ..., -4.4612e-04,\n",
      "         -1.2940e-03,  0.0000e+00],\n",
      "        [ 1.0263e-05,  4.9919e-07,  3.0416e-05,  ...,  1.8481e-04,\n",
      "          2.8934e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['grocery_store', 'city_center', 'grocery_store', 'office']\n",
      "{'audio': tensor([[-3.4728e-05, -2.2404e-04, -3.1241e-04,  ...,  1.3416e-04,\n",
      "          2.3005e-04,  0.0000e+00],\n",
      "        [-8.3810e-04, -1.2936e-03, -9.4187e-04,  ..., -8.2801e-04,\n",
      "         -1.0759e-03,  0.0000e+00],\n",
      "        [ 6.9275e-06, -3.7507e-05, -5.8116e-06,  ...,  2.0074e-04,\n",
      "          2.2467e-04,  0.0000e+00],\n",
      "        [-6.9143e-04, -1.2299e-03, -1.0680e-03,  ..., -9.9705e-04,\n",
      "         -1.1147e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'library', 'home', 'library']}\n",
      "tensor([[-3.4728e-05, -2.2404e-04, -3.1241e-04,  ...,  1.3416e-04,\n",
      "          2.3005e-04,  0.0000e+00],\n",
      "        [-8.3810e-04, -1.2936e-03, -9.4187e-04,  ..., -8.2801e-04,\n",
      "         -1.0759e-03,  0.0000e+00],\n",
      "        [ 6.9275e-06, -3.7507e-05, -5.8116e-06,  ...,  2.0074e-04,\n",
      "          2.2467e-04,  0.0000e+00],\n",
      "        [-6.9143e-04, -1.2299e-03, -1.0680e-03,  ..., -9.9705e-04,\n",
      "         -1.1147e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'library', 'home', 'library']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                  | 58/324 [00:04<00:20, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0206, -0.0349, -0.0302,  ..., -0.0222, -0.0263,  0.0000],\n",
      "        [-0.0009, -0.0013, -0.0008,  ...,  0.0052,  0.0068,  0.0000],\n",
      "        [-0.0020, -0.0043, -0.0088,  ...,  0.0003,  0.0008,  0.0000],\n",
      "        [ 0.0007,  0.0012,  0.0010,  ..., -0.0011, -0.0013,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'grocery_store', 'metro_station', 'metro_station']}\n",
      "tensor([[-0.0206, -0.0349, -0.0302,  ..., -0.0222, -0.0263,  0.0000],\n",
      "        [-0.0009, -0.0013, -0.0008,  ...,  0.0052,  0.0068,  0.0000],\n",
      "        [-0.0020, -0.0043, -0.0088,  ...,  0.0003,  0.0008,  0.0000],\n",
      "        [ 0.0007,  0.0012,  0.0010,  ..., -0.0011, -0.0013,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'grocery_store', 'metro_station', 'metro_station']\n",
      "{'audio': tensor([[ 0.0005,  0.0008,  0.0007,  ..., -0.0002, -0.0003,  0.0000],\n",
      "        [ 0.0084,  0.0131,  0.0101,  ...,  0.0178,  0.0209,  0.0000],\n",
      "        [ 0.0020,  0.0036,  0.0048,  ...,  0.0029,  0.0044,  0.0000],\n",
      "        [ 0.0076,  0.0090,  0.0016,  ...,  0.0178,  0.0227,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'car', 'city_center', 'tram']}\n",
      "tensor([[ 0.0005,  0.0008,  0.0007,  ..., -0.0002, -0.0003,  0.0000],\n",
      "        [ 0.0084,  0.0131,  0.0101,  ...,  0.0178,  0.0209,  0.0000],\n",
      "        [ 0.0020,  0.0036,  0.0048,  ...,  0.0029,  0.0044,  0.0000],\n",
      "        [ 0.0076,  0.0090,  0.0016,  ...,  0.0178,  0.0227,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'car', 'city_center', 'tram']\n",
      "{'audio': tensor([[-1.8109e-04, -4.0275e-04, -5.4027e-04,  ...,  1.1011e-04,\n",
      "          9.4464e-05,  0.0000e+00],\n",
      "        [-4.9870e-04, -1.1199e-03, -1.0375e-03,  ..., -6.9575e-04,\n",
      "         -7.3165e-04,  0.0000e+00],\n",
      "        [ 6.9161e-04,  8.7766e-04,  6.3856e-04,  ...,  7.0361e-04,\n",
      "          8.4827e-04,  0.0000e+00],\n",
      "        [ 4.9232e-04,  4.7934e-04,  3.5083e-04,  ..., -7.2134e-06,\n",
      "         -5.9527e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'library', 'grocery_store', 'home']}\n",
      "tensor([[-1.8109e-04, -4.0275e-04, -5.4027e-04,  ...,  1.1011e-04,\n",
      "          9.4464e-05,  0.0000e+00],\n",
      "        [-4.9870e-04, -1.1199e-03, -1.0375e-03,  ..., -6.9575e-04,\n",
      "         -7.3165e-04,  0.0000e+00],\n",
      "        [ 6.9161e-04,  8.7766e-04,  6.3856e-04,  ...,  7.0361e-04,\n",
      "          8.4827e-04,  0.0000e+00],\n",
      "        [ 4.9232e-04,  4.7934e-04,  3.5083e-04,  ..., -7.2134e-06,\n",
      "         -5.9527e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'library', 'grocery_store', 'home']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                  | 60/324 [00:04<00:20, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 2.2392e-03,  9.7977e-03,  1.9135e-02,  ..., -1.2456e-01,\n",
      "         -1.3938e-01,  0.0000e+00],\n",
      "        [-7.4062e-03, -4.5045e-03,  1.1761e-03,  ...,  1.5027e-03,\n",
      "          6.3159e-04,  0.0000e+00],\n",
      "        [-1.5595e-03, -2.3513e-03, -1.7416e-03,  ..., -2.9630e-04,\n",
      "         -6.0850e-04,  0.0000e+00],\n",
      "        [ 7.0284e-05,  9.8511e-05,  8.2642e-05,  ...,  7.0693e-05,\n",
      "          8.8125e-05,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['tram', 'residential_area', 'park', 'office']}\n",
      "tensor([[ 2.2392e-03,  9.7977e-03,  1.9135e-02,  ..., -1.2456e-01,\n",
      "         -1.3938e-01,  0.0000e+00],\n",
      "        [-7.4062e-03, -4.5045e-03,  1.1761e-03,  ...,  1.5027e-03,\n",
      "          6.3159e-04,  0.0000e+00],\n",
      "        [-1.5595e-03, -2.3513e-03, -1.7416e-03,  ..., -2.9630e-04,\n",
      "         -6.0850e-04,  0.0000e+00],\n",
      "        [ 7.0284e-05,  9.8511e-05,  8.2642e-05,  ...,  7.0693e-05,\n",
      "          8.8125e-05,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['tram', 'residential_area', 'park', 'office']\n",
      "{'audio': tensor([[ 1.6998e-04,  1.8177e-04,  5.3086e-04,  ...,  1.9405e-03,\n",
      "          1.6647e-03,  0.0000e+00],\n",
      "        [ 2.0471e-04,  2.4389e-04,  4.4711e-05,  ..., -3.4175e-03,\n",
      "         -3.5701e-03,  0.0000e+00],\n",
      "        [-1.6390e-03, -1.2903e-03, -1.1189e-03,  ..., -2.9045e-03,\n",
      "         -4.0236e-03,  0.0000e+00],\n",
      "        [ 6.5105e-03,  1.1538e-02,  8.2927e-03,  ...,  4.3876e-03,\n",
      "          2.8777e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'cafe/restaurant', 'metro_station', 'grocery_store']}\n",
      "tensor([[ 1.6998e-04,  1.8177e-04,  5.3086e-04,  ...,  1.9405e-03,\n",
      "          1.6647e-03,  0.0000e+00],\n",
      "        [ 2.0471e-04,  2.4389e-04,  4.4711e-05,  ..., -3.4175e-03,\n",
      "         -3.5701e-03,  0.0000e+00],\n",
      "        [-1.6390e-03, -1.2903e-03, -1.1189e-03,  ..., -2.9045e-03,\n",
      "         -4.0236e-03,  0.0000e+00],\n",
      "        [ 6.5105e-03,  1.1538e-02,  8.2927e-03,  ...,  4.3876e-03,\n",
      "          2.8777e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'cafe/restaurant', 'metro_station', 'grocery_store']\n",
      "{'audio': tensor([[ 0.0030,  0.0049,  0.0035,  ...,  0.0045,  0.0049,  0.0000],\n",
      "        [ 0.0079,  0.0135,  0.0126,  ...,  0.0553,  0.0615,  0.0000],\n",
      "        [-0.0009, -0.0013, -0.0011,  ..., -0.0013, -0.0015,  0.0000],\n",
      "        [ 0.0047,  0.0086,  0.0082,  ..., -0.0185, -0.0205,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['cafe/restaurant', 'bus', 'library', 'city_center']}\n",
      "tensor([[ 0.0030,  0.0049,  0.0035,  ...,  0.0045,  0.0049,  0.0000],\n",
      "        [ 0.0079,  0.0135,  0.0126,  ...,  0.0553,  0.0615,  0.0000],\n",
      "        [-0.0009, -0.0013, -0.0011,  ..., -0.0013, -0.0015,  0.0000],\n",
      "        [ 0.0047,  0.0086,  0.0082,  ..., -0.0185, -0.0205,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['cafe/restaurant', 'bus', 'library', 'city_center']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                 | 64/324 [00:05<00:20, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 2.0775e-04,  2.4410e-04,  1.1138e-04,  ...,  1.1329e-03,\n",
      "          1.2883e-03,  0.0000e+00],\n",
      "        [-1.4409e-04, -2.4224e-04, -6.5595e-05,  ...,  3.7630e-04,\n",
      "          2.5309e-04,  0.0000e+00],\n",
      "        [ 6.3125e-04,  1.1190e-03,  9.9338e-04,  ..., -7.3846e-04,\n",
      "         -6.7214e-04,  0.0000e+00],\n",
      "        [ 2.3420e-03,  4.1658e-03,  8.9662e-04,  ...,  3.2036e-03,\n",
      "          4.3049e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'forest_path', 'home', 'park']}\n",
      "tensor([[ 2.0775e-04,  2.4410e-04,  1.1138e-04,  ...,  1.1329e-03,\n",
      "          1.2883e-03,  0.0000e+00],\n",
      "        [-1.4409e-04, -2.4224e-04, -6.5595e-05,  ...,  3.7630e-04,\n",
      "          2.5309e-04,  0.0000e+00],\n",
      "        [ 6.3125e-04,  1.1190e-03,  9.9338e-04,  ..., -7.3846e-04,\n",
      "         -6.7214e-04,  0.0000e+00],\n",
      "        [ 2.3420e-03,  4.1658e-03,  8.9662e-04,  ...,  3.2036e-03,\n",
      "          4.3049e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'forest_path', 'home', 'park']\n",
      "{'audio': tensor([[-4.8592e-03, -6.3931e-03,  1.3773e-03,  ..., -1.2055e-03,\n",
      "         -1.5225e-03,  0.0000e+00],\n",
      "        [-1.5898e-02, -2.5825e-02, -2.1792e-02,  ..., -7.4729e-03,\n",
      "         -6.8353e-03,  0.0000e+00],\n",
      "        [ 1.4709e-02,  2.5341e-02,  2.2558e-02,  ...,  1.4585e-02,\n",
      "          1.6031e-02,  0.0000e+00],\n",
      "        [ 1.9012e-05,  2.0740e-05,  9.3926e-06,  ...,  8.6557e-06,\n",
      "          9.4024e-05,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['residential_area', 'grocery_store', 'bus', 'office']}\n",
      "tensor([[-4.8592e-03, -6.3931e-03,  1.3773e-03,  ..., -1.2055e-03,\n",
      "         -1.5225e-03,  0.0000e+00],\n",
      "        [-1.5898e-02, -2.5825e-02, -2.1792e-02,  ..., -7.4729e-03,\n",
      "         -6.8353e-03,  0.0000e+00],\n",
      "        [ 1.4709e-02,  2.5341e-02,  2.2558e-02,  ...,  1.4585e-02,\n",
      "          1.6031e-02,  0.0000e+00],\n",
      "        [ 1.9012e-05,  2.0740e-05,  9.3926e-06,  ...,  8.6557e-06,\n",
      "          9.4024e-05,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['residential_area', 'grocery_store', 'bus', 'office']\n",
      "{'audio': tensor([[ 4.6063e-05, -1.4133e-03, -2.7816e-03,  ..., -9.3138e-04,\n",
      "         -1.4768e-03,  0.0000e+00],\n",
      "        [-7.6840e-03, -1.2638e-02, -1.0722e-02,  ..., -4.4121e-02,\n",
      "         -5.1875e-02,  0.0000e+00],\n",
      "        [ 5.4236e-04,  1.0137e-03,  9.8296e-04,  ..., -1.7253e-04,\n",
      "         -1.0468e-04,  0.0000e+00],\n",
      "        [ 1.6238e-04, -4.3360e-05, -2.5592e-04,  ...,  5.8323e-04,\n",
      "          5.3947e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['metro_station', 'car', 'library', 'forest_path']}\n",
      "tensor([[ 4.6063e-05, -1.4133e-03, -2.7816e-03,  ..., -9.3138e-04,\n",
      "         -1.4768e-03,  0.0000e+00],\n",
      "        [-7.6840e-03, -1.2638e-02, -1.0722e-02,  ..., -4.4121e-02,\n",
      "         -5.1875e-02,  0.0000e+00],\n",
      "        [ 5.4236e-04,  1.0137e-03,  9.8296e-04,  ..., -1.7253e-04,\n",
      "         -1.0468e-04,  0.0000e+00],\n",
      "        [ 1.6238e-04, -4.3360e-05, -2.5592e-04,  ...,  5.8323e-04,\n",
      "          5.3947e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['metro_station', 'car', 'library', 'forest_path']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                | 66/324 [00:05<00:22, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0008, -0.0018, -0.0020,  ...,  0.0015,  0.0018,  0.0000],\n",
      "        [-0.0028, -0.0036, -0.0025,  ..., -0.0027,  0.0005,  0.0000],\n",
      "        [ 0.0003,  0.0005,  0.0005,  ...,  0.0012, -0.0021,  0.0000],\n",
      "        [ 0.0032,  0.0056,  0.0054,  ...,  0.0003, -0.0032,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'city_center', 'metro_station', 'park']}\n",
      "tensor([[-0.0008, -0.0018, -0.0020,  ...,  0.0015,  0.0018,  0.0000],\n",
      "        [-0.0028, -0.0036, -0.0025,  ..., -0.0027,  0.0005,  0.0000],\n",
      "        [ 0.0003,  0.0005,  0.0005,  ...,  0.0012, -0.0021,  0.0000],\n",
      "        [ 0.0032,  0.0056,  0.0054,  ...,  0.0003, -0.0032,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'city_center', 'metro_station', 'park']\n",
      "{'audio': tensor([[-8.0714e-03, -1.3554e-02, -1.2040e-02,  ..., -1.6144e-02,\n",
      "         -1.8742e-02,  0.0000e+00],\n",
      "        [ 5.9277e-04,  9.9877e-04,  9.1179e-04,  ...,  7.8388e-04,\n",
      "          7.6160e-04,  0.0000e+00],\n",
      "        [ 1.9607e-05,  1.1307e-03,  2.1732e-03,  ...,  7.0178e-03,\n",
      "          5.2113e-04,  0.0000e+00],\n",
      "        [-1.1489e-06, -1.4811e-03, -2.7933e-03,  ...,  2.2761e-03,\n",
      "          3.3733e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['train', 'park', 'beach', 'beach']}\n",
      "tensor([[-8.0714e-03, -1.3554e-02, -1.2040e-02,  ..., -1.6144e-02,\n",
      "         -1.8742e-02,  0.0000e+00],\n",
      "        [ 5.9277e-04,  9.9877e-04,  9.1179e-04,  ...,  7.8388e-04,\n",
      "          7.6160e-04,  0.0000e+00],\n",
      "        [ 1.9607e-05,  1.1307e-03,  2.1732e-03,  ...,  7.0178e-03,\n",
      "          5.2113e-04,  0.0000e+00],\n",
      "        [-1.1489e-06, -1.4811e-03, -2.7933e-03,  ...,  2.2761e-03,\n",
      "          3.3733e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['train', 'park', 'beach', 'beach']\n",
      "{'audio': tensor([[ 4.4499e-05,  8.8402e-05,  3.0873e-05,  ..., -1.9295e-04,\n",
      "         -1.4562e-04,  0.0000e+00],\n",
      "        [ 2.2907e-04,  1.1890e-03,  1.5588e-03,  ...,  4.7583e-03,\n",
      "          5.9006e-03,  0.0000e+00],\n",
      "        [ 2.7130e-03,  3.7704e-03,  4.8317e-05,  ...,  6.3317e-04,\n",
      "          1.0390e-03,  0.0000e+00],\n",
      "        [-1.4766e-02, -2.5631e-02, -2.3607e-02,  ..., -7.6428e-03,\n",
      "         -8.2091e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'beach', 'beach', 'train']}\n",
      "tensor([[ 4.4499e-05,  8.8402e-05,  3.0873e-05,  ..., -1.9295e-04,\n",
      "         -1.4562e-04,  0.0000e+00],\n",
      "        [ 2.2907e-04,  1.1890e-03,  1.5588e-03,  ...,  4.7583e-03,\n",
      "          5.9006e-03,  0.0000e+00],\n",
      "        [ 2.7130e-03,  3.7704e-03,  4.8317e-05,  ...,  6.3317e-04,\n",
      "          1.0390e-03,  0.0000e+00],\n",
      "        [-1.4766e-02, -2.5631e-02, -2.3607e-02,  ..., -7.6428e-03,\n",
      "         -8.2091e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'beach', 'beach', 'train']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                | 68/324 [00:05<00:21, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-1.5505e-02, -2.8990e-02, -2.5273e-02,  ..., -3.2158e-03,\n",
      "         -3.2503e-03,  0.0000e+00],\n",
      "        [ 1.5489e-04,  3.0427e-04,  5.1343e-06,  ..., -4.9937e-05,\n",
      "          1.9539e-04,  0.0000e+00],\n",
      "        [ 9.8882e-03,  1.5316e-02,  1.1587e-02,  ...,  6.0915e-03,\n",
      "          6.4441e-03,  0.0000e+00],\n",
      "        [-1.9465e-03, -4.0656e-03, -4.5428e-03,  ..., -3.8912e-03,\n",
      "         -2.5880e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'forest_path', 'car', 'city_center']}\n",
      "tensor([[-1.5505e-02, -2.8990e-02, -2.5273e-02,  ..., -3.2158e-03,\n",
      "         -3.2503e-03,  0.0000e+00],\n",
      "        [ 1.5489e-04,  3.0427e-04,  5.1343e-06,  ..., -4.9937e-05,\n",
      "          1.9539e-04,  0.0000e+00],\n",
      "        [ 9.8882e-03,  1.5316e-02,  1.1587e-02,  ...,  6.0915e-03,\n",
      "          6.4441e-03,  0.0000e+00],\n",
      "        [-1.9465e-03, -4.0656e-03, -4.5428e-03,  ..., -3.8912e-03,\n",
      "         -2.5880e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'forest_path', 'car', 'city_center']\n",
      "{'audio': tensor([[ 1.0494e-03,  1.6890e-03,  7.7438e-04,  ..., -1.6466e-02,\n",
      "         -1.6738e-02,  0.0000e+00],\n",
      "        [-1.2624e-02, -2.0566e-02, -1.6781e-02,  ...,  3.1813e-02,\n",
      "          3.5686e-02,  0.0000e+00],\n",
      "        [ 4.0293e-04,  5.5886e-04,  3.6669e-04,  ..., -5.2244e-04,\n",
      "         -9.1941e-04,  0.0000e+00],\n",
      "        [ 7.8673e-05,  9.8322e-05, -5.2158e-04,  ...,  5.9670e-03,\n",
      "          6.5279e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'bus', 'forest_path', 'residential_area']}\n",
      "tensor([[ 1.0494e-03,  1.6890e-03,  7.7438e-04,  ..., -1.6466e-02,\n",
      "         -1.6738e-02,  0.0000e+00],\n",
      "        [-1.2624e-02, -2.0566e-02, -1.6781e-02,  ...,  3.1813e-02,\n",
      "          3.5686e-02,  0.0000e+00],\n",
      "        [ 4.0293e-04,  5.5886e-04,  3.6669e-04,  ..., -5.2244e-04,\n",
      "         -9.1941e-04,  0.0000e+00],\n",
      "        [ 7.8673e-05,  9.8322e-05, -5.2158e-04,  ...,  5.9670e-03,\n",
      "          6.5279e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'bus', 'forest_path', 'residential_area']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                               | 72/324 [00:05<00:23, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 0.0002,  0.0004,  0.0003,  ...,  0.0001,  0.0003,  0.0000],\n",
      "        [-0.0071, -0.0133, -0.0119,  ...,  0.0090,  0.0122,  0.0000],\n",
      "        [-0.0012, -0.0019, -0.0016,  ..., -0.0011, -0.0009,  0.0000],\n",
      "        [-0.0024, -0.0037, -0.0029,  ..., -0.0226, -0.0262,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'tram', 'grocery_store', 'grocery_store']}\n",
      "tensor([[ 0.0002,  0.0004,  0.0003,  ...,  0.0001,  0.0003,  0.0000],\n",
      "        [-0.0071, -0.0133, -0.0119,  ...,  0.0090,  0.0122,  0.0000],\n",
      "        [-0.0012, -0.0019, -0.0016,  ..., -0.0011, -0.0009,  0.0000],\n",
      "        [-0.0024, -0.0037, -0.0029,  ..., -0.0226, -0.0262,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'tram', 'grocery_store', 'grocery_store']\n",
      "{'audio': tensor([[-0.0004, -0.0005, -0.0001,  ..., -0.0010,  0.0002,  0.0000],\n",
      "        [-0.0016, -0.0031, -0.0024,  ...,  0.0007,  0.0007,  0.0000],\n",
      "        [-0.0019, -0.0027, -0.0022,  ..., -0.0052, -0.0054,  0.0000],\n",
      "        [-0.0005, -0.0007, -0.0002,  ...,  0.0031, -0.0019,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'cafe/restaurant', 'residential_area', 'home']}\n",
      "tensor([[-0.0004, -0.0005, -0.0001,  ..., -0.0010,  0.0002,  0.0000],\n",
      "        [-0.0016, -0.0031, -0.0024,  ...,  0.0007,  0.0007,  0.0000],\n",
      "        [-0.0019, -0.0027, -0.0022,  ..., -0.0052, -0.0054,  0.0000],\n",
      "        [-0.0005, -0.0007, -0.0002,  ...,  0.0031, -0.0019,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'cafe/restaurant', 'residential_area', 'home']\n",
      "{'audio': tensor([[ 1.0497e-03, -1.2421e-03, -2.0162e-03,  ...,  1.8350e-04,\n",
      "         -4.4793e-04,  0.0000e+00],\n",
      "        [ 9.2894e-04,  8.9390e-04, -4.5670e-06,  ..., -3.2000e-04,\n",
      "         -2.6608e-04,  0.0000e+00],\n",
      "        [ 6.5749e-06,  6.8814e-04,  6.9190e-04,  ..., -1.5194e-03,\n",
      "         -7.6720e-04,  0.0000e+00],\n",
      "        [ 1.1043e-03,  2.4634e-03,  1.8421e-03,  ...,  8.0708e-04,\n",
      "          1.3554e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['home', 'library', 'beach', 'home']}\n",
      "tensor([[ 1.0497e-03, -1.2421e-03, -2.0162e-03,  ...,  1.8350e-04,\n",
      "         -4.4793e-04,  0.0000e+00],\n",
      "        [ 9.2894e-04,  8.9390e-04, -4.5670e-06,  ..., -3.2000e-04,\n",
      "         -2.6608e-04,  0.0000e+00],\n",
      "        [ 6.5749e-06,  6.8814e-04,  6.9190e-04,  ..., -1.5194e-03,\n",
      "         -7.6720e-04,  0.0000e+00],\n",
      "        [ 1.1043e-03,  2.4634e-03,  1.8421e-03,  ...,  8.0708e-04,\n",
      "          1.3554e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['home', 'library', 'beach', 'home']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                              | 74/324 [00:06<00:22, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 1.3562e-03,  2.7626e-03,  2.5075e-03,  ...,  8.2432e-04,\n",
      "          1.6373e-03,  0.0000e+00],\n",
      "        [-3.5587e-02, -5.9831e-02, -5.2428e-02,  ...,  2.8161e-02,\n",
      "          3.2169e-02,  0.0000e+00],\n",
      "        [-4.4712e-04, -2.8474e-04,  7.2965e-04,  ..., -1.7054e-03,\n",
      "         -2.1021e-03,  0.0000e+00],\n",
      "        [ 4.8570e-04,  5.7517e-05, -2.9247e-06,  ...,  4.5622e-04,\n",
      "          4.0127e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['beach', 'train', 'metro_station', 'beach']}\n",
      "tensor([[ 1.3562e-03,  2.7626e-03,  2.5075e-03,  ...,  8.2432e-04,\n",
      "          1.6373e-03,  0.0000e+00],\n",
      "        [-3.5587e-02, -5.9831e-02, -5.2428e-02,  ...,  2.8161e-02,\n",
      "          3.2169e-02,  0.0000e+00],\n",
      "        [-4.4712e-04, -2.8474e-04,  7.2965e-04,  ..., -1.7054e-03,\n",
      "         -2.1021e-03,  0.0000e+00],\n",
      "        [ 4.8570e-04,  5.7517e-05, -2.9247e-06,  ...,  4.5622e-04,\n",
      "          4.0127e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['beach', 'train', 'metro_station', 'beach']\n",
      "{'audio': tensor([[-1.4955e-03, -2.8063e-03, -3.5955e-03,  ...,  7.9746e-04,\n",
      "         -1.5953e-04,  0.0000e+00],\n",
      "        [ 2.8839e-04, -1.0921e-04, -2.8834e-04,  ..., -8.7746e-04,\n",
      "         -7.6552e-04,  0.0000e+00],\n",
      "        [ 2.1910e-03,  4.2112e-03,  4.3451e-03,  ...,  9.7630e-04,\n",
      "          2.1159e-03,  0.0000e+00],\n",
      "        [ 1.2117e-04,  3.8238e-04,  3.9796e-04,  ...,  2.0590e-05,\n",
      "         -2.9838e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['cafe/restaurant', 'metro_station', 'train', 'residential_area']}\n",
      "tensor([[-1.4955e-03, -2.8063e-03, -3.5955e-03,  ...,  7.9746e-04,\n",
      "         -1.5953e-04,  0.0000e+00],\n",
      "        [ 2.8839e-04, -1.0921e-04, -2.8834e-04,  ..., -8.7746e-04,\n",
      "         -7.6552e-04,  0.0000e+00],\n",
      "        [ 2.1910e-03,  4.2112e-03,  4.3451e-03,  ...,  9.7630e-04,\n",
      "          2.1159e-03,  0.0000e+00],\n",
      "        [ 1.2117e-04,  3.8238e-04,  3.9796e-04,  ...,  2.0590e-05,\n",
      "         -2.9838e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['cafe/restaurant', 'metro_station', 'train', 'residential_area']\n",
      "{'audio': tensor([[ 8.9387e-04,  1.2334e-03,  3.0445e-03,  ...,  2.2271e-03,\n",
      "         -4.2136e-05,  0.0000e+00],\n",
      "        [ 4.1941e-04,  2.1628e-04,  1.2127e-03,  ..., -3.5281e-04,\n",
      "         -6.7630e-04,  0.0000e+00],\n",
      "        [ 2.6704e-03,  4.5200e-03,  2.5494e-03,  ..., -1.0066e-03,\n",
      "         -3.7580e-04,  0.0000e+00],\n",
      "        [-2.2866e-04, -8.8372e-05,  3.4175e-04,  ...,  2.0918e-03,\n",
      "          2.6244e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['tram', 'cafe/restaurant', 'grocery_store', 'metro_station']}\n",
      "tensor([[ 8.9387e-04,  1.2334e-03,  3.0445e-03,  ...,  2.2271e-03,\n",
      "         -4.2136e-05,  0.0000e+00],\n",
      "        [ 4.1941e-04,  2.1628e-04,  1.2127e-03,  ..., -3.5281e-04,\n",
      "         -6.7630e-04,  0.0000e+00],\n",
      "        [ 2.6704e-03,  4.5200e-03,  2.5494e-03,  ..., -1.0066e-03,\n",
      "         -3.7580e-04,  0.0000e+00],\n",
      "        [-2.2866e-04, -8.8372e-05,  3.4175e-04,  ...,  2.0918e-03,\n",
      "          2.6244e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['tram', 'cafe/restaurant', 'grocery_store', 'metro_station']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                             | 78/324 [00:06<00:21, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0012, -0.0010,  0.0006,  ...,  0.0025,  0.0028,  0.0000],\n",
      "        [ 0.0020,  0.0033,  0.0035,  ..., -0.0081, -0.0100,  0.0000],\n",
      "        [-0.0006, -0.0016, -0.0031,  ..., -0.0008,  0.0019,  0.0000],\n",
      "        [ 0.0042,  0.0065,  0.0050,  ..., -0.0008, -0.0004,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['metro_station', 'car', 'beach', 'tram']}\n",
      "tensor([[-0.0012, -0.0010,  0.0006,  ...,  0.0025,  0.0028,  0.0000],\n",
      "        [ 0.0020,  0.0033,  0.0035,  ..., -0.0081, -0.0100,  0.0000],\n",
      "        [-0.0006, -0.0016, -0.0031,  ..., -0.0008,  0.0019,  0.0000],\n",
      "        [ 0.0042,  0.0065,  0.0050,  ..., -0.0008, -0.0004,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['metro_station', 'car', 'beach', 'tram']\n",
      "{'audio': tensor([[ 5.0366e-05,  8.0339e-06, -6.2623e-05,  ..., -2.1188e-04,\n",
      "         -3.0577e-04,  0.0000e+00],\n",
      "        [-4.7597e-05, -5.7921e-05, -2.9894e-05,  ..., -2.9233e-05,\n",
      "          5.3108e-06,  0.0000e+00],\n",
      "        [-1.0899e-04, -3.3426e-04, -9.8932e-05,  ..., -1.8385e-04,\n",
      "         -1.7574e-04,  0.0000e+00],\n",
      "        [-1.3617e-02, -2.3063e-02, -2.0583e-02,  ...,  1.3431e-02,\n",
      "          1.4548e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'office', 'home', 'train']}\n",
      "tensor([[ 5.0366e-05,  8.0339e-06, -6.2623e-05,  ..., -2.1188e-04,\n",
      "         -3.0577e-04,  0.0000e+00],\n",
      "        [-4.7597e-05, -5.7921e-05, -2.9894e-05,  ..., -2.9233e-05,\n",
      "          5.3108e-06,  0.0000e+00],\n",
      "        [-1.0899e-04, -3.3426e-04, -9.8932e-05,  ..., -1.8385e-04,\n",
      "         -1.7574e-04,  0.0000e+00],\n",
      "        [-1.3617e-02, -2.3063e-02, -2.0583e-02,  ...,  1.3431e-02,\n",
      "          1.4548e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'office', 'home', 'train']\n",
      "{'audio': tensor([[ 7.1346e-03,  1.8807e-02,  2.1606e-02,  ...,  5.2798e-04,\n",
      "         -1.7674e-03,  0.0000e+00],\n",
      "        [-1.0651e-04, -4.4170e-04, -6.2750e-05,  ...,  5.1499e-04,\n",
      "          5.6819e-04,  0.0000e+00],\n",
      "        [-1.0579e-05, -5.7147e-04, -7.3805e-05,  ...,  5.6602e-04,\n",
      "          5.8117e-04,  0.0000e+00],\n",
      "        [-1.6969e-02, -3.1817e-02, -3.2965e-02,  ..., -2.4764e-02,\n",
      "         -2.3975e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['city_center', 'home', 'library', 'city_center']}\n",
      "tensor([[ 7.1346e-03,  1.8807e-02,  2.1606e-02,  ...,  5.2798e-04,\n",
      "         -1.7674e-03,  0.0000e+00],\n",
      "        [-1.0651e-04, -4.4170e-04, -6.2750e-05,  ...,  5.1499e-04,\n",
      "          5.6819e-04,  0.0000e+00],\n",
      "        [-1.0579e-05, -5.7147e-04, -7.3805e-05,  ...,  5.6602e-04,\n",
      "          5.8117e-04,  0.0000e+00],\n",
      "        [-1.6969e-02, -3.1817e-02, -3.2965e-02,  ..., -2.4764e-02,\n",
      "         -2.3975e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['city_center', 'home', 'library', 'city_center']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                             | 80/324 [00:06<00:20, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-4.4023e-03, -6.4308e-03, -4.9790e-03,  ..., -1.9383e-03,\n",
      "         -1.6741e-03,  0.0000e+00],\n",
      "        [ 3.2905e-04, -9.9049e-05, -2.7239e-04,  ..., -5.7288e-03,\n",
      "         -5.9443e-03,  0.0000e+00],\n",
      "        [-1.4092e-02, -2.2433e-02, -1.8719e-02,  ...,  3.2359e-03,\n",
      "          1.2700e-03,  0.0000e+00],\n",
      "        [ 6.9751e-03,  1.1887e-02,  1.0259e-02,  ...,  1.6677e-03,\n",
      "          2.7338e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['cafe/restaurant', 'park', 'train', 'bus']}\n",
      "tensor([[-4.4023e-03, -6.4308e-03, -4.9790e-03,  ..., -1.9383e-03,\n",
      "         -1.6741e-03,  0.0000e+00],\n",
      "        [ 3.2905e-04, -9.9049e-05, -2.7239e-04,  ..., -5.7288e-03,\n",
      "         -5.9443e-03,  0.0000e+00],\n",
      "        [-1.4092e-02, -2.2433e-02, -1.8719e-02,  ...,  3.2359e-03,\n",
      "          1.2700e-03,  0.0000e+00],\n",
      "        [ 6.9751e-03,  1.1887e-02,  1.0259e-02,  ...,  1.6677e-03,\n",
      "          2.7338e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['cafe/restaurant', 'park', 'train', 'bus']\n",
      "{'audio': tensor([[ 0.0009,  0.0046, -0.0003,  ..., -0.0101,  0.0017,  0.0000],\n",
      "        [ 0.0036,  0.0072,  0.0019,  ...,  0.0070,  0.0074,  0.0000],\n",
      "        [ 0.0449,  0.0743,  0.0651,  ..., -0.0396, -0.0437,  0.0000],\n",
      "        [ 0.0018,  0.0024,  0.0006,  ...,  0.0082,  0.0091,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['home', 'residential_area', 'car', 'bus']}\n",
      "tensor([[ 0.0009,  0.0046, -0.0003,  ..., -0.0101,  0.0017,  0.0000],\n",
      "        [ 0.0036,  0.0072,  0.0019,  ...,  0.0070,  0.0074,  0.0000],\n",
      "        [ 0.0449,  0.0743,  0.0651,  ..., -0.0396, -0.0437,  0.0000],\n",
      "        [ 0.0018,  0.0024,  0.0006,  ...,  0.0082,  0.0091,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['home', 'residential_area', 'car', 'bus']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                            | 82/324 [00:06<00:22, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0004, -0.0007, -0.0005,  ...,  0.0006,  0.0007,  0.0000],\n",
      "        [ 0.0041,  0.0067,  0.0059,  ...,  0.0017,  0.0028,  0.0000],\n",
      "        [-0.0018, -0.0025, -0.0025,  ...,  0.0016,  0.0006,  0.0000],\n",
      "        [ 0.0022,  0.0026,  0.0022,  ..., -0.0068, -0.0064,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'residential_area', 'beach', 'cafe/restaurant']}\n",
      "tensor([[-0.0004, -0.0007, -0.0005,  ...,  0.0006,  0.0007,  0.0000],\n",
      "        [ 0.0041,  0.0067,  0.0059,  ...,  0.0017,  0.0028,  0.0000],\n",
      "        [-0.0018, -0.0025, -0.0025,  ...,  0.0016,  0.0006,  0.0000],\n",
      "        [ 0.0022,  0.0026,  0.0022,  ..., -0.0068, -0.0064,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'residential_area', 'beach', 'cafe/restaurant']\n",
      "{'audio': tensor([[-0.0007,  0.0008,  0.0019,  ...,  0.0014,  0.0009,  0.0000],\n",
      "        [-0.0003, -0.0004, -0.0003,  ..., -0.0006, -0.0007,  0.0000],\n",
      "        [ 0.0012,  0.0017,  0.0014,  ..., -0.0006, -0.0007,  0.0000],\n",
      "        [-0.0003, -0.0028,  0.0003,  ...,  0.0003,  0.0014,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['tram', 'forest_path', 'park', 'home']}\n",
      "tensor([[-0.0007,  0.0008,  0.0019,  ...,  0.0014,  0.0009,  0.0000],\n",
      "        [-0.0003, -0.0004, -0.0003,  ..., -0.0006, -0.0007,  0.0000],\n",
      "        [ 0.0012,  0.0017,  0.0014,  ..., -0.0006, -0.0007,  0.0000],\n",
      "        [-0.0003, -0.0028,  0.0003,  ...,  0.0003,  0.0014,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['tram', 'forest_path', 'park', 'home']\n",
      "{'audio': tensor([[ 1.6230e-03,  2.5916e-03,  2.2413e-03,  ..., -1.2603e-02,\n",
      "         -1.1816e-02,  0.0000e+00],\n",
      "        [ 3.3490e-03,  5.0733e-03,  3.8205e-03,  ...,  1.0577e-02,\n",
      "          1.1029e-02,  0.0000e+00],\n",
      "        [-1.6864e-03, -9.2400e-05,  2.3113e-03,  ...,  1.0383e-02,\n",
      "          8.5144e-03,  0.0000e+00],\n",
      "        [-1.4852e-04, -2.2284e-04, -2.1827e-04,  ...,  4.2547e-04,\n",
      "          4.0660e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['tram', 'bus', 'tram', 'library']}\n",
      "tensor([[ 1.6230e-03,  2.5916e-03,  2.2413e-03,  ..., -1.2603e-02,\n",
      "         -1.1816e-02,  0.0000e+00],\n",
      "        [ 3.3490e-03,  5.0733e-03,  3.8205e-03,  ...,  1.0577e-02,\n",
      "          1.1029e-02,  0.0000e+00],\n",
      "        [-1.6864e-03, -9.2400e-05,  2.3113e-03,  ...,  1.0383e-02,\n",
      "          8.5144e-03,  0.0000e+00],\n",
      "        [-1.4852e-04, -2.2284e-04, -2.1827e-04,  ...,  4.2547e-04,\n",
      "          4.0660e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['tram', 'bus', 'tram', 'library']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                            | 84/324 [00:06<00:21, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 1.3089e-04,  2.1425e-04,  1.9917e-04,  ...,  4.7943e-03,\n",
      "          5.1022e-03,  0.0000e+00],\n",
      "        [ 4.4004e-04,  8.9487e-04,  8.6508e-04,  ..., -3.5303e-05,\n",
      "         -2.0317e-04,  0.0000e+00],\n",
      "        [ 1.5141e-02,  2.4640e-02,  1.9209e-02,  ...,  1.0019e-02,\n",
      "          7.7629e-03,  0.0000e+00],\n",
      "        [-2.1028e-03, -3.5190e-03, -3.5441e-03,  ...,  6.2437e-03,\n",
      "          6.3362e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'forest_path', 'train', 'cafe/restaurant']}\n",
      "tensor([[ 1.3089e-04,  2.1425e-04,  1.9917e-04,  ...,  4.7943e-03,\n",
      "          5.1022e-03,  0.0000e+00],\n",
      "        [ 4.4004e-04,  8.9487e-04,  8.6508e-04,  ..., -3.5303e-05,\n",
      "         -2.0317e-04,  0.0000e+00],\n",
      "        [ 1.5141e-02,  2.4640e-02,  1.9209e-02,  ...,  1.0019e-02,\n",
      "          7.7629e-03,  0.0000e+00],\n",
      "        [-2.1028e-03, -3.5190e-03, -3.5441e-03,  ...,  6.2437e-03,\n",
      "          6.3362e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'forest_path', 'train', 'cafe/restaurant']\n",
      "{'audio': tensor([[ 0.0290,  0.0459,  0.0411,  ...,  0.0212,  0.0251,  0.0000],\n",
      "        [ 0.0016,  0.0019,  0.0008,  ...,  0.0024,  0.0024,  0.0000],\n",
      "        [-0.0020, -0.0027, -0.0014,  ..., -0.0018, -0.0019,  0.0000],\n",
      "        [ 0.0015,  0.0026,  0.0025,  ...,  0.0011,  0.0012,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'park', 'park', 'cafe/restaurant']}\n",
      "tensor([[ 0.0290,  0.0459,  0.0411,  ...,  0.0212,  0.0251,  0.0000],\n",
      "        [ 0.0016,  0.0019,  0.0008,  ...,  0.0024,  0.0024,  0.0000],\n",
      "        [-0.0020, -0.0027, -0.0014,  ..., -0.0018, -0.0019,  0.0000],\n",
      "        [ 0.0015,  0.0026,  0.0025,  ...,  0.0011,  0.0012,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'park', 'park', 'cafe/restaurant']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                           | 86/324 [00:07<00:23,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 0.0041,  0.0069,  0.0061,  ..., -0.0018, -0.0023,  0.0000],\n",
      "        [-0.0002,  0.0020,  0.0027,  ..., -0.0030, -0.0052,  0.0000],\n",
      "        [-0.0110, -0.0164, -0.0093,  ..., -0.0023, -0.0043,  0.0000],\n",
      "        [-0.0335, -0.0573, -0.0512,  ..., -0.0019, -0.0035,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'beach', 'residential_area', 'tram']}\n",
      "tensor([[ 0.0041,  0.0069,  0.0061,  ..., -0.0018, -0.0023,  0.0000],\n",
      "        [-0.0002,  0.0020,  0.0027,  ..., -0.0030, -0.0052,  0.0000],\n",
      "        [-0.0110, -0.0164, -0.0093,  ..., -0.0023, -0.0043,  0.0000],\n",
      "        [-0.0335, -0.0573, -0.0512,  ..., -0.0019, -0.0035,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'beach', 'residential_area', 'tram']\n",
      "{'audio': tensor([[ 0.0052,  0.0007, -0.0100,  ...,  0.0637,  0.0758,  0.0000],\n",
      "        [ 0.0022,  0.0041,  0.0048,  ...,  0.0037,  0.0031,  0.0000],\n",
      "        [-0.0002, -0.0003, -0.0002,  ...,  0.0014,  0.0017,  0.0000],\n",
      "        [ 0.0013,  0.0020,  0.0014,  ...,  0.0019,  0.0020,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'park', 'forest_path', 'park']}\n",
      "tensor([[ 0.0052,  0.0007, -0.0100,  ...,  0.0637,  0.0758,  0.0000],\n",
      "        [ 0.0022,  0.0041,  0.0048,  ...,  0.0037,  0.0031,  0.0000],\n",
      "        [-0.0002, -0.0003, -0.0002,  ...,  0.0014,  0.0017,  0.0000],\n",
      "        [ 0.0013,  0.0020,  0.0014,  ...,  0.0019,  0.0020,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'park', 'forest_path', 'park']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                          | 89/324 [00:07<00:25,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0014, -0.0021, -0.0014,  ..., -0.0014, -0.0018,  0.0000],\n",
      "        [ 0.0029,  0.0042,  0.0033,  ...,  0.0010,  0.0003,  0.0000],\n",
      "        [ 0.0030,  0.0053,  0.0055,  ...,  0.0029,  0.0030,  0.0000],\n",
      "        [ 0.0434,  0.0712,  0.0603,  ...,  0.0011,  0.0017,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['residential_area', 'park', 'bus', 'car']}\n",
      "tensor([[-0.0014, -0.0021, -0.0014,  ..., -0.0014, -0.0018,  0.0000],\n",
      "        [ 0.0029,  0.0042,  0.0033,  ...,  0.0010,  0.0003,  0.0000],\n",
      "        [ 0.0030,  0.0053,  0.0055,  ...,  0.0029,  0.0030,  0.0000],\n",
      "        [ 0.0434,  0.0712,  0.0603,  ...,  0.0011,  0.0017,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['residential_area', 'park', 'bus', 'car']\n",
      "{'audio': tensor([[-4.7114e-04, -8.3235e-04, -7.7281e-04,  ...,  1.3108e-03,\n",
      "         -6.0268e-04,  0.0000e+00],\n",
      "        [ 6.5169e-05, -2.1902e-04,  1.6745e-04,  ...,  3.8705e-04,\n",
      "          3.0003e-04,  0.0000e+00],\n",
      "        [-6.3714e-05, -2.4421e-05,  9.3663e-06,  ..., -1.7371e-03,\n",
      "         -1.6853e-03,  0.0000e+00],\n",
      "        [ 1.0249e-03,  1.4342e-03,  1.1752e-03,  ...,  4.1279e-03,\n",
      "          4.4231e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['city_center', 'beach', 'forest_path', 'car']}\n",
      "tensor([[-4.7114e-04, -8.3235e-04, -7.7281e-04,  ...,  1.3108e-03,\n",
      "         -6.0268e-04,  0.0000e+00],\n",
      "        [ 6.5169e-05, -2.1902e-04,  1.6745e-04,  ...,  3.8705e-04,\n",
      "          3.0003e-04,  0.0000e+00],\n",
      "        [-6.3714e-05, -2.4421e-05,  9.3663e-06,  ..., -1.7371e-03,\n",
      "         -1.6853e-03,  0.0000e+00],\n",
      "        [ 1.0249e-03,  1.4342e-03,  1.1752e-03,  ...,  4.1279e-03,\n",
      "          4.4231e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['city_center', 'beach', 'forest_path', 'car']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                          | 92/324 [00:07<00:21, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 1.0550e-05,  6.4761e-05,  5.5189e-05,  ...,  1.1070e-04,\n",
      "          1.3951e-04,  0.0000e+00],\n",
      "        [-1.0361e-02, -1.6386e-02, -1.2444e-02,  ..., -1.6345e-03,\n",
      "         -4.4454e-03,  0.0000e+00],\n",
      "        [-5.4309e-03, -9.5361e-03, -9.0606e-03,  ...,  3.5165e-03,\n",
      "          4.5240e-03,  0.0000e+00],\n",
      "        [-5.6629e-04, -8.9568e-04, -5.6524e-04,  ...,  2.0576e-05,\n",
      "         -2.7671e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'bus', 'tram', 'residential_area']}\n",
      "tensor([[ 1.0550e-05,  6.4761e-05,  5.5189e-05,  ...,  1.1070e-04,\n",
      "          1.3951e-04,  0.0000e+00],\n",
      "        [-1.0361e-02, -1.6386e-02, -1.2444e-02,  ..., -1.6345e-03,\n",
      "         -4.4454e-03,  0.0000e+00],\n",
      "        [-5.4309e-03, -9.5361e-03, -9.0606e-03,  ...,  3.5165e-03,\n",
      "          4.5240e-03,  0.0000e+00],\n",
      "        [-5.6629e-04, -8.9568e-04, -5.6524e-04,  ...,  2.0576e-05,\n",
      "         -2.7671e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'bus', 'tram', 'residential_area']\n",
      "{'audio': tensor([[ 4.5240e-05,  1.6638e-04,  1.6545e-04,  ...,  8.4294e-05,\n",
      "          4.6156e-04,  0.0000e+00],\n",
      "        [ 1.2089e-04,  1.7768e-04,  2.0446e-04,  ...,  7.7036e-05,\n",
      "          2.9873e-06,  0.0000e+00],\n",
      "        [ 1.6231e-02,  2.5213e-02,  1.9981e-02,  ...,  5.9276e-02,\n",
      "          6.5754e-02,  0.0000e+00],\n",
      "        [-1.2654e-02, -2.0988e-02, -1.7970e-02,  ..., -5.8905e-02,\n",
      "         -6.6155e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'office', 'car', 'train']}\n",
      "tensor([[ 4.5240e-05,  1.6638e-04,  1.6545e-04,  ...,  8.4294e-05,\n",
      "          4.6156e-04,  0.0000e+00],\n",
      "        [ 1.2089e-04,  1.7768e-04,  2.0446e-04,  ...,  7.7036e-05,\n",
      "          2.9873e-06,  0.0000e+00],\n",
      "        [ 1.6231e-02,  2.5213e-02,  1.9981e-02,  ...,  5.9276e-02,\n",
      "          6.5754e-02,  0.0000e+00],\n",
      "        [-1.2654e-02, -2.0988e-02, -1.7970e-02,  ..., -5.8905e-02,\n",
      "         -6.6155e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'office', 'car', 'train']\n",
      "{'audio': tensor([[ 3.4950e-03,  5.8847e-03,  5.2040e-03,  ..., -8.3897e-04,\n",
      "         -9.0693e-04,  0.0000e+00],\n",
      "        [ 2.6768e-04,  5.7679e-04,  5.3655e-04,  ..., -2.7173e-04,\n",
      "         -5.2898e-04,  0.0000e+00],\n",
      "        [-2.8549e-03, -4.9146e-03, -4.3004e-03,  ...,  7.5979e-03,\n",
      "          8.1560e-03,  0.0000e+00],\n",
      "        [ 1.9814e-04,  3.0494e-04,  2.9480e-04,  ...,  4.7553e-05,\n",
      "          1.7247e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'cafe/restaurant', 'car', 'forest_path']}\n",
      "tensor([[ 3.4950e-03,  5.8847e-03,  5.2040e-03,  ..., -8.3897e-04,\n",
      "         -9.0693e-04,  0.0000e+00],\n",
      "        [ 2.6768e-04,  5.7679e-04,  5.3655e-04,  ..., -2.7173e-04,\n",
      "         -5.2898e-04,  0.0000e+00],\n",
      "        [-2.8549e-03, -4.9146e-03, -4.3004e-03,  ...,  7.5979e-03,\n",
      "          8.1560e-03,  0.0000e+00],\n",
      "        [ 1.9814e-04,  3.0494e-04,  2.9480e-04,  ...,  4.7553e-05,\n",
      "          1.7247e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'cafe/restaurant', 'car', 'forest_path']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                         | 94/324 [00:07<00:22, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 8.6510e-04,  1.5895e-03,  2.1472e-03,  ...,  5.3341e-04,\n",
      "          8.6687e-04,  0.0000e+00],\n",
      "        [-3.7651e-03, -7.4708e-03, -5.4736e-03,  ...,  7.9548e-04,\n",
      "          1.4161e-03,  0.0000e+00],\n",
      "        [-1.6461e-04, -3.0886e-04, -1.7353e-04,  ..., -1.4099e-04,\n",
      "         -6.9087e-05,  0.0000e+00],\n",
      "        [-1.8994e-04, -2.3001e-04, -6.4095e-05,  ...,  6.5595e-05,\n",
      "          2.0813e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'park', 'office', 'library']}\n",
      "tensor([[ 8.6510e-04,  1.5895e-03,  2.1472e-03,  ...,  5.3341e-04,\n",
      "          8.6687e-04,  0.0000e+00],\n",
      "        [-3.7651e-03, -7.4708e-03, -5.4736e-03,  ...,  7.9548e-04,\n",
      "          1.4161e-03,  0.0000e+00],\n",
      "        [-1.6461e-04, -3.0886e-04, -1.7353e-04,  ..., -1.4099e-04,\n",
      "         -6.9087e-05,  0.0000e+00],\n",
      "        [-1.8994e-04, -2.3001e-04, -6.4095e-05,  ...,  6.5595e-05,\n",
      "          2.0813e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'park', 'office', 'library']\n",
      "{'audio': tensor([[-2.0372e-03, -2.9924e-03, -1.9517e-03,  ..., -3.5336e-03,\n",
      "         -5.4170e-03,  0.0000e+00],\n",
      "        [ 7.2400e-04,  1.2106e-03,  1.0270e-03,  ...,  9.9360e-05,\n",
      "          1.1657e-04,  0.0000e+00],\n",
      "        [-8.5084e-03, -1.4322e-02, -1.2553e-02,  ...,  1.7798e-02,\n",
      "          1.8328e-02,  0.0000e+00],\n",
      "        [ 1.3441e-03,  2.1939e-03,  1.6978e-03,  ..., -1.1253e-03,\n",
      "         -1.1653e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['residential_area', 'office', 'car', 'park']}\n",
      "tensor([[-2.0372e-03, -2.9924e-03, -1.9517e-03,  ..., -3.5336e-03,\n",
      "         -5.4170e-03,  0.0000e+00],\n",
      "        [ 7.2400e-04,  1.2106e-03,  1.0270e-03,  ...,  9.9360e-05,\n",
      "          1.1657e-04,  0.0000e+00],\n",
      "        [-8.5084e-03, -1.4322e-02, -1.2553e-02,  ...,  1.7798e-02,\n",
      "          1.8328e-02,  0.0000e+00],\n",
      "        [ 1.3441e-03,  2.1939e-03,  1.6978e-03,  ..., -1.1253e-03,\n",
      "         -1.1653e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['residential_area', 'office', 'car', 'park']\n",
      "{'audio': tensor([[-0.0058, -0.0093, -0.0073,  ..., -0.0080, -0.0091,  0.0000],\n",
      "        [ 0.0016,  0.0027,  0.0029,  ..., -0.0075, -0.0080,  0.0000],\n",
      "        [ 0.0221,  0.0380,  0.0320,  ..., -0.0105, -0.0159,  0.0000],\n",
      "        [ 0.0019,  0.0033,  0.0041,  ..., -0.0066, -0.0079,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'bus', 'city_center', 'grocery_store']}\n",
      "tensor([[-0.0058, -0.0093, -0.0073,  ..., -0.0080, -0.0091,  0.0000],\n",
      "        [ 0.0016,  0.0027,  0.0029,  ..., -0.0075, -0.0080,  0.0000],\n",
      "        [ 0.0221,  0.0380,  0.0320,  ..., -0.0105, -0.0159,  0.0000],\n",
      "        [ 0.0019,  0.0033,  0.0041,  ..., -0.0066, -0.0079,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'bus', 'city_center', 'grocery_store']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                        | 98/324 [00:08<00:18, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 3.3596e-04,  5.7333e-04, -1.2422e-04,  ..., -7.8951e-04,\n",
      "         -1.1675e-03,  0.0000e+00],\n",
      "        [ 2.9885e-04,  3.2597e-04,  2.9072e-05,  ...,  4.0700e-03,\n",
      "          5.4208e-03,  0.0000e+00],\n",
      "        [-7.4410e-03, -1.1579e-02, -8.0650e-03,  ...,  6.4442e-03,\n",
      "          7.8254e-03,  0.0000e+00],\n",
      "        [-2.5587e-04, -4.6630e-04, -3.1629e-04,  ..., -1.3751e-03,\n",
      "         -1.5485e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'park', 'grocery_store', 'forest_path']}\n",
      "tensor([[ 3.3596e-04,  5.7333e-04, -1.2422e-04,  ..., -7.8951e-04,\n",
      "         -1.1675e-03,  0.0000e+00],\n",
      "        [ 2.9885e-04,  3.2597e-04,  2.9072e-05,  ...,  4.0700e-03,\n",
      "          5.4208e-03,  0.0000e+00],\n",
      "        [-7.4410e-03, -1.1579e-02, -8.0650e-03,  ...,  6.4442e-03,\n",
      "          7.8254e-03,  0.0000e+00],\n",
      "        [-2.5587e-04, -4.6630e-04, -3.1629e-04,  ..., -1.3751e-03,\n",
      "         -1.5485e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'park', 'grocery_store', 'forest_path']\n",
      "{'audio': tensor([[ 1.4946e-03,  2.1461e-03,  1.6269e-03,  ...,  4.0642e-03,\n",
      "          4.9718e-03,  0.0000e+00],\n",
      "        [-3.4903e-03, -5.2612e-03, -4.5065e-03,  ..., -2.9359e-02,\n",
      "         -3.4220e-02,  0.0000e+00],\n",
      "        [-4.2264e-05, -7.1793e-05, -6.3390e-05,  ...,  1.6853e-05,\n",
      "          1.2692e-04,  0.0000e+00],\n",
      "        [ 2.8578e-04,  4.3665e-04,  6.9286e-04,  ..., -1.5662e-02,\n",
      "         -1.7719e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'tram', 'office', 'bus']}\n",
      "tensor([[ 1.4946e-03,  2.1461e-03,  1.6269e-03,  ...,  4.0642e-03,\n",
      "          4.9718e-03,  0.0000e+00],\n",
      "        [-3.4903e-03, -5.2612e-03, -4.5065e-03,  ..., -2.9359e-02,\n",
      "         -3.4220e-02,  0.0000e+00],\n",
      "        [-4.2264e-05, -7.1793e-05, -6.3390e-05,  ...,  1.6853e-05,\n",
      "          1.2692e-04,  0.0000e+00],\n",
      "        [ 2.8578e-04,  4.3665e-04,  6.9286e-04,  ..., -1.5662e-02,\n",
      "         -1.7719e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'tram', 'office', 'bus']\n",
      "{'audio': tensor([[-4.0203e-03, -5.8872e-03, -7.4815e-03,  ...,  6.2121e-02,\n",
      "          8.2174e-02,  0.0000e+00],\n",
      "        [-4.7357e-05, -4.8689e-05,  7.4113e-06,  ..., -2.0828e-04,\n",
      "         -2.9763e-04,  0.0000e+00],\n",
      "        [ 2.0220e-04,  3.1323e-04,  2.2024e-04,  ..., -1.6365e-05,\n",
      "          2.3848e-05,  0.0000e+00],\n",
      "        [-2.3432e-02, -3.8479e-02, -3.1040e-02,  ..., -2.6230e-03,\n",
      "         -3.4417e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['train', 'office', 'library', 'train']}\n",
      "tensor([[-4.0203e-03, -5.8872e-03, -7.4815e-03,  ...,  6.2121e-02,\n",
      "          8.2174e-02,  0.0000e+00],\n",
      "        [-4.7357e-05, -4.8689e-05,  7.4113e-06,  ..., -2.0828e-04,\n",
      "         -2.9763e-04,  0.0000e+00],\n",
      "        [ 2.0220e-04,  3.1323e-04,  2.2024e-04,  ..., -1.6365e-05,\n",
      "          2.3848e-05,  0.0000e+00],\n",
      "        [-2.3432e-02, -3.8479e-02, -3.1040e-02,  ..., -2.6230e-03,\n",
      "         -3.4417e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['train', 'office', 'library', 'train']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                       | 100/324 [00:08<00:19, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 2.6741e-04,  4.9761e-04,  8.5071e-04,  ...,  1.6481e-04,\n",
      "          2.6994e-05,  0.0000e+00],\n",
      "        [ 3.1509e-04,  2.2324e-03,  1.8065e-03,  ...,  1.2527e-02,\n",
      "          1.3677e-02,  0.0000e+00],\n",
      "        [ 2.8664e-03,  4.6882e-03,  3.8578e-03,  ..., -1.1584e-02,\n",
      "         -1.3295e-02,  0.0000e+00],\n",
      "        [-2.0495e-04, -2.7607e-04, -1.8035e-04,  ...,  4.1930e-04,\n",
      "          2.2793e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['cafe/restaurant', 'bus', 'train', 'forest_path']}\n",
      "tensor([[ 2.6741e-04,  4.9761e-04,  8.5071e-04,  ...,  1.6481e-04,\n",
      "          2.6994e-05,  0.0000e+00],\n",
      "        [ 3.1509e-04,  2.2324e-03,  1.8065e-03,  ...,  1.2527e-02,\n",
      "          1.3677e-02,  0.0000e+00],\n",
      "        [ 2.8664e-03,  4.6882e-03,  3.8578e-03,  ..., -1.1584e-02,\n",
      "         -1.3295e-02,  0.0000e+00],\n",
      "        [-2.0495e-04, -2.7607e-04, -1.8035e-04,  ...,  4.1930e-04,\n",
      "          2.2793e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['cafe/restaurant', 'bus', 'train', 'forest_path']\n",
      "{'audio': tensor([[ 7.2625e-03,  1.1801e-02,  9.5855e-03,  ...,  1.4105e-03,\n",
      "          2.2204e-03,  0.0000e+00],\n",
      "        [-5.4774e-03, -8.5200e-03, -5.1134e-03,  ..., -1.0621e-03,\n",
      "         -3.6685e-04,  0.0000e+00],\n",
      "        [-1.9128e-03, -3.1241e-03, -2.6238e-03,  ...,  1.8981e-03,\n",
      "          2.1597e-03,  0.0000e+00],\n",
      "        [-3.8166e-05,  1.6781e-05,  1.7629e-04,  ...,  1.0300e-04,\n",
      "          1.6134e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['tram', 'residential_area', 'park', 'library']}\n",
      "tensor([[ 7.2625e-03,  1.1801e-02,  9.5855e-03,  ...,  1.4105e-03,\n",
      "          2.2204e-03,  0.0000e+00],\n",
      "        [-5.4774e-03, -8.5200e-03, -5.1134e-03,  ..., -1.0621e-03,\n",
      "         -3.6685e-04,  0.0000e+00],\n",
      "        [-1.9128e-03, -3.1241e-03, -2.6238e-03,  ...,  1.8981e-03,\n",
      "          2.1597e-03,  0.0000e+00],\n",
      "        [-3.8166e-05,  1.6781e-05,  1.7629e-04,  ...,  1.0300e-04,\n",
      "          1.6134e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['tram', 'residential_area', 'park', 'library']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                      | 104/324 [00:08<00:17, 12.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-9.0173e-04, -1.5828e-03, -1.4034e-03,  ...,  1.3242e-05,\n",
      "         -1.7026e-04,  0.0000e+00],\n",
      "        [ 2.3797e-03,  4.1347e-03,  3.6214e-03,  ..., -1.3138e-03,\n",
      "         -1.2521e-03,  0.0000e+00],\n",
      "        [-7.3090e-05, -1.2238e-03, -1.4891e-03,  ...,  1.1758e-02,\n",
      "         -3.3171e-04,  0.0000e+00],\n",
      "        [-7.2292e-04, -9.2891e-04, -7.0811e-04,  ...,  5.7055e-05,\n",
      "         -1.2929e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'car', 'beach', 'grocery_store']}\n",
      "tensor([[-9.0173e-04, -1.5828e-03, -1.4034e-03,  ...,  1.3242e-05,\n",
      "         -1.7026e-04,  0.0000e+00],\n",
      "        [ 2.3797e-03,  4.1347e-03,  3.6214e-03,  ..., -1.3138e-03,\n",
      "         -1.2521e-03,  0.0000e+00],\n",
      "        [-7.3090e-05, -1.2238e-03, -1.4891e-03,  ...,  1.1758e-02,\n",
      "         -3.3171e-04,  0.0000e+00],\n",
      "        [-7.2292e-04, -9.2891e-04, -7.0811e-04,  ...,  5.7055e-05,\n",
      "         -1.2929e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'car', 'beach', 'grocery_store']\n",
      "{'audio': tensor([[-8.3844e-04, -6.8916e-04, -1.8309e-05,  ..., -9.4555e-03,\n",
      "         -1.0182e-02,  0.0000e+00],\n",
      "        [-3.7015e-04, -2.2168e-03, -2.2881e-03,  ...,  3.4532e-03,\n",
      "          2.5933e-03,  0.0000e+00],\n",
      "        [ 8.3381e-03,  1.1650e-02,  8.2221e-03,  ..., -6.4229e-03,\n",
      "         -8.0766e-03,  0.0000e+00],\n",
      "        [-2.6590e-04, -7.3889e-04, -8.1188e-04,  ..., -1.3770e-03,\n",
      "         -1.4555e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'park', 'tram', 'residential_area']}\n",
      "tensor([[-8.3844e-04, -6.8916e-04, -1.8309e-05,  ..., -9.4555e-03,\n",
      "         -1.0182e-02,  0.0000e+00],\n",
      "        [-3.7015e-04, -2.2168e-03, -2.2881e-03,  ...,  3.4532e-03,\n",
      "          2.5933e-03,  0.0000e+00],\n",
      "        [ 8.3381e-03,  1.1650e-02,  8.2221e-03,  ..., -6.4229e-03,\n",
      "         -8.0766e-03,  0.0000e+00],\n",
      "        [-2.6590e-04, -7.3889e-04, -8.1188e-04,  ..., -1.3770e-03,\n",
      "         -1.4555e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'park', 'tram', 'residential_area']\n",
      "{'audio': tensor([[-0.0007, -0.0012, -0.0007,  ...,  0.0001,  0.0003,  0.0000],\n",
      "        [-0.0068, -0.0106, -0.0084,  ..., -0.0280, -0.0314,  0.0000],\n",
      "        [-0.0003, -0.0009, -0.0011,  ..., -0.0061, -0.0072,  0.0000],\n",
      "        [-0.0022, -0.0033, -0.0075,  ...,  0.0047, -0.0016,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['cafe/restaurant', 'car', 'park', 'beach']}\n",
      "tensor([[-0.0007, -0.0012, -0.0007,  ...,  0.0001,  0.0003,  0.0000],\n",
      "        [-0.0068, -0.0106, -0.0084,  ..., -0.0280, -0.0314,  0.0000],\n",
      "        [-0.0003, -0.0009, -0.0011,  ..., -0.0061, -0.0072,  0.0000],\n",
      "        [-0.0022, -0.0033, -0.0075,  ...,  0.0047, -0.0016,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['cafe/restaurant', 'car', 'park', 'beach']\n",
      "{'audio': tensor([[ 0.0064,  0.0114,  0.0107,  ...,  0.0021,  0.0036,  0.0000],\n",
      "        [-0.0004, -0.0013, -0.0016,  ..., -0.0004,  0.0001,  0.0000],\n",
      "        [ 0.0003, -0.0003, -0.0007,  ..., -0.0012, -0.0006,  0.0000],\n",
      "        [ 0.0007,  0.0012,  0.0010,  ..., -0.0007, -0.0010,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'home', 'home', 'forest_path']}\n",
      "tensor([[ 0.0064,  0.0114,  0.0107,  ...,  0.0021,  0.0036,  0.0000],\n",
      "        [-0.0004, -0.0013, -0.0016,  ..., -0.0004,  0.0001,  0.0000],\n",
      "        [ 0.0003, -0.0003, -0.0007,  ..., -0.0012, -0.0006,  0.0000],\n",
      "        [ 0.0007,  0.0012,  0.0010,  ..., -0.0007, -0.0010,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'home', 'home', 'forest_path']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                     | 108/324 [00:09<00:17, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-2.7329e-02, -4.4575e-02, -3.7885e-02,  ..., -5.0550e-02,\n",
      "         -5.9066e-02,  0.0000e+00],\n",
      "        [-1.2358e-02, -1.9784e-02, -1.5354e-02,  ...,  7.7317e-03,\n",
      "          8.6601e-03,  0.0000e+00],\n",
      "        [-2.3824e-03, -4.0225e-03, -3.7028e-03,  ...,  6.2583e-03,\n",
      "          9.3642e-03,  0.0000e+00],\n",
      "        [ 1.9587e-04,  5.8258e-05,  4.4896e-04,  ..., -2.5939e-03,\n",
      "         -2.8500e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['train', 'grocery_store', 'tram', 'metro_station']}\n",
      "tensor([[-2.7329e-02, -4.4575e-02, -3.7885e-02,  ..., -5.0550e-02,\n",
      "         -5.9066e-02,  0.0000e+00],\n",
      "        [-1.2358e-02, -1.9784e-02, -1.5354e-02,  ...,  7.7317e-03,\n",
      "          8.6601e-03,  0.0000e+00],\n",
      "        [-2.3824e-03, -4.0225e-03, -3.7028e-03,  ...,  6.2583e-03,\n",
      "          9.3642e-03,  0.0000e+00],\n",
      "        [ 1.9587e-04,  5.8258e-05,  4.4896e-04,  ..., -2.5939e-03,\n",
      "         -2.8500e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['train', 'grocery_store', 'tram', 'metro_station']\n",
      "{'audio': tensor([[-3.5756e-03, -6.4475e-03, -4.8250e-03,  ..., -1.6154e-02,\n",
      "         -1.7077e-02,  0.0000e+00],\n",
      "        [ 3.3066e-04,  5.3647e-04,  1.7004e-04,  ...,  6.3724e-05,\n",
      "          1.1297e-04,  0.0000e+00],\n",
      "        [-2.2355e-03, -3.4469e-03, -6.1994e-04,  ...,  3.2656e-03,\n",
      "          2.7734e-03,  0.0000e+00],\n",
      "        [-1.6389e-03, -2.5665e-03, -2.0809e-03,  ...,  6.3642e-03,\n",
      "          7.1195e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'cafe/restaurant', 'beach', 'bus']}\n",
      "tensor([[-3.5756e-03, -6.4475e-03, -4.8250e-03,  ..., -1.6154e-02,\n",
      "         -1.7077e-02,  0.0000e+00],\n",
      "        [ 3.3066e-04,  5.3647e-04,  1.7004e-04,  ...,  6.3724e-05,\n",
      "          1.1297e-04,  0.0000e+00],\n",
      "        [-2.2355e-03, -3.4469e-03, -6.1994e-04,  ...,  3.2656e-03,\n",
      "          2.7734e-03,  0.0000e+00],\n",
      "        [-1.6389e-03, -2.5665e-03, -2.0809e-03,  ...,  6.3642e-03,\n",
      "          7.1195e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'cafe/restaurant', 'beach', 'bus']\n",
      "{'audio': tensor([[-6.6139e-04, -1.0030e-03, -9.2422e-04,  ..., -9.9169e-04,\n",
      "         -6.4387e-04,  0.0000e+00],\n",
      "        [-6.0563e-03, -1.2435e-02, -1.0403e-02,  ...,  1.1372e-02,\n",
      "          1.3784e-03,  0.0000e+00],\n",
      "        [-1.8701e-05, -6.2694e-05, -5.8961e-05,  ...,  2.0374e-04,\n",
      "          2.0054e-04,  0.0000e+00],\n",
      "        [ 1.4617e-03,  2.7577e-03,  3.0414e-03,  ...,  5.7159e-03,\n",
      "          6.5614e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'car', 'forest_path', 'grocery_store']}\n",
      "tensor([[-6.6139e-04, -1.0030e-03, -9.2422e-04,  ..., -9.9169e-04,\n",
      "         -6.4387e-04,  0.0000e+00],\n",
      "        [-6.0563e-03, -1.2435e-02, -1.0403e-02,  ...,  1.1372e-02,\n",
      "          1.3784e-03,  0.0000e+00],\n",
      "        [-1.8701e-05, -6.2694e-05, -5.8961e-05,  ...,  2.0374e-04,\n",
      "          2.0054e-04,  0.0000e+00],\n",
      "        [ 1.4617e-03,  2.7577e-03,  3.0414e-03,  ...,  5.7159e-03,\n",
      "          6.5614e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'car', 'forest_path', 'grocery_store']\n",
      "{'audio': tensor([[-0.0018,  0.0006,  0.0013,  ..., -0.0042, -0.0043,  0.0000],\n",
      "        [ 0.0074,  0.0119,  0.0103,  ...,  0.0150,  0.0171,  0.0000],\n",
      "        [ 0.0061,  0.0096,  0.0074,  ..., -0.0034, -0.0032,  0.0000],\n",
      "        [ 0.0024,  0.0036,  0.0024,  ..., -0.0036, -0.0035,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'bus', 'bus', 'beach']}\n",
      "tensor([[-0.0018,  0.0006,  0.0013,  ..., -0.0042, -0.0043,  0.0000],\n",
      "        [ 0.0074,  0.0119,  0.0103,  ...,  0.0150,  0.0171,  0.0000],\n",
      "        [ 0.0061,  0.0096,  0.0074,  ..., -0.0034, -0.0032,  0.0000],\n",
      "        [ 0.0024,  0.0036,  0.0024,  ..., -0.0036, -0.0035,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'bus', 'bus', 'beach']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 110/324 [00:09<00:17, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0040, -0.0065, -0.0072,  ...,  0.0097,  0.0107,  0.0000],\n",
      "        [-0.0098, -0.0169, -0.0144,  ..., -0.0773, -0.0957,  0.0000],\n",
      "        [ 0.0007,  0.0009,  0.0017,  ...,  0.0015,  0.0016,  0.0000],\n",
      "        [-0.0003, -0.0006, -0.0006,  ...,  0.0009,  0.0011,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['grocery_store', 'train', 'residential_area', 'library']}\n",
      "tensor([[-0.0040, -0.0065, -0.0072,  ...,  0.0097,  0.0107,  0.0000],\n",
      "        [-0.0098, -0.0169, -0.0144,  ..., -0.0773, -0.0957,  0.0000],\n",
      "        [ 0.0007,  0.0009,  0.0017,  ...,  0.0015,  0.0016,  0.0000],\n",
      "        [-0.0003, -0.0006, -0.0006,  ...,  0.0009,  0.0011,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['grocery_store', 'train', 'residential_area', 'library']\n",
      "{'audio': tensor([[-2.5343e-03, -5.1744e-03, -5.2470e-03,  ...,  7.8379e-03,\n",
      "          1.1474e-02,  0.0000e+00],\n",
      "        [-1.5950e-02, -2.6810e-02, -2.3568e-02,  ..., -3.0914e-03,\n",
      "         -3.6492e-03,  0.0000e+00],\n",
      "        [ 3.7226e-04, -3.1165e-05, -8.4141e-04,  ...,  1.1154e-03,\n",
      "          1.2507e-03,  0.0000e+00],\n",
      "        [-5.2815e-03, -9.5932e-03, -1.0058e-02,  ..., -1.2344e-03,\n",
      "         -1.5018e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['cafe/restaurant', 'car', 'cafe/restaurant', 'grocery_store']}\n",
      "tensor([[-2.5343e-03, -5.1744e-03, -5.2470e-03,  ...,  7.8379e-03,\n",
      "          1.1474e-02,  0.0000e+00],\n",
      "        [-1.5950e-02, -2.6810e-02, -2.3568e-02,  ..., -3.0914e-03,\n",
      "         -3.6492e-03,  0.0000e+00],\n",
      "        [ 3.7226e-04, -3.1165e-05, -8.4141e-04,  ...,  1.1154e-03,\n",
      "          1.2507e-03,  0.0000e+00],\n",
      "        [-5.2815e-03, -9.5932e-03, -1.0058e-02,  ..., -1.2344e-03,\n",
      "         -1.5018e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['cafe/restaurant', 'car', 'cafe/restaurant', 'grocery_store']\n",
      "{'audio': tensor([[ 5.9964e-05,  1.2869e-04,  1.1753e-04,  ..., -5.3113e-06,\n",
      "          3.1807e-05,  0.0000e+00],\n",
      "        [-4.9540e-03, -7.6580e-03, -5.7111e-03,  ..., -7.2410e-04,\n",
      "          5.4324e-04,  0.0000e+00],\n",
      "        [-7.5322e-06, -5.3116e-04, -6.2258e-04,  ..., -1.7275e-03,\n",
      "         -1.8120e-03,  0.0000e+00],\n",
      "        [ 4.5613e-04,  7.5833e-04,  6.6684e-04,  ..., -9.6873e-05,\n",
      "         -4.4374e-05,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'bus', 'train', 'library']}\n",
      "tensor([[ 5.9964e-05,  1.2869e-04,  1.1753e-04,  ..., -5.3113e-06,\n",
      "          3.1807e-05,  0.0000e+00],\n",
      "        [-4.9540e-03, -7.6580e-03, -5.7111e-03,  ..., -7.2410e-04,\n",
      "          5.4324e-04,  0.0000e+00],\n",
      "        [-7.5322e-06, -5.3116e-04, -6.2258e-04,  ..., -1.7275e-03,\n",
      "         -1.8120e-03,  0.0000e+00],\n",
      "        [ 4.5613e-04,  7.5833e-04,  6.6684e-04,  ..., -9.6873e-05,\n",
      "         -4.4374e-05,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'bus', 'train', 'library']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 114/324 [00:09<00:18, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0022, -0.0021,  0.0004,  ..., -0.0006, -0.0002,  0.0000],\n",
      "        [ 0.0078,  0.0132,  0.0189,  ...,  0.0109,  0.0061,  0.0000],\n",
      "        [ 0.0011,  0.0020,  0.0016,  ..., -0.0005, -0.0012,  0.0000],\n",
      "        [-0.0002, -0.0001,  0.0003,  ..., -0.0065, -0.0075,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['home', 'train', 'park', 'train']}\n",
      "tensor([[-0.0022, -0.0021,  0.0004,  ..., -0.0006, -0.0002,  0.0000],\n",
      "        [ 0.0078,  0.0132,  0.0189,  ...,  0.0109,  0.0061,  0.0000],\n",
      "        [ 0.0011,  0.0020,  0.0016,  ..., -0.0005, -0.0012,  0.0000],\n",
      "        [-0.0002, -0.0001,  0.0003,  ..., -0.0065, -0.0075,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['home', 'train', 'park', 'train']\n",
      "{'audio': tensor([[-0.0029, -0.0045, -0.0057,  ..., -0.0018, -0.0005,  0.0000],\n",
      "        [ 0.0032,  0.0056,  0.0050,  ...,  0.0024,  0.0028,  0.0000],\n",
      "        [-0.0025, -0.0083, -0.0107,  ...,  0.0021,  0.0028,  0.0000],\n",
      "        [-0.0004, -0.0007, -0.0007,  ...,  0.0003,  0.0003,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['beach', 'residential_area', 'residential_area', 'forest_path']}\n",
      "tensor([[-0.0029, -0.0045, -0.0057,  ..., -0.0018, -0.0005,  0.0000],\n",
      "        [ 0.0032,  0.0056,  0.0050,  ...,  0.0024,  0.0028,  0.0000],\n",
      "        [-0.0025, -0.0083, -0.0107,  ...,  0.0021,  0.0028,  0.0000],\n",
      "        [-0.0004, -0.0007, -0.0007,  ...,  0.0003,  0.0003,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['beach', 'residential_area', 'residential_area', 'forest_path']\n",
      "{'audio': tensor([[ 7.3692e-05,  1.1145e-04, -1.3133e-05,  ..., -5.6006e-04,\n",
      "         -6.1772e-04,  0.0000e+00],\n",
      "        [ 1.5325e-03,  2.6130e-03,  2.4122e-03,  ..., -2.0816e-03,\n",
      "         -2.0660e-03,  0.0000e+00],\n",
      "        [ 4.7883e-05,  7.7911e-05,  7.9249e-05,  ...,  5.7969e-04,\n",
      "          5.4016e-04,  0.0000e+00],\n",
      "        [ 4.5212e-03,  7.2562e-03,  3.9026e-03,  ...,  5.8424e-03,\n",
      "          5.9693e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['home', 'park', 'library', 'park']}\n",
      "tensor([[ 7.3692e-05,  1.1145e-04, -1.3133e-05,  ..., -5.6006e-04,\n",
      "         -6.1772e-04,  0.0000e+00],\n",
      "        [ 1.5325e-03,  2.6130e-03,  2.4122e-03,  ..., -2.0816e-03,\n",
      "         -2.0660e-03,  0.0000e+00],\n",
      "        [ 4.7883e-05,  7.7911e-05,  7.9249e-05,  ...,  5.7969e-04,\n",
      "          5.4016e-04,  0.0000e+00],\n",
      "        [ 4.5212e-03,  7.2562e-03,  3.9026e-03,  ...,  5.8424e-03,\n",
      "          5.9693e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['home', 'park', 'library', 'park']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                   | 116/324 [00:09<00:17, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-4.5132e-08,  1.3490e-05,  1.2615e-05,  ..., -2.3443e-04,\n",
      "         -2.4858e-04,  0.0000e+00],\n",
      "        [-5.4068e-04, -4.9715e-04, -1.4847e-04,  ..., -8.5489e-04,\n",
      "         -7.1828e-04,  0.0000e+00],\n",
      "        [-1.8882e-03, -3.8591e-03,  2.5352e-03,  ...,  8.4823e-05,\n",
      "          2.5315e-03,  0.0000e+00],\n",
      "        [-1.4619e-03, -2.5374e-03, -1.9500e-03,  ...,  1.6359e-03,\n",
      "          2.1893e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'home', 'park', 'grocery_store']}\n",
      "tensor([[-4.5132e-08,  1.3490e-05,  1.2615e-05,  ..., -2.3443e-04,\n",
      "         -2.4858e-04,  0.0000e+00],\n",
      "        [-5.4068e-04, -4.9715e-04, -1.4847e-04,  ..., -8.5489e-04,\n",
      "         -7.1828e-04,  0.0000e+00],\n",
      "        [-1.8882e-03, -3.8591e-03,  2.5352e-03,  ...,  8.4823e-05,\n",
      "          2.5315e-03,  0.0000e+00],\n",
      "        [-1.4619e-03, -2.5374e-03, -1.9500e-03,  ...,  1.6359e-03,\n",
      "          2.1893e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'home', 'park', 'grocery_store']\n",
      "{'audio': tensor([[-4.3006e-03, -7.2180e-03, -6.2406e-03,  ...,  6.0214e-03,\n",
      "          6.2457e-03,  0.0000e+00],\n",
      "        [-6.5165e-03, -1.0300e-02, -9.2356e-03,  ...,  1.1122e-03,\n",
      "          9.7833e-04,  0.0000e+00],\n",
      "        [-2.7050e-02, -4.4576e-02, -3.8209e-02,  ...,  2.8943e-02,\n",
      "          3.2499e-02,  0.0000e+00],\n",
      "        [-1.2316e-05, -4.4861e-05, -1.5721e-05,  ..., -4.8743e-04,\n",
      "         -5.1730e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'car', 'train', 'library']}\n",
      "tensor([[-4.3006e-03, -7.2180e-03, -6.2406e-03,  ...,  6.0214e-03,\n",
      "          6.2457e-03,  0.0000e+00],\n",
      "        [-6.5165e-03, -1.0300e-02, -9.2356e-03,  ...,  1.1122e-03,\n",
      "          9.7833e-04,  0.0000e+00],\n",
      "        [-2.7050e-02, -4.4576e-02, -3.8209e-02,  ...,  2.8943e-02,\n",
      "          3.2499e-02,  0.0000e+00],\n",
      "        [-1.2316e-05, -4.4861e-05, -1.5721e-05,  ..., -4.8743e-04,\n",
      "         -5.1730e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'car', 'train', 'library']\n",
      "{'audio': tensor([[ 8.7896e-03,  1.4504e-02,  1.2634e-02,  ...,  1.0957e-02,\n",
      "          1.1517e-02,  0.0000e+00],\n",
      "        [-1.7835e-03, -3.3468e-03, -3.5235e-03,  ...,  3.5670e-02,\n",
      "          4.1737e-02,  0.0000e+00],\n",
      "        [ 6.1991e-05, -2.8849e-04,  1.2753e-04,  ...,  2.4282e-03,\n",
      "          2.7198e-03,  0.0000e+00],\n",
      "        [-2.0035e-03, -2.6744e-03, -3.9117e-03,  ..., -3.0874e-04,\n",
      "         -4.1838e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['train', 'bus', 'tram', 'office']}\n",
      "tensor([[ 8.7896e-03,  1.4504e-02,  1.2634e-02,  ...,  1.0957e-02,\n",
      "          1.1517e-02,  0.0000e+00],\n",
      "        [-1.7835e-03, -3.3468e-03, -3.5235e-03,  ...,  3.5670e-02,\n",
      "          4.1737e-02,  0.0000e+00],\n",
      "        [ 6.1991e-05, -2.8849e-04,  1.2753e-04,  ...,  2.4282e-03,\n",
      "          2.7198e-03,  0.0000e+00],\n",
      "        [-2.0035e-03, -2.6744e-03, -3.9117e-03,  ..., -3.0874e-04,\n",
      "         -4.1838e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['train', 'bus', 'tram', 'office']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                  | 120/324 [00:10<00:15, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 8.2888e-05,  1.7292e-04,  1.2113e-04,  ..., -1.0264e-04,\n",
      "         -1.2307e-04,  0.0000e+00],\n",
      "        [-2.8906e-04, -1.2109e-03, -5.4911e-04,  ...,  1.6705e-03,\n",
      "          2.5375e-03,  0.0000e+00],\n",
      "        [-4.9044e-04, -9.3949e-04, -5.6104e-04,  ...,  6.7080e-04,\n",
      "          4.3754e-04,  0.0000e+00],\n",
      "        [-4.3667e-03, -7.1545e-03, -6.4293e-03,  ...,  2.3105e-03,\n",
      "          1.5833e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'park', 'home', 'bus']}\n",
      "tensor([[ 8.2888e-05,  1.7292e-04,  1.2113e-04,  ..., -1.0264e-04,\n",
      "         -1.2307e-04,  0.0000e+00],\n",
      "        [-2.8906e-04, -1.2109e-03, -5.4911e-04,  ...,  1.6705e-03,\n",
      "          2.5375e-03,  0.0000e+00],\n",
      "        [-4.9044e-04, -9.3949e-04, -5.6104e-04,  ...,  6.7080e-04,\n",
      "          4.3754e-04,  0.0000e+00],\n",
      "        [-4.3667e-03, -7.1545e-03, -6.4293e-03,  ...,  2.3105e-03,\n",
      "          1.5833e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'park', 'home', 'bus']\n",
      "{'audio': tensor([[ 7.4295e-04,  1.1570e-03,  7.4769e-04,  ..., -3.2760e-04,\n",
      "         -3.5017e-04,  0.0000e+00],\n",
      "        [-9.0106e-06, -4.2357e-04, -7.5724e-04,  ..., -1.0918e-04,\n",
      "         -1.5743e-04,  0.0000e+00],\n",
      "        [-8.4833e-04, -1.3933e-03, -1.3231e-03,  ...,  9.5768e-04,\n",
      "          8.9383e-04,  0.0000e+00],\n",
      "        [ 5.8403e-03,  9.6581e-03,  8.6262e-03,  ...,  2.0291e-02,\n",
      "          2.3647e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'forest_path', 'forest_path', 'bus']}\n",
      "tensor([[ 7.4295e-04,  1.1570e-03,  7.4769e-04,  ..., -3.2760e-04,\n",
      "         -3.5017e-04,  0.0000e+00],\n",
      "        [-9.0106e-06, -4.2357e-04, -7.5724e-04,  ..., -1.0918e-04,\n",
      "         -1.5743e-04,  0.0000e+00],\n",
      "        [-8.4833e-04, -1.3933e-03, -1.3231e-03,  ...,  9.5768e-04,\n",
      "          8.9383e-04,  0.0000e+00],\n",
      "        [ 5.8403e-03,  9.6581e-03,  8.6262e-03,  ...,  2.0291e-02,\n",
      "          2.3647e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'forest_path', 'forest_path', 'bus']\n",
      "{'audio': tensor([[ 3.7546e-02,  6.2676e-02,  5.4765e-02,  ..., -4.2864e-02,\n",
      "         -4.9731e-02,  0.0000e+00],\n",
      "        [ 1.9770e-04,  5.9876e-04,  7.8083e-04,  ..., -1.8926e-03,\n",
      "         -2.3852e-03,  0.0000e+00],\n",
      "        [-1.5861e-03, -3.1990e-03, -3.2164e-03,  ...,  7.2826e-03,\n",
      "          8.4190e-03,  0.0000e+00],\n",
      "        [ 2.5029e-05, -2.1255e-05, -3.9757e-05,  ..., -2.0222e-04,\n",
      "         -2.3370e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'grocery_store', 'residential_area', 'office']}\n",
      "tensor([[ 3.7546e-02,  6.2676e-02,  5.4765e-02,  ..., -4.2864e-02,\n",
      "         -4.9731e-02,  0.0000e+00],\n",
      "        [ 1.9770e-04,  5.9876e-04,  7.8083e-04,  ..., -1.8926e-03,\n",
      "         -2.3852e-03,  0.0000e+00],\n",
      "        [-1.5861e-03, -3.1990e-03, -3.2164e-03,  ...,  7.2826e-03,\n",
      "          8.4190e-03,  0.0000e+00],\n",
      "        [ 2.5029e-05, -2.1255e-05, -3.9757e-05,  ..., -2.0222e-04,\n",
      "         -2.3370e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'grocery_store', 'residential_area', 'office']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                 | 124/324 [00:10<00:14, 13.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 2.8564e-02,  4.8959e-02,  4.4242e-02,  ..., -2.2525e-02,\n",
      "         -2.7673e-02,  0.0000e+00],\n",
      "        [-2.8650e-04, -6.3224e-05,  3.6205e-04,  ..., -2.2707e-03,\n",
      "         -2.2584e-03,  0.0000e+00],\n",
      "        [-2.1448e-05,  9.6860e-05,  5.1283e-05,  ..., -9.7297e-04,\n",
      "         -7.8018e-04,  0.0000e+00],\n",
      "        [ 5.9606e-03,  9.7654e-03,  8.3883e-03,  ...,  1.8055e-03,\n",
      "          2.2511e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'bus', 'forest_path', 'metro_station']}\n",
      "tensor([[ 2.8564e-02,  4.8959e-02,  4.4242e-02,  ..., -2.2525e-02,\n",
      "         -2.7673e-02,  0.0000e+00],\n",
      "        [-2.8650e-04, -6.3224e-05,  3.6205e-04,  ..., -2.2707e-03,\n",
      "         -2.2584e-03,  0.0000e+00],\n",
      "        [-2.1448e-05,  9.6860e-05,  5.1283e-05,  ..., -9.7297e-04,\n",
      "         -7.8018e-04,  0.0000e+00],\n",
      "        [ 5.9606e-03,  9.7654e-03,  8.3883e-03,  ...,  1.8055e-03,\n",
      "          2.2511e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'bus', 'forest_path', 'metro_station']\n",
      "{'audio': tensor([[ 0.0003,  0.0002,  0.0001,  ...,  0.0410,  0.0476,  0.0000],\n",
      "        [ 0.0057,  0.0097,  0.0089,  ..., -0.0662, -0.0758,  0.0000],\n",
      "        [ 0.0009,  0.0021,  0.0024,  ...,  0.0014,  0.0037,  0.0000],\n",
      "        [ 0.0073,  0.0131,  0.0133,  ..., -0.0118, -0.0125,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'car', 'metro_station', 'cafe/restaurant']}\n",
      "tensor([[ 0.0003,  0.0002,  0.0001,  ...,  0.0410,  0.0476,  0.0000],\n",
      "        [ 0.0057,  0.0097,  0.0089,  ..., -0.0662, -0.0758,  0.0000],\n",
      "        [ 0.0009,  0.0021,  0.0024,  ...,  0.0014,  0.0037,  0.0000],\n",
      "        [ 0.0073,  0.0131,  0.0133,  ..., -0.0118, -0.0125,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'car', 'metro_station', 'cafe/restaurant']\n",
      "{'audio': tensor([[ 2.7118e-04,  4.6669e-04,  3.8242e-04,  ...,  6.0452e-04,\n",
      "          6.3567e-04,  0.0000e+00],\n",
      "        [-4.9092e-04, -6.5136e-04, -6.1458e-04,  ..., -9.2808e-04,\n",
      "         -9.4216e-04,  0.0000e+00],\n",
      "        [-1.4935e-04, -1.4724e-04, -1.9906e-05,  ..., -3.0852e-05,\n",
      "          4.4114e-06,  0.0000e+00],\n",
      "        [ 3.1799e-04,  6.4235e-04,  5.8188e-04,  ...,  1.1954e-04,\n",
      "          3.1466e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'forest_path', 'forest_path', 'office']}\n",
      "tensor([[ 2.7118e-04,  4.6669e-04,  3.8242e-04,  ...,  6.0452e-04,\n",
      "          6.3567e-04,  0.0000e+00],\n",
      "        [-4.9092e-04, -6.5136e-04, -6.1458e-04,  ..., -9.2808e-04,\n",
      "         -9.4216e-04,  0.0000e+00],\n",
      "        [-1.4935e-04, -1.4724e-04, -1.9906e-05,  ..., -3.0852e-05,\n",
      "          4.4114e-06,  0.0000e+00],\n",
      "        [ 3.1799e-04,  6.4235e-04,  5.8188e-04,  ...,  1.1954e-04,\n",
      "          3.1466e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'forest_path', 'forest_path', 'office']\n",
      "{'audio': tensor([[-6.0204e-05, -1.1756e-04, -1.0717e-04,  ..., -1.9348e-05,\n",
      "         -2.8417e-05,  0.0000e+00],\n",
      "        [-1.9820e-03, -3.0267e-03, -2.4503e-03,  ..., -4.2031e-03,\n",
      "         -5.2547e-03,  0.0000e+00],\n",
      "        [ 3.7505e-05,  2.5371e-04,  6.3101e-04,  ...,  6.1435e-04,\n",
      "          9.6322e-04,  0.0000e+00],\n",
      "        [ 1.5923e-04,  2.6893e-04,  2.2882e-04,  ...,  2.3562e-05,\n",
      "          8.0384e-05,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'cafe/restaurant', 'residential_area', 'residential_area']}\n",
      "tensor([[-6.0204e-05, -1.1756e-04, -1.0717e-04,  ..., -1.9348e-05,\n",
      "         -2.8417e-05,  0.0000e+00],\n",
      "        [-1.9820e-03, -3.0267e-03, -2.4503e-03,  ..., -4.2031e-03,\n",
      "         -5.2547e-03,  0.0000e+00],\n",
      "        [ 3.7505e-05,  2.5371e-04,  6.3101e-04,  ...,  6.1435e-04,\n",
      "          9.6322e-04,  0.0000e+00],\n",
      "        [ 1.5923e-04,  2.6893e-04,  2.2882e-04,  ...,  2.3562e-05,\n",
      "          8.0384e-05,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'cafe/restaurant', 'residential_area', 'residential_area']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                 | 126/324 [00:10<00:15, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 1.2635e-02,  2.1573e-02,  1.9848e-02,  ..., -1.2623e-02,\n",
      "         -1.3489e-02,  0.0000e+00],\n",
      "        [-3.9275e-02, -6.5410e-02, -5.5991e-02,  ...,  1.8763e-02,\n",
      "          2.2289e-02,  0.0000e+00],\n",
      "        [ 2.4633e-03,  4.3278e-03,  3.4019e-03,  ..., -1.8914e-03,\n",
      "         -1.4184e-03,  0.0000e+00],\n",
      "        [-1.1000e-04, -1.3281e-04, -9.7020e-05,  ...,  2.6914e-04,\n",
      "          2.4544e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'train', 'cafe/restaurant', 'home']}\n",
      "tensor([[ 1.2635e-02,  2.1573e-02,  1.9848e-02,  ..., -1.2623e-02,\n",
      "         -1.3489e-02,  0.0000e+00],\n",
      "        [-3.9275e-02, -6.5410e-02, -5.5991e-02,  ...,  1.8763e-02,\n",
      "          2.2289e-02,  0.0000e+00],\n",
      "        [ 2.4633e-03,  4.3278e-03,  3.4019e-03,  ..., -1.8914e-03,\n",
      "         -1.4184e-03,  0.0000e+00],\n",
      "        [-1.1000e-04, -1.3281e-04, -9.7020e-05,  ...,  2.6914e-04,\n",
      "          2.4544e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'train', 'cafe/restaurant', 'home']\n",
      "{'audio': tensor([[ 1.2244e-04,  1.9464e-04,  1.7422e-04,  ...,  1.5977e-05,\n",
      "          1.0625e-05,  0.0000e+00],\n",
      "        [ 2.7591e-03,  4.9313e-03,  4.7165e-03,  ..., -2.5166e-03,\n",
      "         -3.2422e-03,  0.0000e+00],\n",
      "        [ 3.6879e-02,  6.6874e-02,  6.3807e-02,  ..., -4.0959e-02,\n",
      "         -3.8913e-02,  0.0000e+00],\n",
      "        [-2.8435e-04, -6.5578e-04, -3.6375e-04,  ...,  2.5477e-04,\n",
      "          2.3737e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'park', 'tram', 'residential_area']}\n",
      "tensor([[ 1.2244e-04,  1.9464e-04,  1.7422e-04,  ...,  1.5977e-05,\n",
      "          1.0625e-05,  0.0000e+00],\n",
      "        [ 2.7591e-03,  4.9313e-03,  4.7165e-03,  ..., -2.5166e-03,\n",
      "         -3.2422e-03,  0.0000e+00],\n",
      "        [ 3.6879e-02,  6.6874e-02,  6.3807e-02,  ..., -4.0959e-02,\n",
      "         -3.8913e-02,  0.0000e+00],\n",
      "        [-2.8435e-04, -6.5578e-04, -3.6375e-04,  ...,  2.5477e-04,\n",
      "          2.3737e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'park', 'tram', 'residential_area']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                | 128/324 [00:10<00:15, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-7.9205e-05, -1.9924e-04, -2.6054e-04,  ...,  1.4583e-04,\n",
      "          6.5611e-05,  0.0000e+00],\n",
      "        [-8.8913e-04, -1.2288e-03, -9.6443e-04,  ...,  2.8787e-03,\n",
      "          3.2783e-03,  0.0000e+00],\n",
      "        [-2.5094e-04,  5.6331e-04,  4.2301e-04,  ..., -1.2925e-03,\n",
      "         -3.2561e-04,  0.0000e+00],\n",
      "        [-2.5817e-04,  5.8412e-04,  1.1394e-03,  ...,  2.5335e-03,\n",
      "          1.0816e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'home', 'beach', 'beach']}\n",
      "tensor([[-7.9205e-05, -1.9924e-04, -2.6054e-04,  ...,  1.4583e-04,\n",
      "          6.5611e-05,  0.0000e+00],\n",
      "        [-8.8913e-04, -1.2288e-03, -9.6443e-04,  ...,  2.8787e-03,\n",
      "          3.2783e-03,  0.0000e+00],\n",
      "        [-2.5094e-04,  5.6331e-04,  4.2301e-04,  ..., -1.2925e-03,\n",
      "         -3.2561e-04,  0.0000e+00],\n",
      "        [-2.5817e-04,  5.8412e-04,  1.1394e-03,  ...,  2.5335e-03,\n",
      "          1.0816e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'home', 'beach', 'beach']\n",
      "{'audio': tensor([[-1.3317e-04, -2.0444e-04, -1.9480e-04,  ..., -2.0087e-04,\n",
      "         -2.3727e-04,  0.0000e+00],\n",
      "        [-2.5184e-04, -2.0246e-04, -6.7617e-05,  ..., -1.4186e-03,\n",
      "         -1.3560e-03,  0.0000e+00],\n",
      "        [ 1.8900e-03,  3.0485e-03,  2.3396e-03,  ..., -5.6073e-02,\n",
      "         -6.3200e-02,  0.0000e+00],\n",
      "        [ 2.0891e-04,  3.7931e-04,  3.1192e-04,  ...,  1.6623e-04,\n",
      "          2.3809e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'park', 'bus', 'office']}\n",
      "tensor([[-1.3317e-04, -2.0444e-04, -1.9480e-04,  ..., -2.0087e-04,\n",
      "         -2.3727e-04,  0.0000e+00],\n",
      "        [-2.5184e-04, -2.0246e-04, -6.7617e-05,  ..., -1.4186e-03,\n",
      "         -1.3560e-03,  0.0000e+00],\n",
      "        [ 1.8900e-03,  3.0485e-03,  2.3396e-03,  ..., -5.6073e-02,\n",
      "         -6.3200e-02,  0.0000e+00],\n",
      "        [ 2.0891e-04,  3.7931e-04,  3.1192e-04,  ...,  1.6623e-04,\n",
      "          2.3809e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'park', 'bus', 'office']\n",
      "{'audio': tensor([[ 5.1906e-03,  8.7005e-03,  7.3231e-03,  ...,  1.1656e-02,\n",
      "          1.1810e-02,  0.0000e+00],\n",
      "        [ 5.7237e-05,  2.3858e-05, -4.1021e-05,  ..., -6.4423e-04,\n",
      "         -9.5412e-04,  0.0000e+00],\n",
      "        [-4.2060e-04, -1.9233e-03, -2.6437e-03,  ..., -7.4933e-03,\n",
      "         -7.9966e-03,  0.0000e+00],\n",
      "        [ 1.6251e-03,  2.5613e-03,  1.5395e-03,  ...,  2.0456e-03,\n",
      "          5.5316e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'forest_path', 'grocery_store', 'metro_station']}\n",
      "tensor([[ 5.1906e-03,  8.7005e-03,  7.3231e-03,  ...,  1.1656e-02,\n",
      "          1.1810e-02,  0.0000e+00],\n",
      "        [ 5.7237e-05,  2.3858e-05, -4.1021e-05,  ..., -6.4423e-04,\n",
      "         -9.5412e-04,  0.0000e+00],\n",
      "        [-4.2060e-04, -1.9233e-03, -2.6437e-03,  ..., -7.4933e-03,\n",
      "         -7.9966e-03,  0.0000e+00],\n",
      "        [ 1.6251e-03,  2.5613e-03,  1.5395e-03,  ...,  2.0456e-03,\n",
      "          5.5316e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'forest_path', 'grocery_store', 'metro_station']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                | 130/324 [00:10<00:15, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0171, -0.0286, -0.0248,  ..., -0.0179, -0.0192,  0.0000],\n",
      "        [-0.0008, -0.0012, -0.0011,  ...,  0.0005,  0.0011,  0.0000],\n",
      "        [ 0.0051,  0.0105,  0.0099,  ...,  0.0014,  0.0013,  0.0000],\n",
      "        [-0.0057, -0.0101, -0.0089,  ...,  0.0066,  0.0085,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'metro_station', 'beach', 'car']}\n",
      "tensor([[-0.0171, -0.0286, -0.0248,  ..., -0.0179, -0.0192,  0.0000],\n",
      "        [-0.0008, -0.0012, -0.0011,  ...,  0.0005,  0.0011,  0.0000],\n",
      "        [ 0.0051,  0.0105,  0.0099,  ...,  0.0014,  0.0013,  0.0000],\n",
      "        [-0.0057, -0.0101, -0.0089,  ...,  0.0066,  0.0085,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'metro_station', 'beach', 'car']\n",
      "{'audio': tensor([[-0.0010, -0.0019, -0.0017,  ...,  0.0100,  0.0116,  0.0000],\n",
      "        [ 0.0011,  0.0020,  0.0018,  ..., -0.0007, -0.0011,  0.0000],\n",
      "        [ 0.0058,  0.0090,  0.0066,  ..., -0.0114, -0.0162,  0.0000],\n",
      "        [ 0.0044,  0.0087,  0.0097,  ...,  0.0082,  0.0105,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['train', 'city_center', 'metro_station', 'park']}\n",
      "tensor([[-0.0010, -0.0019, -0.0017,  ...,  0.0100,  0.0116,  0.0000],\n",
      "        [ 0.0011,  0.0020,  0.0018,  ..., -0.0007, -0.0011,  0.0000],\n",
      "        [ 0.0058,  0.0090,  0.0066,  ..., -0.0114, -0.0162,  0.0000],\n",
      "        [ 0.0044,  0.0087,  0.0097,  ...,  0.0082,  0.0105,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['train', 'city_center', 'metro_station', 'park']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                               | 134/324 [00:11<00:15, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-1.4102e-03, -4.6655e-03, -6.0874e-03,  ...,  2.6774e-02,\n",
      "          2.2964e-02,  0.0000e+00],\n",
      "        [-7.0641e-04, -5.3973e-04,  1.2927e-04,  ..., -2.6561e-03,\n",
      "         -3.9117e-03,  0.0000e+00],\n",
      "        [-5.5248e-04, -6.8050e-04, -3.3667e-04,  ...,  2.9443e-04,\n",
      "         -4.1025e-05,  0.0000e+00],\n",
      "        [-7.9357e-02, -1.3465e-01, -1.2139e-01,  ..., -7.6044e-02,\n",
      "         -8.4747e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'grocery_store', 'residential_area', 'train']}\n",
      "tensor([[-1.4102e-03, -4.6655e-03, -6.0874e-03,  ...,  2.6774e-02,\n",
      "          2.2964e-02,  0.0000e+00],\n",
      "        [-7.0641e-04, -5.3973e-04,  1.2927e-04,  ..., -2.6561e-03,\n",
      "         -3.9117e-03,  0.0000e+00],\n",
      "        [-5.5248e-04, -6.8050e-04, -3.3667e-04,  ...,  2.9443e-04,\n",
      "         -4.1025e-05,  0.0000e+00],\n",
      "        [-7.9357e-02, -1.3465e-01, -1.2139e-01,  ..., -7.6044e-02,\n",
      "         -8.4747e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'grocery_store', 'residential_area', 'train']\n",
      "{'audio': tensor([[-6.8992e-04,  1.2375e-03,  5.5122e-03,  ...,  3.8238e-03,\n",
      "          9.6723e-04,  0.0000e+00],\n",
      "        [-2.3830e-03, -4.3252e-03, -3.2575e-03,  ...,  1.6846e-03,\n",
      "          2.4831e-03,  0.0000e+00],\n",
      "        [ 5.9297e-03,  9.3102e-03,  8.0996e-03,  ..., -4.3774e-03,\n",
      "         -5.6291e-03,  0.0000e+00],\n",
      "        [ 2.8028e-04,  3.3658e-04,  6.4629e-06,  ...,  8.5842e-04,\n",
      "          7.2150e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['home', 'beach', 'tram', 'office']}\n",
      "tensor([[-6.8992e-04,  1.2375e-03,  5.5122e-03,  ...,  3.8238e-03,\n",
      "          9.6723e-04,  0.0000e+00],\n",
      "        [-2.3830e-03, -4.3252e-03, -3.2575e-03,  ...,  1.6846e-03,\n",
      "          2.4831e-03,  0.0000e+00],\n",
      "        [ 5.9297e-03,  9.3102e-03,  8.0996e-03,  ..., -4.3774e-03,\n",
      "         -5.6291e-03,  0.0000e+00],\n",
      "        [ 2.8028e-04,  3.3658e-04,  6.4629e-06,  ...,  8.5842e-04,\n",
      "          7.2150e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['home', 'beach', 'tram', 'office']\n",
      "{'audio': tensor([[-0.0063, -0.0096, -0.0061,  ...,  0.0668,  0.0748,  0.0000],\n",
      "        [ 0.0026,  0.0034,  0.0022,  ..., -0.0025, -0.0032,  0.0000],\n",
      "        [ 0.0017,  0.0040,  0.0050,  ...,  0.0018,  0.0019,  0.0000],\n",
      "        [ 0.0253,  0.0351,  0.0238,  ...,  0.0497,  0.0507,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['train', 'city_center', 'tram', 'train']}\n",
      "tensor([[-0.0063, -0.0096, -0.0061,  ...,  0.0668,  0.0748,  0.0000],\n",
      "        [ 0.0026,  0.0034,  0.0022,  ..., -0.0025, -0.0032,  0.0000],\n",
      "        [ 0.0017,  0.0040,  0.0050,  ...,  0.0018,  0.0019,  0.0000],\n",
      "        [ 0.0253,  0.0351,  0.0238,  ...,  0.0497,  0.0507,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['train', 'city_center', 'tram', 'train']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                              | 136/324 [00:11<00:14, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0043, -0.0073, -0.0059,  ..., -0.0098, -0.0103,  0.0000],\n",
      "        [-0.0005, -0.0008, -0.0007,  ..., -0.0003,  0.0006,  0.0000],\n",
      "        [-0.0002, -0.0002, -0.0001,  ..., -0.0002, -0.0002,  0.0000],\n",
      "        [-0.0008, -0.0001, -0.0008,  ...,  0.0011,  0.0029,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'home', 'metro_station', 'beach']}\n",
      "tensor([[-0.0043, -0.0073, -0.0059,  ..., -0.0098, -0.0103,  0.0000],\n",
      "        [-0.0005, -0.0008, -0.0007,  ..., -0.0003,  0.0006,  0.0000],\n",
      "        [-0.0002, -0.0002, -0.0001,  ..., -0.0002, -0.0002,  0.0000],\n",
      "        [-0.0008, -0.0001, -0.0008,  ...,  0.0011,  0.0029,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'home', 'metro_station', 'beach']\n",
      "{'audio': tensor([[ 4.8054e-04,  7.4235e-04,  1.3446e-03,  ...,  2.8756e-04,\n",
      "         -3.8453e-05,  0.0000e+00],\n",
      "        [-4.8053e-03, -7.1961e-03, -5.6463e-03,  ..., -4.8795e-03,\n",
      "         -8.0332e-03,  0.0000e+00],\n",
      "        [-2.3416e-03, -3.2600e-03, -1.7215e-03,  ..., -4.1011e-03,\n",
      "         -4.5660e-03,  0.0000e+00],\n",
      "        [-3.5322e-03, -5.7558e-03, -4.8474e-03,  ..., -2.4729e-03,\n",
      "         -2.2785e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'park', 'city_center', 'grocery_store']}\n",
      "tensor([[ 4.8054e-04,  7.4235e-04,  1.3446e-03,  ...,  2.8756e-04,\n",
      "         -3.8453e-05,  0.0000e+00],\n",
      "        [-4.8053e-03, -7.1961e-03, -5.6463e-03,  ..., -4.8795e-03,\n",
      "         -8.0332e-03,  0.0000e+00],\n",
      "        [-2.3416e-03, -3.2600e-03, -1.7215e-03,  ..., -4.1011e-03,\n",
      "         -4.5660e-03,  0.0000e+00],\n",
      "        [-3.5322e-03, -5.7558e-03, -4.8474e-03,  ..., -2.4729e-03,\n",
      "         -2.2785e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'park', 'city_center', 'grocery_store']\n",
      "{'audio': tensor([[-2.1460e-04, -9.4677e-05, -3.2678e-05,  ..., -4.2395e-04,\n",
      "         -4.8082e-04,  0.0000e+00],\n",
      "        [-8.2791e-05, -4.1678e-05, -6.7669e-05,  ...,  2.7714e-04,\n",
      "          2.9989e-04,  0.0000e+00],\n",
      "        [ 2.5845e-03,  2.2617e-04, -5.5673e-03,  ..., -6.2449e-03,\n",
      "         -1.7266e-03,  0.0000e+00],\n",
      "        [ 1.9824e-02,  3.3739e-02,  3.0085e-02,  ...,  7.5149e-03,\n",
      "          7.7298e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['metro_station', 'library', 'city_center', 'tram']}\n",
      "tensor([[-2.1460e-04, -9.4677e-05, -3.2678e-05,  ..., -4.2395e-04,\n",
      "         -4.8082e-04,  0.0000e+00],\n",
      "        [-8.2791e-05, -4.1678e-05, -6.7669e-05,  ...,  2.7714e-04,\n",
      "          2.9989e-04,  0.0000e+00],\n",
      "        [ 2.5845e-03,  2.2617e-04, -5.5673e-03,  ..., -6.2449e-03,\n",
      "         -1.7266e-03,  0.0000e+00],\n",
      "        [ 1.9824e-02,  3.3739e-02,  3.0085e-02,  ...,  7.5149e-03,\n",
      "          7.7298e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['metro_station', 'library', 'city_center', 'tram']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                             | 140/324 [00:11<00:14, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-3.4885e-04, -4.1119e-04, -3.4733e-04,  ...,  2.7650e-04,\n",
      "          2.6939e-04,  0.0000e+00],\n",
      "        [ 2.9241e-03,  4.1058e-03,  9.9788e-04,  ..., -1.5013e-03,\n",
      "         -2.0917e-03,  0.0000e+00],\n",
      "        [ 4.2889e-04,  4.5783e-04,  3.0506e-04,  ...,  3.1587e-04,\n",
      "         -7.5804e-06,  0.0000e+00],\n",
      "        [ 6.7885e-03,  1.2195e-02,  9.3937e-03,  ..., -1.3217e-03,\n",
      "         -1.7817e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['home', 'beach', 'park', 'cafe/restaurant']}\n",
      "tensor([[-3.4885e-04, -4.1119e-04, -3.4733e-04,  ...,  2.7650e-04,\n",
      "          2.6939e-04,  0.0000e+00],\n",
      "        [ 2.9241e-03,  4.1058e-03,  9.9788e-04,  ..., -1.5013e-03,\n",
      "         -2.0917e-03,  0.0000e+00],\n",
      "        [ 4.2889e-04,  4.5783e-04,  3.0506e-04,  ...,  3.1587e-04,\n",
      "         -7.5804e-06,  0.0000e+00],\n",
      "        [ 6.7885e-03,  1.2195e-02,  9.3937e-03,  ..., -1.3217e-03,\n",
      "         -1.7817e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['home', 'beach', 'park', 'cafe/restaurant']\n",
      "{'audio': tensor([[ 0.0005,  0.0009, -0.0005,  ...,  0.0052,  0.0070,  0.0000],\n",
      "        [ 0.0121,  0.0194,  0.0196,  ..., -0.0272, -0.0288,  0.0000],\n",
      "        [ 0.0035,  0.0064,  0.0010,  ...,  0.0005,  0.0019,  0.0000],\n",
      "        [ 0.0006,  0.0009,  0.0009,  ..., -0.0006, -0.0004,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'train', 'home', 'library']}\n",
      "tensor([[ 0.0005,  0.0009, -0.0005,  ...,  0.0052,  0.0070,  0.0000],\n",
      "        [ 0.0121,  0.0194,  0.0196,  ..., -0.0272, -0.0288,  0.0000],\n",
      "        [ 0.0035,  0.0064,  0.0010,  ...,  0.0005,  0.0019,  0.0000],\n",
      "        [ 0.0006,  0.0009,  0.0009,  ..., -0.0006, -0.0004,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'train', 'home', 'library']\n",
      "{'audio': tensor([[ 5.2395e-03,  7.5997e-03,  5.8881e-03,  ...,  1.4273e-02,\n",
      "          1.5641e-02,  0.0000e+00],\n",
      "        [-8.2871e-05, -3.3656e-04, -3.3244e-04,  ..., -2.8004e-03,\n",
      "         -9.4178e-04,  0.0000e+00],\n",
      "        [ 8.9035e-04,  1.2040e-03,  1.9683e-03,  ...,  1.0775e-03,\n",
      "          3.8713e-04,  0.0000e+00],\n",
      "        [ 1.7056e-02,  2.8599e-02,  2.6276e-02,  ..., -2.3546e-02,\n",
      "         -2.7346e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['tram', 'metro_station', 'beach', 'bus']}\n",
      "tensor([[ 5.2395e-03,  7.5997e-03,  5.8881e-03,  ...,  1.4273e-02,\n",
      "          1.5641e-02,  0.0000e+00],\n",
      "        [-8.2871e-05, -3.3656e-04, -3.3244e-04,  ..., -2.8004e-03,\n",
      "         -9.4178e-04,  0.0000e+00],\n",
      "        [ 8.9035e-04,  1.2040e-03,  1.9683e-03,  ...,  1.0775e-03,\n",
      "          3.8713e-04,  0.0000e+00],\n",
      "        [ 1.7056e-02,  2.8599e-02,  2.6276e-02,  ..., -2.3546e-02,\n",
      "         -2.7346e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['tram', 'metro_station', 'beach', 'bus']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                             | 142/324 [00:11<00:13, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 1.2295e-02,  2.0562e-02,  1.7722e-02,  ..., -4.3415e-02,\n",
      "         -5.0686e-02,  0.0000e+00],\n",
      "        [ 1.2250e-02,  2.0226e-02,  1.7618e-02,  ...,  5.6831e-02,\n",
      "          6.5919e-02,  0.0000e+00],\n",
      "        [ 3.6181e-05,  6.2088e-05,  6.3480e-05,  ...,  1.8611e-04,\n",
      "          2.2464e-04,  0.0000e+00],\n",
      "        [-9.5525e-04, -1.7237e-03, -1.7680e-03,  ...,  5.5970e-03,\n",
      "          6.4893e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'car', 'home', 'tram']}\n",
      "tensor([[ 1.2295e-02,  2.0562e-02,  1.7722e-02,  ..., -4.3415e-02,\n",
      "         -5.0686e-02,  0.0000e+00],\n",
      "        [ 1.2250e-02,  2.0226e-02,  1.7618e-02,  ...,  5.6831e-02,\n",
      "          6.5919e-02,  0.0000e+00],\n",
      "        [ 3.6181e-05,  6.2088e-05,  6.3480e-05,  ...,  1.8611e-04,\n",
      "          2.2464e-04,  0.0000e+00],\n",
      "        [-9.5525e-04, -1.7237e-03, -1.7680e-03,  ...,  5.5970e-03,\n",
      "          6.4893e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'car', 'home', 'tram']\n",
      "{'audio': tensor([[ 9.9389e-03,  1.5800e-02,  1.2871e-02,  ...,  1.7478e-02,\n",
      "          1.7302e-02,  0.0000e+00],\n",
      "        [ 9.7973e-04,  7.5972e-04,  7.5477e-05,  ..., -1.2453e-04,\n",
      "          8.2665e-05,  0.0000e+00],\n",
      "        [ 1.1372e-03,  2.0246e-03,  1.8106e-03,  ...,  8.5923e-04,\n",
      "          5.2264e-04,  0.0000e+00],\n",
      "        [-2.8747e-05, -3.1711e-05, -1.7695e-05,  ...,  8.4861e-04,\n",
      "          1.0265e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'cafe/restaurant', 'park', 'home']}\n",
      "tensor([[ 9.9389e-03,  1.5800e-02,  1.2871e-02,  ...,  1.7478e-02,\n",
      "          1.7302e-02,  0.0000e+00],\n",
      "        [ 9.7973e-04,  7.5972e-04,  7.5477e-05,  ..., -1.2453e-04,\n",
      "          8.2665e-05,  0.0000e+00],\n",
      "        [ 1.1372e-03,  2.0246e-03,  1.8106e-03,  ...,  8.5923e-04,\n",
      "          5.2264e-04,  0.0000e+00],\n",
      "        [-2.8747e-05, -3.1711e-05, -1.7695e-05,  ...,  8.4861e-04,\n",
      "          1.0265e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'cafe/restaurant', 'park', 'home']\n",
      "{'audio': tensor([[-0.0009, -0.0017, -0.0014,  ...,  0.0010,  0.0012,  0.0000],\n",
      "        [-0.0004, -0.0006, -0.0005,  ...,  0.0017,  0.0014,  0.0000],\n",
      "        [-0.0146, -0.0235, -0.0192,  ..., -0.1118, -0.1306,  0.0000],\n",
      "        [-0.0002, -0.0004, -0.0006,  ..., -0.0004, -0.0005,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'beach', 'train', 'library']}\n",
      "tensor([[-0.0009, -0.0017, -0.0014,  ...,  0.0010,  0.0012,  0.0000],\n",
      "        [-0.0004, -0.0006, -0.0005,  ...,  0.0017,  0.0014,  0.0000],\n",
      "        [-0.0146, -0.0235, -0.0192,  ..., -0.1118, -0.1306,  0.0000],\n",
      "        [-0.0002, -0.0004, -0.0006,  ..., -0.0004, -0.0005,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'beach', 'train', 'library']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                            | 146/324 [00:12<00:13, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 4.6371e-05,  7.2311e-05, -3.4880e-06,  ..., -6.2937e-04,\n",
      "         -5.8368e-04,  0.0000e+00],\n",
      "        [ 1.0186e-04,  1.8825e-04,  1.5617e-04,  ..., -8.8148e-05,\n",
      "         -8.5813e-05,  0.0000e+00],\n",
      "        [-1.2486e-04, -2.1112e-04, -2.2177e-04,  ...,  7.6994e-05,\n",
      "          1.0498e-04,  0.0000e+00],\n",
      "        [ 4.7646e-05,  1.1762e-05, -6.3772e-05,  ..., -2.2371e-04,\n",
      "         -2.1459e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'office', 'home', 'office']}\n",
      "tensor([[ 4.6371e-05,  7.2311e-05, -3.4880e-06,  ..., -6.2937e-04,\n",
      "         -5.8368e-04,  0.0000e+00],\n",
      "        [ 1.0186e-04,  1.8825e-04,  1.5617e-04,  ..., -8.8148e-05,\n",
      "         -8.5813e-05,  0.0000e+00],\n",
      "        [-1.2486e-04, -2.1112e-04, -2.2177e-04,  ...,  7.6994e-05,\n",
      "          1.0498e-04,  0.0000e+00],\n",
      "        [ 4.7646e-05,  1.1762e-05, -6.3772e-05,  ..., -2.2371e-04,\n",
      "         -2.1459e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'office', 'home', 'office']\n",
      "{'audio': tensor([[-1.1314e-03, -3.8087e-03, -3.9568e-03,  ..., -6.8399e-03,\n",
      "         -4.9419e-03,  0.0000e+00],\n",
      "        [-2.3102e-04, -4.3927e-04, -4.9453e-04,  ...,  4.8699e-05,\n",
      "          1.6057e-04,  0.0000e+00],\n",
      "        [-1.5604e-03, -5.4863e-03, -5.7112e-03,  ..., -9.3080e-03,\n",
      "         -9.9375e-03,  0.0000e+00],\n",
      "        [ 1.1593e-03,  1.4111e-03,  1.0105e-03,  ..., -3.5459e-03,\n",
      "         -2.9162e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['beach', 'library', 'tram', 'metro_station']}\n",
      "tensor([[-1.1314e-03, -3.8087e-03, -3.9568e-03,  ..., -6.8399e-03,\n",
      "         -4.9419e-03,  0.0000e+00],\n",
      "        [-2.3102e-04, -4.3927e-04, -4.9453e-04,  ...,  4.8699e-05,\n",
      "          1.6057e-04,  0.0000e+00],\n",
      "        [-1.5604e-03, -5.4863e-03, -5.7112e-03,  ..., -9.3080e-03,\n",
      "         -9.9375e-03,  0.0000e+00],\n",
      "        [ 1.1593e-03,  1.4111e-03,  1.0105e-03,  ..., -3.5459e-03,\n",
      "         -2.9162e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['beach', 'library', 'tram', 'metro_station']\n",
      "{'audio': tensor([[ 2.3459e-04,  4.4646e-04,  3.9942e-04,  ..., -8.0740e-05,\n",
      "         -4.8133e-05,  0.0000e+00],\n",
      "        [-1.5690e-03, -7.4643e-03, -7.7321e-03,  ...,  6.0600e-02,\n",
      "          7.9797e-02,  0.0000e+00],\n",
      "        [-2.1888e-02, -4.3843e-02, -4.5905e-02,  ...,  4.8972e-03,\n",
      "          6.5503e-04,  0.0000e+00],\n",
      "        [-2.2781e-02, -3.0409e-02, -9.3300e-03,  ...,  4.2768e-02,\n",
      "          6.4262e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'train', 'tram', 'city_center']}\n",
      "tensor([[ 2.3459e-04,  4.4646e-04,  3.9942e-04,  ..., -8.0740e-05,\n",
      "         -4.8133e-05,  0.0000e+00],\n",
      "        [-1.5690e-03, -7.4643e-03, -7.7321e-03,  ...,  6.0600e-02,\n",
      "          7.9797e-02,  0.0000e+00],\n",
      "        [-2.1888e-02, -4.3843e-02, -4.5905e-02,  ...,  4.8972e-03,\n",
      "          6.5503e-04,  0.0000e+00],\n",
      "        [-2.2781e-02, -3.0409e-02, -9.3300e-03,  ...,  4.2768e-02,\n",
      "          6.4262e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'train', 'tram', 'city_center']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                           | 148/324 [00:12<00:15, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0018, -0.0029, -0.0018,  ...,  0.0005,  0.0013,  0.0000],\n",
      "        [ 0.0037,  0.0053,  0.0035,  ...,  0.0108,  0.0121,  0.0000],\n",
      "        [-0.0107, -0.0187, -0.0173,  ...,  0.0031,  0.0016,  0.0000],\n",
      "        [-0.0002, -0.0003, -0.0003,  ..., -0.0001, -0.0001,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['residential_area', 'tram', 'train', 'library']}\n",
      "tensor([[-0.0018, -0.0029, -0.0018,  ...,  0.0005,  0.0013,  0.0000],\n",
      "        [ 0.0037,  0.0053,  0.0035,  ...,  0.0108,  0.0121,  0.0000],\n",
      "        [-0.0107, -0.0187, -0.0173,  ...,  0.0031,  0.0016,  0.0000],\n",
      "        [-0.0002, -0.0003, -0.0003,  ..., -0.0001, -0.0001,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['residential_area', 'tram', 'train', 'library']\n",
      "{'audio': tensor([[-8.4248e-05, -1.4780e-04, -1.3109e-04,  ...,  3.2339e-05,\n",
      "          6.3317e-06,  0.0000e+00],\n",
      "        [-7.0589e-02, -1.3090e-01, -1.2641e-01,  ..., -3.8475e-02,\n",
      "         -2.7368e-02,  0.0000e+00],\n",
      "        [-1.6020e-03, -2.5812e-03, -2.8014e-03,  ..., -1.8435e-03,\n",
      "         -1.3095e-03,  0.0000e+00],\n",
      "        [-9.7866e-03, -1.6621e-02, -1.4892e-02,  ..., -5.4485e-03,\n",
      "         -7.0179e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['office', 'city_center', 'beach', 'train']}\n",
      "tensor([[-8.4248e-05, -1.4780e-04, -1.3109e-04,  ...,  3.2339e-05,\n",
      "          6.3317e-06,  0.0000e+00],\n",
      "        [-7.0589e-02, -1.3090e-01, -1.2641e-01,  ..., -3.8475e-02,\n",
      "         -2.7368e-02,  0.0000e+00],\n",
      "        [-1.6020e-03, -2.5812e-03, -2.8014e-03,  ..., -1.8435e-03,\n",
      "         -1.3095e-03,  0.0000e+00],\n",
      "        [-9.7866e-03, -1.6621e-02, -1.4892e-02,  ..., -5.4485e-03,\n",
      "         -7.0179e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['office', 'city_center', 'beach', 'train']\n",
      "{'audio': tensor([[ 2.2533e-02,  3.7240e-02,  3.1962e-02,  ...,  1.8044e-02,\n",
      "          2.0614e-02,  0.0000e+00],\n",
      "        [ 1.2598e-03,  2.2473e-03,  2.0177e-03,  ..., -4.1875e-03,\n",
      "         -5.1881e-03,  0.0000e+00],\n",
      "        [ 2.8423e-02,  4.7519e-02,  4.1692e-02,  ...,  8.2845e-04,\n",
      "          9.3838e-04,  0.0000e+00],\n",
      "        [ 6.1511e-04,  2.8422e-05, -1.8853e-03,  ..., -1.2007e-04,\n",
      "         -2.9157e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['car', 'residential_area', 'car', 'residential_area']}\n",
      "tensor([[ 2.2533e-02,  3.7240e-02,  3.1962e-02,  ...,  1.8044e-02,\n",
      "          2.0614e-02,  0.0000e+00],\n",
      "        [ 1.2598e-03,  2.2473e-03,  2.0177e-03,  ..., -4.1875e-03,\n",
      "         -5.1881e-03,  0.0000e+00],\n",
      "        [ 2.8423e-02,  4.7519e-02,  4.1692e-02,  ...,  8.2845e-04,\n",
      "          9.3838e-04,  0.0000e+00],\n",
      "        [ 6.1511e-04,  2.8422e-05, -1.8853e-03,  ..., -1.2007e-04,\n",
      "         -2.9157e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['car', 'residential_area', 'car', 'residential_area']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                          | 152/324 [00:12<00:14, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0013, -0.0024, -0.0043,  ..., -0.0030, -0.0019,  0.0000],\n",
      "        [-0.0039, -0.0064, -0.0063,  ..., -0.0079, -0.0097,  0.0000],\n",
      "        [ 0.0008,  0.0014,  0.0011,  ..., -0.0004, -0.0007,  0.0000],\n",
      "        [-0.0002, -0.0003,  0.0005,  ...,  0.0020,  0.0026,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['park', 'tram', 'park', 'city_center']}\n",
      "tensor([[-0.0013, -0.0024, -0.0043,  ..., -0.0030, -0.0019,  0.0000],\n",
      "        [-0.0039, -0.0064, -0.0063,  ..., -0.0079, -0.0097,  0.0000],\n",
      "        [ 0.0008,  0.0014,  0.0011,  ..., -0.0004, -0.0007,  0.0000],\n",
      "        [-0.0002, -0.0003,  0.0005,  ...,  0.0020,  0.0026,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['park', 'tram', 'park', 'city_center']\n",
      "{'audio': tensor([[-4.9931e-05, -2.6516e-04, -5.4160e-04,  ..., -6.5709e-04,\n",
      "         -5.7380e-04,  0.0000e+00],\n",
      "        [-9.9667e-04, -1.0815e-03,  1.9757e-04,  ...,  1.7687e-04,\n",
      "          1.5668e-03,  0.0000e+00],\n",
      "        [ 1.0241e-02,  1.8736e-02,  1.7425e-02,  ..., -9.9011e-03,\n",
      "         -9.7231e-03,  0.0000e+00],\n",
      "        [ 7.4454e-05,  1.3975e-04,  2.3606e-04,  ...,  2.6712e-02,\n",
      "         -1.0515e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['library', 'cafe/restaurant', 'grocery_store', 'residential_area']}\n",
      "tensor([[-4.9931e-05, -2.6516e-04, -5.4160e-04,  ..., -6.5709e-04,\n",
      "         -5.7380e-04,  0.0000e+00],\n",
      "        [-9.9667e-04, -1.0815e-03,  1.9757e-04,  ...,  1.7687e-04,\n",
      "          1.5668e-03,  0.0000e+00],\n",
      "        [ 1.0241e-02,  1.8736e-02,  1.7425e-02,  ..., -9.9011e-03,\n",
      "         -9.7231e-03,  0.0000e+00],\n",
      "        [ 7.4454e-05,  1.3975e-04,  2.3606e-04,  ...,  2.6712e-02,\n",
      "         -1.0515e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['library', 'cafe/restaurant', 'grocery_store', 'residential_area']\n",
      "{'audio': tensor([[-6.6015e-04, -1.2977e-03, -6.1104e-04,  ...,  1.1635e-03,\n",
      "          5.3367e-03,  0.0000e+00],\n",
      "        [-2.0936e-03, -3.3954e-03, -8.4000e-04,  ...,  2.3191e-03,\n",
      "          1.7184e-03,  0.0000e+00],\n",
      "        [ 9.7712e-03,  1.6046e-02,  1.3347e-02,  ..., -2.0455e-02,\n",
      "         -2.4045e-02,  0.0000e+00],\n",
      "        [ 2.8463e-04,  1.1599e-03,  1.8439e-03,  ...,  6.4045e-05,\n",
      "         -2.0023e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['beach', 'beach', 'train', 'residential_area']}\n",
      "tensor([[-6.6015e-04, -1.2977e-03, -6.1104e-04,  ...,  1.1635e-03,\n",
      "          5.3367e-03,  0.0000e+00],\n",
      "        [-2.0936e-03, -3.3954e-03, -8.4000e-04,  ...,  2.3191e-03,\n",
      "          1.7184e-03,  0.0000e+00],\n",
      "        [ 9.7712e-03,  1.6046e-02,  1.3347e-02,  ..., -2.0455e-02,\n",
      "         -2.4045e-02,  0.0000e+00],\n",
      "        [ 2.8463e-04,  1.1599e-03,  1.8439e-03,  ...,  6.4045e-05,\n",
      "         -2.0023e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['beach', 'beach', 'train', 'residential_area']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                          | 154/324 [00:12<00:15, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 2.0935e-03,  3.2623e-03,  2.5961e-03,  ..., -7.7205e-03,\n",
      "         -8.3146e-03,  0.0000e+00],\n",
      "        [-1.8831e-03, -5.8271e-04, -6.2520e-03,  ..., -9.2437e-04,\n",
      "         -1.7414e-03,  0.0000e+00],\n",
      "        [ 1.3552e-03,  2.0564e-03,  1.5588e-03,  ..., -1.5756e-03,\n",
      "         -1.4639e-03,  0.0000e+00],\n",
      "        [ 1.5600e-03,  2.2021e-03,  1.5062e-03,  ..., -3.0864e-06,\n",
      "         -1.7209e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['tram', 'beach', 'residential_area', 'city_center']}\n",
      "tensor([[ 2.0935e-03,  3.2623e-03,  2.5961e-03,  ..., -7.7205e-03,\n",
      "         -8.3146e-03,  0.0000e+00],\n",
      "        [-1.8831e-03, -5.8271e-04, -6.2520e-03,  ..., -9.2437e-04,\n",
      "         -1.7414e-03,  0.0000e+00],\n",
      "        [ 1.3552e-03,  2.0564e-03,  1.5588e-03,  ..., -1.5756e-03,\n",
      "         -1.4639e-03,  0.0000e+00],\n",
      "        [ 1.5600e-03,  2.2021e-03,  1.5062e-03,  ..., -3.0864e-06,\n",
      "         -1.7209e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['tram', 'beach', 'residential_area', 'city_center']\n",
      "{'audio': tensor([[ 0.0145,  0.0257,  0.0213,  ...,  0.0236,  0.0301,  0.0000],\n",
      "        [ 0.0012,  0.0018,  0.0017,  ...,  0.0040,  0.0014,  0.0000],\n",
      "        [-0.0051, -0.0081, -0.0124,  ...,  0.0061,  0.0081,  0.0000],\n",
      "        [ 0.0003,  0.0004,  0.0003,  ...,  0.0019,  0.0022,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'city_center', 'bus', 'library']}\n",
      "tensor([[ 0.0145,  0.0257,  0.0213,  ...,  0.0236,  0.0301,  0.0000],\n",
      "        [ 0.0012,  0.0018,  0.0017,  ...,  0.0040,  0.0014,  0.0000],\n",
      "        [-0.0051, -0.0081, -0.0124,  ...,  0.0061,  0.0081,  0.0000],\n",
      "        [ 0.0003,  0.0004,  0.0003,  ...,  0.0019,  0.0022,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'city_center', 'bus', 'library']\n",
      "{'audio': tensor([[-6.3706e-05, -1.1553e-04, -7.5287e-05,  ...,  1.5197e-04,\n",
      "          1.7680e-04,  0.0000e+00],\n",
      "        [ 5.9833e-03,  9.4687e-03,  6.0872e-03,  ...,  5.1139e-04,\n",
      "         -5.0196e-04,  0.0000e+00],\n",
      "        [ 9.0066e-05,  4.1078e-04,  2.9351e-04,  ...,  7.9949e-04,\n",
      "          1.0061e-03,  0.0000e+00],\n",
      "        [ 2.0002e-03,  3.4249e-03,  3.0774e-03,  ..., -3.7486e-04,\n",
      "         -4.9463e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['home', 'cafe/restaurant', 'office', 'home']}\n",
      "tensor([[-6.3706e-05, -1.1553e-04, -7.5287e-05,  ...,  1.5197e-04,\n",
      "          1.7680e-04,  0.0000e+00],\n",
      "        [ 5.9833e-03,  9.4687e-03,  6.0872e-03,  ...,  5.1139e-04,\n",
      "         -5.0196e-04,  0.0000e+00],\n",
      "        [ 9.0066e-05,  4.1078e-04,  2.9351e-04,  ...,  7.9949e-04,\n",
      "          1.0061e-03,  0.0000e+00],\n",
      "        [ 2.0002e-03,  3.4249e-03,  3.0774e-03,  ..., -3.7486e-04,\n",
      "         -4.9463e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['home', 'cafe/restaurant', 'office', 'home']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                         | 158/324 [00:13<00:14, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-1.7568e-02, -1.8058e-02, -2.7027e-02,  ...,  4.0097e-02,\n",
      "          4.6585e-02,  0.0000e+00],\n",
      "        [ 4.5016e-05,  1.0741e-04,  5.1401e-05,  ..., -1.1363e-04,\n",
      "         -1.5320e-04,  0.0000e+00],\n",
      "        [-1.5823e-04, -5.3969e-04, -1.0100e-03,  ..., -2.6626e-03,\n",
      "         -5.8239e-04,  0.0000e+00],\n",
      "        [ 1.5203e-04,  3.2060e-04,  3.9877e-04,  ..., -6.3333e-04,\n",
      "         -7.5161e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['city_center', 'office', 'residential_area', 'forest_path']}\n",
      "tensor([[-1.7568e-02, -1.8058e-02, -2.7027e-02,  ...,  4.0097e-02,\n",
      "          4.6585e-02,  0.0000e+00],\n",
      "        [ 4.5016e-05,  1.0741e-04,  5.1401e-05,  ..., -1.1363e-04,\n",
      "         -1.5320e-04,  0.0000e+00],\n",
      "        [-1.5823e-04, -5.3969e-04, -1.0100e-03,  ..., -2.6626e-03,\n",
      "         -5.8239e-04,  0.0000e+00],\n",
      "        [ 1.5203e-04,  3.2060e-04,  3.9877e-04,  ..., -6.3333e-04,\n",
      "         -7.5161e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['city_center', 'office', 'residential_area', 'forest_path']\n",
      "{'audio': tensor([[-6.7040e-03, -1.0935e-02, -9.5532e-03,  ...,  6.0350e-03,\n",
      "          7.3235e-03,  0.0000e+00],\n",
      "        [ 9.5885e-04,  1.7616e-03,  1.8398e-03,  ...,  2.9243e-03,\n",
      "          3.8276e-03,  0.0000e+00],\n",
      "        [ 4.6157e-04, -2.7640e-04, -4.4223e-04,  ..., -2.0019e-06,\n",
      "         -6.2826e-04,  0.0000e+00],\n",
      "        [-6.9291e-07, -4.3599e-06,  6.3342e-06,  ...,  8.7492e-05,\n",
      "          7.2590e-05,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['tram', 'metro_station', 'home', 'office']}\n",
      "tensor([[-6.7040e-03, -1.0935e-02, -9.5532e-03,  ...,  6.0350e-03,\n",
      "          7.3235e-03,  0.0000e+00],\n",
      "        [ 9.5885e-04,  1.7616e-03,  1.8398e-03,  ...,  2.9243e-03,\n",
      "          3.8276e-03,  0.0000e+00],\n",
      "        [ 4.6157e-04, -2.7640e-04, -4.4223e-04,  ..., -2.0019e-06,\n",
      "         -6.2826e-04,  0.0000e+00],\n",
      "        [-6.9291e-07, -4.3599e-06,  6.3342e-06,  ...,  8.7492e-05,\n",
      "          7.2590e-05,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['tram', 'metro_station', 'home', 'office']\n",
      "{'audio': tensor([[ 0.0003,  0.0003,  0.0002,  ..., -0.0017, -0.0019,  0.0000],\n",
      "        [-0.0501, -0.0831, -0.0717,  ...,  0.0383,  0.0444,  0.0000],\n",
      "        [-0.0025, -0.0044, -0.0031,  ...,  0.0064,  0.0082,  0.0000],\n",
      "        [ 0.0017,  0.0030,  0.0034,  ...,  0.0007,  0.0008,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['cafe/restaurant', 'train', 'residential_area', 'library']}\n",
      "tensor([[ 0.0003,  0.0003,  0.0002,  ..., -0.0017, -0.0019,  0.0000],\n",
      "        [-0.0501, -0.0831, -0.0717,  ...,  0.0383,  0.0444,  0.0000],\n",
      "        [-0.0025, -0.0044, -0.0031,  ...,  0.0064,  0.0082,  0.0000],\n",
      "        [ 0.0017,  0.0030,  0.0034,  ...,  0.0007,  0.0008,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['cafe/restaurant', 'train', 'residential_area', 'library']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                        | 160/324 [00:13<00:13, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-1.4241e-03, -1.8594e-03, -1.5779e-03,  ..., -4.5728e-04,\n",
      "         -3.9253e-04,  0.0000e+00],\n",
      "        [ 4.3958e-03,  2.7914e-03, -2.9251e-03,  ...,  2.0364e-02,\n",
      "          2.0503e-02,  0.0000e+00],\n",
      "        [ 9.0581e-04,  1.4918e-03,  1.3124e-03,  ...,  5.2064e-04,\n",
      "          1.1568e-03,  0.0000e+00],\n",
      "        [-4.3392e-03, -6.9566e-03, -4.7360e-03,  ..., -8.2851e-04,\n",
      "          3.1826e-06,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['grocery_store', 'city_center', 'cafe/restaurant', 'cafe/restaurant']}\n",
      "tensor([[-1.4241e-03, -1.8594e-03, -1.5779e-03,  ..., -4.5728e-04,\n",
      "         -3.9253e-04,  0.0000e+00],\n",
      "        [ 4.3958e-03,  2.7914e-03, -2.9251e-03,  ...,  2.0364e-02,\n",
      "          2.0503e-02,  0.0000e+00],\n",
      "        [ 9.0581e-04,  1.4918e-03,  1.3124e-03,  ...,  5.2064e-04,\n",
      "          1.1568e-03,  0.0000e+00],\n",
      "        [-4.3392e-03, -6.9566e-03, -4.7360e-03,  ..., -8.2851e-04,\n",
      "          3.1826e-06,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['grocery_store', 'city_center', 'cafe/restaurant', 'cafe/restaurant']\n",
      "{'audio': tensor([[-0.0125, -0.0200, -0.0164,  ...,  0.0020,  0.0008,  0.0000],\n",
      "        [ 0.0001, -0.0011, -0.0015,  ...,  0.0013, -0.0010,  0.0000],\n",
      "        [-0.0008, -0.0013, -0.0008,  ...,  0.0025,  0.0022,  0.0000],\n",
      "        [-0.0047, -0.0105, -0.0121,  ..., -0.0120, -0.0132,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['cafe/restaurant', 'home', 'residential_area', 'city_center']}\n",
      "tensor([[-0.0125, -0.0200, -0.0164,  ...,  0.0020,  0.0008,  0.0000],\n",
      "        [ 0.0001, -0.0011, -0.0015,  ...,  0.0013, -0.0010,  0.0000],\n",
      "        [-0.0008, -0.0013, -0.0008,  ...,  0.0025,  0.0022,  0.0000],\n",
      "        [-0.0047, -0.0105, -0.0121,  ..., -0.0120, -0.0132,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['cafe/restaurant', 'home', 'residential_area', 'city_center']\n",
      "{'audio': tensor([[-1.1338e-03, -3.5301e-03, -3.8920e-03,  ..., -5.1669e-03,\n",
      "         -3.1233e-03,  0.0000e+00],\n",
      "        [-5.6019e-06, -4.1672e-05, -3.2564e-04,  ...,  1.3453e-08,\n",
      "          4.9253e-05,  0.0000e+00],\n",
      "        [-3.4786e-04,  9.3842e-05,  3.2598e-03,  ..., -7.5562e-03,\n",
      "         -1.0208e-02,  0.0000e+00],\n",
      "        [-6.4366e-04, -1.3162e-03, -1.1092e-03,  ...,  2.4386e-05,\n",
      "          2.1375e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['beach', 'home', 'grocery_store', 'cafe/restaurant']}\n",
      "tensor([[-1.1338e-03, -3.5301e-03, -3.8920e-03,  ..., -5.1669e-03,\n",
      "         -3.1233e-03,  0.0000e+00],\n",
      "        [-5.6019e-06, -4.1672e-05, -3.2564e-04,  ...,  1.3453e-08,\n",
      "          4.9253e-05,  0.0000e+00],\n",
      "        [-3.4786e-04,  9.3842e-05,  3.2598e-03,  ..., -7.5562e-03,\n",
      "         -1.0208e-02,  0.0000e+00],\n",
      "        [-6.4366e-04, -1.3162e-03, -1.1092e-03,  ...,  2.4386e-05,\n",
      "          2.1375e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['beach', 'home', 'grocery_store', 'cafe/restaurant']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                       | 164/324 [00:13<00:13, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 0.0023,  0.0035,  0.0012,  ..., -0.0035, -0.0045,  0.0000],\n",
      "        [-0.0003, -0.0015,  0.0002,  ...,  0.0011,  0.0025,  0.0000],\n",
      "        [ 0.0061,  0.0097,  0.0072,  ...,  0.0091,  0.0093,  0.0000],\n",
      "        [ 0.0001,  0.0004,  0.0003,  ..., -0.0001, -0.0008,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['beach', 'metro_station', 'bus', 'residential_area']}\n",
      "tensor([[ 0.0023,  0.0035,  0.0012,  ..., -0.0035, -0.0045,  0.0000],\n",
      "        [-0.0003, -0.0015,  0.0002,  ...,  0.0011,  0.0025,  0.0000],\n",
      "        [ 0.0061,  0.0097,  0.0072,  ...,  0.0091,  0.0093,  0.0000],\n",
      "        [ 0.0001,  0.0004,  0.0003,  ..., -0.0001, -0.0008,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['beach', 'metro_station', 'bus', 'residential_area']\n",
      "{'audio': tensor([[-0.0202, -0.0342, -0.0302,  ..., -0.0355, -0.0411,  0.0000],\n",
      "        [-0.0015, -0.0031, -0.0030,  ...,  0.0002, -0.0008,  0.0000],\n",
      "        [-0.0002, -0.0004, -0.0003,  ...,  0.0004,  0.0005,  0.0000],\n",
      "        [ 0.0185,  0.0305,  0.0254,  ...,  0.0016,  0.0007,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['bus', 'metro_station', 'library', 'tram']}\n",
      "tensor([[-0.0202, -0.0342, -0.0302,  ..., -0.0355, -0.0411,  0.0000],\n",
      "        [-0.0015, -0.0031, -0.0030,  ...,  0.0002, -0.0008,  0.0000],\n",
      "        [-0.0002, -0.0004, -0.0003,  ...,  0.0004,  0.0005,  0.0000],\n",
      "        [ 0.0185,  0.0305,  0.0254,  ...,  0.0016,  0.0007,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['bus', 'metro_station', 'library', 'tram']\n",
      "{'audio': tensor([[ 0.0106,  0.0196,  0.0196,  ..., -0.0087, -0.0112,  0.0000],\n",
      "        [ 0.0398,  0.0673,  0.0599,  ...,  0.0550,  0.0630,  0.0000],\n",
      "        [-0.0056, -0.0095, -0.0083,  ..., -0.0097, -0.0104,  0.0000],\n",
      "        [-0.0012, -0.0025, -0.0025,  ..., -0.0012, -0.0005,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['tram', 'car', 'tram', 'grocery_store']}\n",
      "tensor([[ 0.0106,  0.0196,  0.0196,  ..., -0.0087, -0.0112,  0.0000],\n",
      "        [ 0.0398,  0.0673,  0.0599,  ...,  0.0550,  0.0630,  0.0000],\n",
      "        [-0.0056, -0.0095, -0.0083,  ..., -0.0097, -0.0104,  0.0000],\n",
      "        [-0.0012, -0.0025, -0.0025,  ..., -0.0012, -0.0005,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['tram', 'car', 'tram', 'grocery_store']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                       | 166/324 [00:13<00:12, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0007, -0.0012, -0.0010,  ...,  0.0023,  0.0024,  0.0000],\n",
      "        [ 0.0288,  0.0466,  0.0373,  ..., -0.0008, -0.0028,  0.0000],\n",
      "        [ 0.0003,  0.0002, -0.0004,  ..., -0.0013, -0.0015,  0.0000],\n",
      "        [-0.0017, -0.0031, -0.0031,  ...,  0.0060,  0.0073,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['forest_path', 'city_center', 'forest_path', 'beach']}\n",
      "tensor([[-0.0007, -0.0012, -0.0010,  ...,  0.0023,  0.0024,  0.0000],\n",
      "        [ 0.0288,  0.0466,  0.0373,  ..., -0.0008, -0.0028,  0.0000],\n",
      "        [ 0.0003,  0.0002, -0.0004,  ..., -0.0013, -0.0015,  0.0000],\n",
      "        [-0.0017, -0.0031, -0.0031,  ...,  0.0060,  0.0073,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['forest_path', 'city_center', 'forest_path', 'beach']\n",
      "{'audio': tensor([[ 6.5762e-04, -1.2394e-03, -2.0203e-03,  ...,  2.5427e-03,\n",
      "          5.6356e-04,  0.0000e+00],\n",
      "        [-1.3286e-04, -1.7477e-04, -1.4000e-04,  ..., -7.1883e-04,\n",
      "         -1.1705e-03,  0.0000e+00],\n",
      "        [ 1.9543e-04,  2.5848e-04,  3.2231e-04,  ..., -6.1688e-04,\n",
      "         -1.0967e-03,  0.0000e+00],\n",
      "        [ 3.7075e-05, -1.1342e-04, -9.9392e-04,  ..., -2.6403e-03,\n",
      "         -2.3344e-03,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['home', 'home', 'cafe/restaurant', 'residential_area']}\n",
      "tensor([[ 6.5762e-04, -1.2394e-03, -2.0203e-03,  ...,  2.5427e-03,\n",
      "          5.6356e-04,  0.0000e+00],\n",
      "        [-1.3286e-04, -1.7477e-04, -1.4000e-04,  ..., -7.1883e-04,\n",
      "         -1.1705e-03,  0.0000e+00],\n",
      "        [ 1.9543e-04,  2.5848e-04,  3.2231e-04,  ..., -6.1688e-04,\n",
      "         -1.0967e-03,  0.0000e+00],\n",
      "        [ 3.7075e-05, -1.1342e-04, -9.9392e-04,  ..., -2.6403e-03,\n",
      "         -2.3344e-03,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['home', 'home', 'cafe/restaurant', 'residential_area']\n",
      "{'audio': tensor([[ 0.0045,  0.0073,  0.0062,  ..., -0.0010, -0.0011,  0.0000],\n",
      "        [ 0.0039,  0.0065,  0.0050,  ...,  0.0058,  0.0061,  0.0000],\n",
      "        [ 0.0014,  0.0021,  0.0013,  ...,  0.0045,  0.0040,  0.0000],\n",
      "        [ 0.0016,  0.0027,  0.0020,  ..., -0.0027, -0.0030,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['beach', 'tram', 'car', 'metro_station']}\n",
      "tensor([[ 0.0045,  0.0073,  0.0062,  ..., -0.0010, -0.0011,  0.0000],\n",
      "        [ 0.0039,  0.0065,  0.0050,  ...,  0.0058,  0.0061,  0.0000],\n",
      "        [ 0.0014,  0.0021,  0.0013,  ...,  0.0045,  0.0040,  0.0000],\n",
      "        [ 0.0016,  0.0027,  0.0020,  ..., -0.0027, -0.0030,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['beach', 'tram', 'car', 'metro_station']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                      | 170/324 [00:14<00:11, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[-0.0001, -0.0007, -0.0018,  ...,  0.0007,  0.0007,  0.0000],\n",
      "        [-0.0001, -0.0002, -0.0002,  ...,  0.0002,  0.0003,  0.0000],\n",
      "        [ 0.0003,  0.0006,  0.0006,  ...,  0.0007,  0.0006,  0.0000],\n",
      "        [-0.0679, -0.1165, -0.1053,  ..., -0.0914, -0.0984,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['grocery_store', 'library', 'forest_path', 'car']}\n",
      "tensor([[-0.0001, -0.0007, -0.0018,  ...,  0.0007,  0.0007,  0.0000],\n",
      "        [-0.0001, -0.0002, -0.0002,  ...,  0.0002,  0.0003,  0.0000],\n",
      "        [ 0.0003,  0.0006,  0.0006,  ...,  0.0007,  0.0006,  0.0000],\n",
      "        [-0.0679, -0.1165, -0.1053,  ..., -0.0914, -0.0984,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['grocery_store', 'library', 'forest_path', 'car']\n",
      "{'audio': tensor([[ 0.0009,  0.0010,  0.0005,  ..., -0.0008, -0.0007,  0.0000],\n",
      "        [-0.0373, -0.0618, -0.0532,  ..., -0.0123, -0.0139,  0.0000],\n",
      "        [ 0.0010,  0.0017,  0.0012,  ...,  0.0033,  0.0042,  0.0000],\n",
      "        [-0.0001, -0.0001, -0.0002,  ..., -0.0015, -0.0018,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['metro_station', 'bus', 'park', 'metro_station']}\n",
      "tensor([[ 0.0009,  0.0010,  0.0005,  ..., -0.0008, -0.0007,  0.0000],\n",
      "        [-0.0373, -0.0618, -0.0532,  ..., -0.0123, -0.0139,  0.0000],\n",
      "        [ 0.0010,  0.0017,  0.0012,  ...,  0.0033,  0.0042,  0.0000],\n",
      "        [-0.0001, -0.0001, -0.0002,  ..., -0.0015, -0.0018,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['metro_station', 'bus', 'park', 'metro_station']\n",
      "{'audio': tensor([[ 1.2248e-03,  2.3744e-03,  1.7593e-03,  ...,  1.1545e-03,\n",
      "          1.1808e-03,  0.0000e+00],\n",
      "        [ 2.3223e-04,  5.6496e-04,  4.6617e-04,  ..., -4.3488e-04,\n",
      "         -4.1702e-04,  0.0000e+00],\n",
      "        [ 5.0140e-05, -4.1053e-04, -6.0691e-04,  ..., -5.5902e-04,\n",
      "         -1.6992e-03,  0.0000e+00],\n",
      "        [-2.0291e-04, -4.9299e-04,  1.3416e-03,  ...,  3.7952e-04,\n",
      "          5.4545e-04,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['beach', 'library', 'home', 'metro_station']}\n",
      "tensor([[ 1.2248e-03,  2.3744e-03,  1.7593e-03,  ...,  1.1545e-03,\n",
      "          1.1808e-03,  0.0000e+00],\n",
      "        [ 2.3223e-04,  5.6496e-04,  4.6617e-04,  ..., -4.3488e-04,\n",
      "         -4.1702e-04,  0.0000e+00],\n",
      "        [ 5.0140e-05, -4.1053e-04, -6.0691e-04,  ..., -5.5902e-04,\n",
      "         -1.6992e-03,  0.0000e+00],\n",
      "        [-2.0291e-04, -4.9299e-04,  1.3416e-03,  ...,  3.7952e-04,\n",
      "          5.4545e-04,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['beach', 'library', 'home', 'metro_station']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                     | 173/324 [00:14<00:12, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': tensor([[ 0.0023,  0.0040,  0.0039,  ...,  0.0016,  0.0014,  0.0000],\n",
      "        [ 0.0067,  0.0072,  0.0044,  ..., -0.0052, -0.0064,  0.0000],\n",
      "        [ 0.0100,  0.0183,  0.0192,  ..., -0.0120, -0.0112,  0.0000],\n",
      "        [-0.0065, -0.0102, -0.0079,  ..., -0.0141, -0.0162,  0.0000]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['grocery_store', 'metro_station', 'car', 'train']}\n",
      "tensor([[ 0.0023,  0.0040,  0.0039,  ...,  0.0016,  0.0014,  0.0000],\n",
      "        [ 0.0067,  0.0072,  0.0044,  ..., -0.0052, -0.0064,  0.0000],\n",
      "        [ 0.0100,  0.0183,  0.0192,  ..., -0.0120, -0.0112,  0.0000],\n",
      "        [-0.0065, -0.0102, -0.0079,  ..., -0.0141, -0.0162,  0.0000]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['grocery_store', 'metro_station', 'car', 'train']\n",
      "{'audio': tensor([[-2.4439e-04, -3.0662e-04, -1.1655e-03,  ...,  1.6145e-03,\n",
      "          3.8238e-03,  0.0000e+00],\n",
      "        [ 1.9462e-04,  1.4024e-04, -6.5956e-05,  ...,  1.6403e-04,\n",
      "         -5.7581e-07,  0.0000e+00],\n",
      "        [-1.1479e-02, -1.8826e-02, -1.7602e-02,  ...,  4.2724e-03,\n",
      "          8.2793e-06,  0.0000e+00],\n",
      "        [-1.6774e-03, -2.4053e-03, -1.7186e-03,  ..., -1.2194e-02,\n",
      "         -1.4029e-02,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['metro_station', 'forest_path', 'city_center', 'car']}\n",
      "tensor([[-2.4439e-04, -3.0662e-04, -1.1655e-03,  ...,  1.6145e-03,\n",
      "          3.8238e-03,  0.0000e+00],\n",
      "        [ 1.9462e-04,  1.4024e-04, -6.5956e-05,  ...,  1.6403e-04,\n",
      "         -5.7581e-07,  0.0000e+00],\n",
      "        [-1.1479e-02, -1.8826e-02, -1.7602e-02,  ...,  4.2724e-03,\n",
      "          8.2793e-06,  0.0000e+00],\n",
      "        [-1.6774e-03, -2.4053e-03, -1.7186e-03,  ..., -1.2194e-02,\n",
      "         -1.4029e-02,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['metro_station', 'forest_path', 'city_center', 'car']\n",
      "{'audio': tensor([[-1.5178e-03, -2.0555e-03,  4.4597e-04,  ..., -6.1310e-03,\n",
      "         -6.4683e-03,  0.0000e+00],\n",
      "        [ 1.2355e-02,  1.8570e-02,  1.3332e-02,  ...,  3.3555e-02,\n",
      "          3.8646e-02,  0.0000e+00],\n",
      "        [-8.1879e-04, -1.2828e-03, -9.7043e-04,  ...,  1.3591e-03,\n",
      "          4.9097e-03,  0.0000e+00],\n",
      "        [ 2.1786e-04,  6.4669e-04,  7.0017e-04,  ..., -2.6795e-04,\n",
      "          4.4855e-05,  0.0000e+00]]), 'sample_rate': tensor([16000, 16000, 16000, 16000]), 'label': ['beach', 'bus', 'home', 'office']}\n",
      "tensor([[-1.5178e-03, -2.0555e-03,  4.4597e-04,  ..., -6.1310e-03,\n",
      "         -6.4683e-03,  0.0000e+00],\n",
      "        [ 1.2355e-02,  1.8570e-02,  1.3332e-02,  ...,  3.3555e-02,\n",
      "          3.8646e-02,  0.0000e+00],\n",
      "        [-8.1879e-04, -1.2828e-03, -9.7043e-04,  ...,  1.3591e-03,\n",
      "          4.9097e-03,  0.0000e+00],\n",
      "        [ 2.1786e-04,  6.4669e-04,  7.0017e-04,  ..., -2.6795e-04,\n",
      "          4.4855e-05,  0.0000e+00]])\n",
      "tensor([16000, 16000, 16000, 16000])\n",
      "['beach', 'bus', 'home', 'office']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[336], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[335], line 8\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m      6\u001b[0m criterion\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[319], line 48\u001b[0m, in \u001b[0;36mTUT17.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m audio_name:\n\u001b[0;32m     47\u001b[0m     f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m---> 48\u001b[0m     audio, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m: audio, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: sample_rate, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]}\n",
      "Cell \u001b[1;32mIn[304], line 5\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_audio\u001b[39m(audio_path):\n\u001b[1;32m----> 5\u001b[0m     audio, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m audio, sample_rate\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    206\u001b[0m     context \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n\u001b[0;32m    212\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m sf_desc\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\soundfile.py:1205\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1203\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1204\u001b[0m             file \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mencode(_sys\u001b[38;5;241m.\u001b[39mgetfilesystemencoding())\n\u001b[1;32m-> 1205\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m \u001b[43mopenfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1207\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_open_fd(file, mode_int, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info, closefd)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ast_prompt = AST_PromptTuning(prompt_type=None)\n",
    "ast_prompt_shallow = AST_PromptTuning(prompt_type='shallow')\n",
    "ast_prompt_deep = AST_PromptTuning(prompt_type='deep')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_one_epoch(model, train_loader, criterion, optimizer, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1548797e-da3e-4263-bda8-844ea5b40f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, feature_extractor, criterion, epochs, dev, lr=0.001, load_checkpoint = False, save_every = 10, save_path = 'weights'):\n",
    "    try:\n",
    "        if not os.path.isdir(save_path):\n",
    "            os.mkdir(save_path)\n",
    "            \n",
    "        # Move model to CUDA\n",
    "        model = model.to(dev)\n",
    "        # MOVE criterior to CUDA\n",
    "        criterion = criterion.to(dev)\n",
    "\n",
    "        # create optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "        \n",
    "        labels_l = []\n",
    "        predictions_l = []\n",
    "        \n",
    "        # load checkpoints\n",
    "        if load_checkpoint:\n",
    "            if os.path.isfile(os.path.join(save_path,'weights.pt')):\n",
    "                print('Loading weights...')\n",
    "                # it is possible to load a state dict that doesn't match the networck architecture by passing asserting the strict mode\n",
    "                model.load_state_dict(torch.load(os.path.join(save_path,'weights.pt')))\n",
    "            if os.path.isfile(os.path.join(save_path,'optim.pt')):\n",
    "                print('Loading optimizer...')\n",
    "                optimizer.load_state_dict(torch.load(os.path.join(save_path,'optim.pt')))\n",
    "            print('Loading completed!')\n",
    "\n",
    "        # Initialize history\n",
    "        history_loss = {\"train\": [], \"val\": [], \"test\": []}\n",
    "        history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "        # Process each epoch\n",
    "        for epoch in range(epochs):\n",
    "            # Initialize epoch variables\n",
    "            sum_loss = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "            sum_accuracy = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "            \n",
    "            # Process each split\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                #Select train() or eval() mode\n",
    "                if split == 'train':\n",
    "                  model.train()\n",
    "                else:\n",
    "                  model.eval()\n",
    "                    \n",
    "                # Process each batch\n",
    "                for batch in loaders[split]:\n",
    "                    # Move to CUDA\n",
    "                    input_audio = batch['audio'].to(dev)\n",
    "                    sample_rate = batch['sample_rate'].to(dev)\n",
    "                    target = batch['label'].squeeze(1).to(dev)\n",
    "\n",
    "                    # Reset gradients\n",
    "                    if split == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                    \n",
    "                    # Compute output\n",
    "                    ast_imput = feature_extractor(input_audio, sampling_rate=sample_rate, return_tensors=\"pt\")\n",
    "                    output = model(ast_input)\n",
    "\n",
    "                    # Compute loss \n",
    "                    loss = criterion(output, target.long())\n",
    "                    \n",
    "                    # Update loss\n",
    "                    sum_loss[split] += loss.item()\n",
    "                    \n",
    "                    # Check parameter update\n",
    "                    if split == \"train\":\n",
    "                        # Compute gradients\n",
    "                        loss.backward()\n",
    "                        # Optimize\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    # Compute accuracy\n",
    "                    pred = torch.argmax(output,1)\n",
    "                    batch_accuracy = (pred == target).sum().item()/target.numel()\n",
    "                    \n",
    "                    # Update accuracy\n",
    "                    sum_accuracy[split] += batch_accuracy\n",
    "\n",
    "                # checkpoint\n",
    "                if epoch%save_every == 0 and split == 'train':\n",
    "                    torch.save(model.state_dict(), os.path.join(save_path, 'weights.pt'))\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(save_path, 'optim.pt'))\n",
    "                \n",
    "                \n",
    "            # Compute epoch loss/accuracy\n",
    "            epoch_loss = {split: sum_loss[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
    "            epoch_accuracy = {split: sum_accuracy[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
    "            # Update history\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                history_loss[split].append(epoch_loss[split])\n",
    "                history_accuracy[split].append(epoch_accuracy[split])\n",
    "            # Print info\n",
    "            print(f\"Epoch {epoch+1}:\",\n",
    "                  f\"TrL={epoch_loss['train']:.4f},\",\n",
    "                  f\"TrA={epoch_accuracy['train']:.4f},\",\n",
    "                  f\"VL={epoch_loss['val']:.4f},\",\n",
    "                  f\"VA={epoch_accuracy['val']:.4f},\",\n",
    "                  f\"TeL={epoch_loss['test']:.4f},\",\n",
    "                  f\"TeA={epoch_accuracy['test']:.4f},\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    finally:\n",
    "        # Plot loss\n",
    "        plt.title(\"Loss\")\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            plt.plot(history_loss[split], label=split)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # Plot accuracy\n",
    "        plt.title(\"Accuracy\")\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            plt.plot(history_accuracy[split], label=split)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "cdde3f07-1812-4343-967c-982fdbc0ec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bus': 108, 'residential_area': 108, 'car': 108, 'grocery_store': 108, 'train': 108, 'forest_path': 108, 'park': 108, 'library': 108, 'cafe/restaurant': 108, 'tram': 108, 'city_center': 108, 'office': 108, 'beach': 108, 'home': 108, 'metro_station': 108}\n"
     ]
    }
   ],
   "source": [
    "def conta_istanze_classi(path):\n",
    "    class_count = {}\n",
    "\n",
    "\n",
    "\n",
    "    with open(path, 'r') as file:\n",
    "\n",
    "        for line in file:\n",
    "\n",
    "            nome_audio, nome_classe = line.strip().split()\n",
    "\n",
    "            if nome_classe in class_count:\n",
    "                class_count[nome_classe] += 1\n",
    "            else:\n",
    "                class_count[nome_classe] = 1\n",
    "\n",
    "\n",
    "    return class_count\n",
    "\n",
    "print(conta_istanze_classi(\"c:/Users/cerru/Desktop/TUT17/labels/evaluate.txt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
