{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c5dcf1-fd7f-498b-a627-f95b3d1f7a28",
   "metadata": {},
   "source": [
    "# Inizializzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40eceac-2dd3-4eba-bfbc-8b2a2cfb7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "063fd768-2fe9-4315-b472-23d52a5c921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.23.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fce462e-0156-4751-aeba-df63a6cf37c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3fff90d-213e-48ab-9eb4-34bb2f5bf9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cerru\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e449586-6df0-4775-8c09-de9aa1c99c0f",
   "metadata": {},
   "source": [
    "# Import AST Pretrained and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f00374df-0d56-4eea-973f-a6762a271f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASTForAudioClassification(\n",
       "  (audio_spectrogram_transformer): ASTModel(\n",
       "    (embeddings): ASTEmbeddings(\n",
       "      (patch_embeddings): ASTPatchEmbeddings(\n",
       "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ASTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ASTLayer(\n",
       "          (attention): ASTSdpaAttention(\n",
       "            (attention): ASTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ASTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ASTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ASTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): ASTMLPHead(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=768, out_features=527, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, ASTForAudioClassification\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\", trust_remote_code=True)\n",
    "dataset = dataset.sort(\"id\")\n",
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "model = ASTForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4185ed5-b0e3-4b3c-82f1-4bc82a1c423e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Speech'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio file is decoded on the fly\n",
    "inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_ids = torch.argmax(logits, dim=-1).item()\n",
    "predicted_label = model.config.id2label[predicted_class_ids]\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c7e9e7-8f81-4620-a28c-048a5383064f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute loss - target_label is e.g. \"down\"\n",
    "target_label = model.config.id2label[0]\n",
    "inputs[\"labels\"] = torch.tensor([model.config.label2id[target_label]])\n",
    "loss = model(**inputs).loss\n",
    "round(loss.item(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c578e51-5352-4509-90ad-a8ee869c69c6",
   "metadata": {},
   "source": [
    "# Prompt Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dcd6f0-f65a-44b9-b327-3096e50b4a89",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187b8b8f-f1f4-4ffd-8ce1-e7c11fdd2eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cerru\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ASTModel(\n",
       "  (embeddings): ASTEmbeddings(\n",
       "    (patch_embeddings): ASTPatchEmbeddings(\n",
       "      (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): ASTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ASTLayer(\n",
       "        (attention): ASTSdpaAttention(\n",
       "          (attention): ASTSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ASTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ASTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ASTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ASTModel, AutoProcessor\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\", trust_remote_code=True)\n",
    "dataset = dataset.sort(\"id\")\n",
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "\n",
    "model = ASTModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0265fcd-366f-4fa5-9cd1-8204a8ffe4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1214, 768]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio file is decoded on the fly\n",
    "inputs = processor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7470bdd-43ab-4460-bb27-e7b61c221633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id'],\n",
       "    num_rows: 73\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "167d706b-1322-4a6d-82a3-74389d3cf07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': 'C:/Users/cerru/.cache/huggingface/datasets/downloads/extracted/f3eb62acb63aa6cb8437f4bdaee2cc3fe72cb5c7d10d1f47223e14d011e73d46/dev_clean/1272/128104\\\\1272-128104-0000.flac', 'audio': {'path': 'C:/Users/cerru/.cache/huggingface/datasets/downloads/extracted/f3eb62acb63aa6cb8437f4bdaee2cc3fe72cb5c7d10d1f47223e14d011e73d46/dev_clean/1272/128104\\\\1272-128104-0000.flac', 'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00042725, 0.00057983,\n",
      "       0.0010376 ]), 'sampling_rate': 16000}, 'text': 'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL', 'speaker_id': 1272, 'chapter_id': 128104, 'id': '1272-128104-0000'}\n",
      "[0.00238037 0.0020752  0.00198364 ... 0.00042725 0.00057983 0.0010376 ]\n",
      "93680\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "print(dataset[0][\"audio\"][\"array\"])\n",
    "print(len(dataset[0][\"audio\"][\"array\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9207ad-fdde-42f1-b9b8-263d20db75e5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7892cd7b-906c-4c63-baaa-452420a9edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import mul\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AST_PromptTuning(nn.Module):\n",
    "\n",
    "    # dropout apply dropout after each prompt\n",
    "    # str = \"none\" --> only head tuning\n",
    "    def __init__(self, prompt_tokens: int = 5, prompt_dropout: float = 0.0, prompt_type: str = 'deep'):\n",
    "        super().__init__()\n",
    "\n",
    "        # load vit model\n",
    "        self.encoder = ASTModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "\n",
    "        # hidden_size = depth of the model\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.config.hidden_size, 384),\n",
    "            # nn.Linear(self.encoder.config.hidden_size, 192),\n",
    "            # nn.Linear(self.encoder.config.hidden_size, 96),\n",
    "            nn.Linear(384, 15)\n",
    "        )\n",
    "\n",
    "        # freeze\n",
    "        for n, p in self.encoder.named_parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.prompt_type = prompt_type # \"shallow\" \"deep\" or None\n",
    "\n",
    "        if prompt_type is not None:\n",
    "\n",
    "            # prompt\n",
    "            self.prompt_tokens = prompt_tokens  # number of prompted tokens\n",
    "            self.prompt_dropout = nn.Dropout(prompt_dropout)\n",
    "            self.prompt_dim = self.encoder.config.hidden_size\n",
    "\n",
    "            # initiate prompt (random)\n",
    "            val = math.sqrt(6. / float(3 * reduce(mul, (self.encoder.config.patch_size, self.encoder.config.patch_size), 1) + self.prompt_dim))\n",
    "\n",
    "            # my vector of learnable parameters (how many (prompt_tokens) and dimension (prompt_dim))\n",
    "            self.prompt_embeddings = nn.Parameter(torch.zeros(1, self.prompt_tokens, self.prompt_dim))\n",
    "\n",
    "            # xavier_uniform initialization\n",
    "            nn.init.uniform_(self.prompt_embeddings.data, -val, val)\n",
    "\n",
    "            if self.prompt_type == 'deep':\n",
    "                self.total_d_layer = self.encoder.config.num_hidden_layers\n",
    "                self.deep_prompt_embeddings = nn.Parameter(\n",
    "                    # - 1 cause shallow already inserted\n",
    "                    torch.zeros(self.total_d_layer-1, self.prompt_tokens, self.prompt_dim)\n",
    "                )\n",
    "                # xavier_uniform initialization\n",
    "                nn.init.uniform_(self.deep_prompt_embeddings.data, -val, val)\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        # set train status for this class: disable all but the prompt-related modules\n",
    "        if mode:\n",
    "            # training:\n",
    "            self.encoder.eval()\n",
    "            if self.prompt_type is not None:\n",
    "              # enable dropout and batch normalization\n",
    "                self.prompt_dropout.train()\n",
    "        else:\n",
    "            # eval:\n",
    "            for module in self.children():\n",
    "                module.train(mode)\n",
    "\n",
    "    def incorporate_prompt(self, x, prompt_embeddings, n_prompt: int = 0):\n",
    "        # x shape: (batch size, n_tokens, hidden_dim)\n",
    "        # pompt_embeddings shape: (1, n_prompt, hidden_dim)\n",
    "        B = x.shape[0]\n",
    "\n",
    "        # peek the class token, add prompts, add sequence\n",
    "\n",
    "        # concat prompts: (batch size, cls_token + n_prompt + n_patches, hidden_dim)\n",
    "        x = torch.cat((\n",
    "            x[:, :1, :],\n",
    "            self.prompt_dropout(prompt_embeddings.expand(B, -1, -1)),\n",
    "            x[:, (1+n_prompt):, :]\n",
    "        ), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_features(self, x):\n",
    "\n",
    "        # go through the encoder embeddings\n",
    "        x = self.encoder.embeddings(x)\n",
    "\n",
    "        # add prompts\n",
    "        x = self.incorporate_prompt(x, self.prompt_embeddings)\n",
    "\n",
    "        if self.prompt_type == 'deep':\n",
    "            # deep mode\n",
    "            x = model.encoder.encoder.layer[0](x)[0]\n",
    "            for i in range(1, self.total_d_layer):\n",
    "                x = self.incorporate_prompt(x, self.deep_prompt_embeddings[i-1], self.prompt_tokens)\n",
    "                x = model.encoder.encoder.layer[i](x)[0]\n",
    "        else:\n",
    "            # shallow mode\n",
    "            x = self.encoder.encoder(x)[\"last_hidden_state\"]\n",
    "\n",
    "        x = self.encoder.layernorm(x)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.prompt_type is not None:\n",
    "            x = self.forward_features(x)[:, 0, :]\n",
    "        else:\n",
    "          # pass x, take the classification token\n",
    "            x = self.encoder(x)[\"last_hidden_state\"][:, 0, :]\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5f66293-d648-4fb4-808d-1ef178a2e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AST params: 86488335\n",
      "Head fine-tuning: 301071\n",
      "Shallow prompt-tuning: 304911\n",
      "Deep prompt-tuning: 347151\n"
     ]
    }
   ],
   "source": [
    "model = AST_PromptTuning(prompt_type=None)\n",
    "# count number of parameters\n",
    "print(\"AST params:\", sum(p.numel() for p in model.parameters()))\n",
    "# count number of trainable parameters\n",
    "print(\"Head fine-tuning:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "model = AST_PromptTuning(prompt_type='shallow')\n",
    "# count number of trainable parameters\n",
    "print(\"Shallow prompt-tuning:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "model = AST_PromptTuning(prompt_type='deep')\n",
    "# count number of trainable parameters\n",
    "print(\"Deep prompt-tuning:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a071ebf6-97fa-4c54-9831-12b5dbdd824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_values': tensor([[[-0.9894, -1.2776, -0.9066,  ..., -0.5855, -0.7328, -0.7346],\n",
      "         [-0.9942, -1.2776, -0.9058,  ..., -0.6302, -0.7277, -0.8872],\n",
      "         [-0.8979, -1.2094, -0.8326,  ..., -0.5787, -0.6236, -0.7860],\n",
      "         ...,\n",
      "         [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670],\n",
      "         [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670],\n",
      "         [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670]]])}\n"
     ]
    }
   ],
   "source": [
    "# audio file is decoded on the fly\n",
    "inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "\n",
    "print(inputs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs['input_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81777924-5548-4293-9dc7-5b1551c8abb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7189, -0.0014,  0.2666, -0.5154, -0.0391,  0.0547,  0.0153, -0.1374,\n",
       "         -0.1847,  0.2537, -0.2873,  0.2529,  0.5561, -0.3804, -0.3067]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8866e966-09c9-4418-94e3-025792ff7444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_ids = torch.argmax(outputs, dim=-1).item()\n",
    "predicted_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0ca634f-8544-499d-b268-8383356231ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0333, 0.0683, 0.0893, 0.0409, 0.0658, 0.0723, 0.0695, 0.0596, 0.0569,\n",
       "         0.0882, 0.0513, 0.0881, 0.1193, 0.0468, 0.0503]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "softmax = F.softmax(outputs, dim=1)\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98edb4-bc22-4e82-8a2f-8183727b9c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
